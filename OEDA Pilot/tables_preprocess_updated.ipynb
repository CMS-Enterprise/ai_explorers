{"cells":[{"cell_type":"code","source":["%run \"./one_hot_encoder\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"933181ac-3cef-47e4-bcee-3a81de3f7223"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Table preprocessing\n\nThis notebook includes routines for building the preprocessed tables from the tsfresh and timeseries inputs.\n\nPreprocessing consists of several steps:\n- One-hot encoding categorical variables (see the one_hot_encoder notebook) -- these tables are also saved for use as non-resampled inputs\n- SMOTE oversampling\n- (optionally) Undersampling using either the SMOTEENN (edited nearest neighbor) or Tomek methods.\n- Writing the resampled data frames to tables for reuse."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c5a3e06e-bc69-4d58-b941-308eb723a950"}}},{"cell_type":"code","source":["# Enable Arrow for faster pd/spark interop\nspark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n\n# use our project-standard splits\ninput_table_afe = 'eldb.opioid_SA_LA_hosp_final_abbr_ftr_extrctn_and_demos'\ninput_table_tsf = 'eldb.opioid_SA_LA_hosp_final_tsfresh_and_demos'\ntrain_split_sql = 'MOD(bene_id, 20) < 14'\nval_split_sql = 'MOD(bene_id, 20) >= 14 AND MOD(bene_id, 20) < 18'\ntest_split_sql = 'MOD(bene_id, 20) >= 18'"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4594638e-5cb9-4528-8620-b60682bedf71"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## One-hot encoding\nThis is a modified version of the CMSPytorchDataset class that (also) produces a one-hot encoded pandas DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a993b05-2414-412f-88e2-351cadaa53c0"}}},{"cell_type":"code","source":["import random\nfrom torch.utils.data import Dataset, DataLoader\n\n# pass in a pandas DataFrame (either via PySpark's toPandas() or via pd.read_csv)\n\nclass CMSPandasPytorchDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.bad_cateogries = [\"STATIC_DEMO_bene_age\"]\n        self.prep_cols()\n        self.run_one_hot_encoding()\n        \n    def prep_cols(self):\n        for column in self.bad_cateogries:\n            if column in self.df.columns:\n                self.df.drop(column, axis=1, inplace=True)\n        categorical_cols = [column for column in self.df.columns if \"STATIC\" in column]\n        self.df.dropna(inplace=True, axis=0)\n        self.categorical_df = self.df[categorical_cols].astype(str)\n        self.df.drop(columns=categorical_cols, inplace=True)\n        self.labels = self.df[\"target\"].to_numpy().astype(float)\n        self.df.drop(columns=[\"target\"], axis=1, inplace=True)\n\n    def run_one_hot_encoding(self):\n        self.encoder = CMSOneHotEncoder(self.categorical_df.to_numpy())\n        categorical_df_as_numpy = self.encoder.get_one_hots(self.categorical_df.to_numpy())\n        self.pdf = pd.concat([self.df.astype(float), self.encoder.get_one_hots_df(self.categorical_df.to_numpy()), pd.DataFrame(self.labels, columns=[\"labels\"])], axis=1)\n        self.data = np.concatenate((self.df.to_numpy(), categorical_df_as_numpy), axis=1).astype(float)\n        \n    def __getitem__(self, index):\n        features = self.data[index]\n        label = self.labels[index]\n        return features, label\n\n    def __len__(self):\n        return len(self.df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b914204a-99e2-4f20-aa1f-fefca88ed975"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["## Create and catalog one-hot-encoded tables\nfor input_table in [input_table_afe, input_table_tsf]:\n  pdf = spark.table(input_table).toPandas()\n  cms_ds = CMSPandasPytorchDataset(df=pdf)\n  ohe_df = spark.createDataFrame(cms_ds.pdf)\n  ohe_df.write.mode(\"overwrite\").saveAsTable(input_table + '_ohe')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f1da4dc-45c4-460a-b9e6-6aee0cdafaa8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## SMOTE Resampling\nTo correct class imbalance we apply SMOTE. Becasue our dataset includes many categorical variables, we can't apply plain SMOTE (or Approx-SMOTE, in its current implementation). We use SMOTENC from the `imbalanced-learn` library, which is designed to handle a mix of categorical and numeric variables.\n\nWe also optionally apply the Tomek or ENN (Edited Nearest Neighbor) undersampling methods to remove samples from the majority class. They have slightly different strategies for removing samples, which can result in slightly different boundary tradeoffs in models trained from them.\n\nNote that `imblearn` is not Spark-aware, so the actual fit/resample step will run on the driver node, not the cluster worker nodes."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"88accae3-eade-4d85-890f-0abe702cdf17"}}},{"cell_type":"code","source":["from imblearn.over_sampling import SMOTENC\nfrom imblearn.combine import SMOTEENN, SMOTETomek\nfrom collections import Counter\nimport pandas as pd\nimport time\n\nfor input_table in [input_table_afe, input_table_tsf]:\n  print(f'Processing {input_table}')\n  pdf = spark.table(input_table+'_ohe').where(train_split_sql).toPandas()\n  X = pdf.drop(['bene_id','labels'], axis=1)\n  y = pdf['labels']\n  print(f'Original dataset samples per class {Counter(y)}')\n  # categorical vars are:\n  # - all CC_\n  # - all STATIC_\n  cat_cols = [X.columns.get_loc(col) for col in X.columns if col.startswith(\"CC_\") or col.startswith(\"STATIC_\")] \n  smote = SMOTENC(random_state=2143, categorical_features=cat_cols)\n  sme = SMOTETomek(smote=smote) #SMOTEENN(smote=smote)\n  print('Starting resample...')\n  start = time.time()\n  X_res, y_res = sme.fit_resample(X, y)  # to oversample only, use smote.fit_resample(X, y) instead\n  end = time.time()\n  print(f'Resampling took {end - start} seconds')\n  print(f'Resampled dataset samples per class {Counter(y_res)}')\n  \n  spark.createDataFrame(pd.concat([X_res, y_res], axis=1)) \\\n    .write.mode(\"overwrite\") \\\n    .saveAsTable(input_table+'_train_smotenctomek')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de05bb61-1768-426a-b8c6-dc1be4a4cb40"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Processing eldb.opioid_SA_LA_hosp_final_abbr_ftr_extrctn_and_demos\nOriginal dataset samples per class Counter({0.0: 457023, 1.0: 1008})\nStarting resample...\nResampling took 16937.497621297836 seconds\nResampled dataset samples per class Counter({0.0: 456865, 1.0: 456865})\nProcessing eldb.opioid_SA_LA_hosp_final_tsfresh_and_demos\nOriginal dataset samples per class Counter({0.0: 457023, 1.0: 1008})\nStarting resample...\nResampling took 19424.448752641678 seconds\nResampled dataset samples per class Counter({0.0: 454628, 1.0: 454628})\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Processing eldb.opioid_SA_LA_hosp_final_abbr_ftr_extrctn_and_demos\nOriginal dataset samples per class Counter({0.0: 457023, 1.0: 1008})\nStarting resample...\nResampling took 16937.497621297836 seconds\nResampled dataset samples per class Counter({0.0: 456865, 1.0: 456865})\nProcessing eldb.opioid_SA_LA_hosp_final_tsfresh_and_demos\nOriginal dataset samples per class Counter({0.0: 457023, 1.0: 1008})\nStarting resample...\nResampling took 19424.448752641678 seconds\nResampled dataset samples per class Counter({0.0: 454628, 1.0: 454628})\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2040ec9-96cf-46a8-b76d-84feaa7acd17"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"tables_preprocess_updated","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":428349}},"nbformat":4,"nbformat_minor":0}
