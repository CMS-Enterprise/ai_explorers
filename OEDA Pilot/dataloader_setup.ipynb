{"cells":[{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\nimport pandas as pd\nimport numpy as np\nimport re, string, timeit\n\ndef remove_punctuation(s):\n  \"\"\"\n    Helper function to remove punctuation from category names so that they play nice with being columns \n  \"\"\"\n  s = s.replace(\" \", \"_\").lower()\n  s = s.replace(\"-\", \"_\")\n  return re.sub(r'\\W+', '', s)\n\nclass CMSOneHotEncoder:\n    \"\"\"\n      A class dedicated to reliably and repeatably one hot encoding the categorical features in the eldb.opioid_SA_LA_hosp_sktime_table.\n      NOTE: the order of classes and keys in this dictionary and category list are absolutely cruicial to ensuring the output is as expect.\n      DO NOT EDIT THE ORDER OF THIS LIST OR DICTIONARY WITHOUT CONSULTING OTHERS ON THE PROJECT\n      DO NOT EDIT THE ORDER OF THIS LIST OR DICTINOARY UNLESS YOU ARE PREPARED TO THROW AWAY ALL PAST MODELS\n      Uses sklearn's OneHotEncoder class\n    \"\"\"\n    def __init__(self, data):\n        self.category_info = {\n          'STATIC_DEMO_crec_label': ['Old age and survivorâ€™s insurance (OASI)', 'End-stage renal disease (ESRD)', 'Disability insurance benefits (DIB)'],\n          'STATIC_DEMO_race_label': ['Black or African-American', 'Asian / Pacific Islander','Unknown','Other','Hispanic','American Indian / Alaska Native','Non-Hispanic White'],\n          'STATIC_DEMO_sex_label': ['Female', 'Male'],\n          'STATIC_DEMO_state_cd': ['SC','AZ','LA','MN','NJ','DC','OR','VA','RI','KY','WY','NH','MI','NV','WI','ID','CA','CT','NE','MT','NC','VT','MD', 'DE', 'MO',         'VI','IL','ME','ND','WA','MS','AL','IN','OH','TN','IA','NM','PA','SD','NY','TX','WV','GA','MA','KS','FL','CO','AK','AR','OK','PR','UT','HI','Unassigned'],\n          'STATIC_DEMO_RUCA1': ['1','4','2','7','3','9','10','8','6','5'],\n          'STATIC_DEMO_ADI_NATRANK_binned': ['0-10','11-20','21-30','31-40','41-50','51-60','61-70','71-80','81-90','91-100','Unassigned']\n                             }\n        self.category_list = [\n          self.category_info[\"STATIC_DEMO_sex_label\"], \n          self.category_info[\"STATIC_DEMO_state_cd\"], \n          self.category_info[\"STATIC_DEMO_race_label\"], \n          self.category_info[\"STATIC_DEMO_crec_label\"], \n          self.category_info[\"STATIC_DEMO_RUCA1\"],\n          self.category_info[\"STATIC_DEMO_ADI_NATRANK_binned\"]\n        ]\n        self.encoder = OneHotEncoder(categories=self.category_list)\n        self.encoder.fit(data)\n        \n    def get_one_hots(self, input_data):\n        return self.encoder.transform(input_data).toarray()\n    \n    def get_one_hots_df(self, input_data):\n        # This order is specific for the list above\n        col_names = []\n        # This for loop constructs the proper column names for each OHE'd column\n        for dict_key in [\"STATIC_DEMO_sex_label\", \"STATIC_DEMO_state_cd\", \"STATIC_DEMO_race_label\", \"STATIC_DEMO_crec_label\",\"STATIC_DEMO_RUCA1\",\"STATIC_DEMO_ADI_NATRANK_binned\"]:\n          cur_category_list = self.category_info[dict_key]\n          cur_category_list = map(remove_punctuation, cur_category_list)\n          categories_to_add = [f\"{dict_key}_{sub_cat}\"for sub_cat in cur_category_list]\n          col_names.extend(categories_to_add)\n\n        transformed_data = self.encoder.transform(input_data).toarray()\n        return pd.DataFrame(data=transformed_data, columns=col_names)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"17ff8cf9-cde6-44e7-a0ee-49e0cba4b117"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["import random\nfrom torch.utils.data import Dataset, DataLoader\n\nclass CMSPytorchDataset(Dataset):\n    \"\"\"\n      This class inherits from torch's Dataset class, and performs final step data prep, like normalization and OHEing\n    \"\"\"\n    def __init__(self, csv_path = \"csv_path.csv\", one_hot_encoding = True, drop_ts=False):\n        self.df = pd.read_csv(csv_path)\n        if \"target\" in self.df.columns:\n          self.target_col_name = \"target\"\n        else:\n          self.target_col_name = \"labels\"\n        self.cat_normalization = {\"STATIC_DEMO_bene_age\": lambda x: x/100}\n        \n        self.normalize_cols()\n        self.remove_cols()\n        self.drop_ts = drop_ts\n        self.one_hot_encoding = one_hot_encoding\n        if self.drop_ts:\n          self.drop_ts()\n        if self.one_hot_encoding:\n          self.run_one_hot_encoding()\n        else:\n          self.set_data()\n          \n        self.input_shape = self.data.shape[1]\n          \n    def normalize_cols(self):\n        # Perform normalization. If additional features were added that needed normalization, \n        # one could add the corresponding normalization function to the dictionary above.\n        for column, norm_func in self.cat_normalization.items():\n          if column in self.df.columns:\n            self.df[column] = self.df[column].apply(norm_func)\n\n    def remove_cols(self):\n        # Drop rows with nan values, if any were to ever appear\n        self.df.dropna(inplace=True, axis=0)\n\n        # Save but drop the labels and bene_ids. They both will be in the same order as the feature\n        # ie self.labels[i] for some valid i corresponds to self.bene_ids[i] and self.df.iloc[i]\n\n        self.labels = self.df[self.target_col_name].to_numpy().astype(float)\n        self.df.drop(columns=[self.target_col_name], axis=1, inplace=True)\n        \n        if \"bene_id\" in self.df.columns:\n          self.bene_ids = self.df[\"bene_id\"].to_numpy().astype(float)\n          self.df.drop(columns=[\"bene_id\"], axis=1, inplace=True)\n         \n    def drop_ts(self):\n      print('Removing columns...')\n      for column in self.df.columns:\n        if \"TS_\" in column:\n          print(f\"Removing {column}\")\n          self.df.drop(columns=[column], axis=1, inplace=True)\n        \n    def run_one_hot_encoding(self):\n        \"\"\"\n          Run the One Hot Encoder and assign self.data the full dataset\n        \"\"\"\n        categorical_cols = [column for column in self.df.columns if \"STATIC\" in column]\n        self.categorical_df = self.df[categorical_cols].astype(str)\n        self.df.drop(columns=categorical_cols, inplace=True)\n        \n        self.encoder = CMSOneHotEncoder(self.categorical_df.to_numpy())\n        categorical_df_as_numpy = self.encoder.get_one_hots(self.categorical_df.to_numpy())\n        self.data = np.concatenate((self.df.to_numpy(), categorical_df_as_numpy), axis=1).astype(float)\n        \n    def set_data(self):\n      self.data = self.df.to_numpy()\n        \n    def get_full_dataset_as_df(self):\n        \"\"\"\n          Return the dataset as a dataframe with One Hot Encoded categorical features included.\n          The column names will contain both the cateogrical group and specific label separated by an underscore.\n          Dataframes are slightly slower to access than numpy arrays, hence using numpy in self.data\n        \"\"\"\n        print(self.one_hot_encoding)\n        if self.one_hot_encoding:\n          ohe_df = self.encoder.get_one_hots_df(self.categorical_df.to_numpy())\n          labels = pd.DataFrame(data=self.labels,columns=[self.target_col_name])\n          return pd.concat([self.df, ohe_df, labels], axis=1)\n        else:\n          labels = pd.DataFrame(data=self.labels,columns=[self.target_col_name])\n          return pd.concat([self.df, labels], axis=1)\n\n    def __getitem__(self, index):\n        \"\"\"\n          A pythonic function for using the dataloader as both\n          an iterator and to index it like one would a list (ie dataset[0])\n        \"\"\"\n        features = self.data[index]\n        label = self.labels[index]\n        return features, label\n\n    def __len__(self):\n        \"\"\"\n          A pythonic function to allow len(dataset)\n        \"\"\"\n        return len(self.df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9fe3671b-175b-43e1-8060-ab894963ce53"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"dataloader_setup","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":393216}},"nbformat":4,"nbformat_minor":0}
