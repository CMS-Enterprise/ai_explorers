{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3cc96f4-cce8-4fca-bb20-4d0493676e73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import count\n",
    "import databricks.automl\n",
    "import logging\n",
    "import mlflow.pyfunc\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "logging.getLogger(\"py4j\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"py4j\").setLevel(logging.WARNING)\n",
    "# To supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def get_date_int(in_date):\n",
    "    return int(str(in_date).split('-')[2])\n",
    "  \n",
    "\n",
    "def get_date_text(in_date):\n",
    "    return str(in_date)\n",
    "\n",
    "def run_multi_timeseries(train_pdf,train_pdf_work,test_pdf,process_type,state_numeric,state_alpha,file,run_nbr):\n",
    "    \n",
    "    test_pdf['date_int'] = test_pdf.daily_rep_pd_date.apply(get_date_int)\n",
    "    train_pdf['date_int'] = train_pdf.daily_rep_pd_date.apply(get_date_int)\n",
    "    train_pdf_work['date_int'] = train_pdf_work.daily_rep_pd_date.apply(get_date_int)\n",
    "    train_pdf['daily_rep_pd_date']= pd.to_datetime(train_pdf['daily_rep_pd_date'])\n",
    "    train_pdf_work['daily_rep_pd_date']= pd.to_datetime(train_pdf_work['daily_rep_pd_date'])\n",
    "    test_pdf['daily_rep_pd_date']= pd.to_datetime(test_pdf['daily_rep_pd_date'])\n",
    "\n",
    "    AutoMLSummary = databricks.automl.forecast(dataset = train_pdf_work,target_col = \"errs\",time_col = \"daily_rep_pd_date\",frequency = \"D\",horizon = 1,primary_metric = \"smape\", timeout_minutes = 120)\n",
    "            \n",
    "    run_id = MlflowClient()\n",
    "    #print(run_id)\n",
    "    trial_id = AutoMLSummary.best_trial.mlflow_run_id\n",
    "    #print(trial_id)\n",
    "    model_uri = \"runs:/{run_id}/model\".format(run_id=trial_id)\n",
    "    print(model_uri)\n",
    "\n",
    "    training_score = 0\n",
    "    validation_score = 0\n",
    "    test_score = AutoMLSummary.best_trial.evaluation_metric_score\n",
    "\n",
    "    # Prepare test dataset\n",
    "    y_test = test_pdf[\"errs\"]\n",
    "    X_test = test_pdf.drop(\"errs\", axis=1)\n",
    "\n",
    "    # Run inference using the best model\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    predictions = model.predict(X_test)\n",
    "    # Prepare test dataset\n",
    "    \n",
    "\n",
    "    test_pdf[\"errs_predict\"] = predictions\n",
    "    test_pdf['errs_predict'] = test_pdf['errs_predict'].astype('int64')\n",
    "    \n",
    "    test_pdf['file_type'] = file\n",
    "    test_pdf['state_code_numeric'] = state_numeric\n",
    "    test_pdf['state_code_alpha'] = state_alpha\n",
    "    test_pdf['date_text'] = test_pdf.daily_rep_pd_date.apply(get_date_text)\n",
    "\n",
    "    test_pdf['model_score_train'] = training_score\n",
    "    test_pdf['model_score_validate'] = validation_score \n",
    "    test_pdf['model_score_test'] = test_score\n",
    "\n",
    "    test_pdf['model_parent_process'] = 'AutoML-Forecast ML'\n",
    "    test_pdf['model_name'] = AutoMLSummary.best_trial.model_description\n",
    "    test_pdf['score_type'] = 'smape'\n",
    "    test_pdf['errs_predict'] = test_pdf['errs_predict'].astype('int64')\n",
    "\n",
    "    test_pdf[\"best_model_url\"] = model_uri\n",
    "    test_pdf[\"experimant_info\"] = ''\n",
    "    test_pdf[\"model_run_num\"] = run_nbr\n",
    "    test_pdf['model_run_type'] = 'E - FC - Auto Multi-Model'\n",
    "    test_pdf['comments'] = process_type\n",
    "    test_pdf['source_data_table_name'] = ' '\n",
    "    \n",
    "    test_pdf['errors_actual_previous_mo'] = 0\n",
    "    test_pdf['mo_to_mo_difference'] = 0\n",
    "    \n",
    "    test_pdf['errors_actual_previous_mo'] = 0\n",
    "    test_pdf['errors_actual_previous_mo'] = test_pdf['errors_actual_previous_mo'].astype('int64')\n",
    "    test_pdf['actual_to_predicted_difference'] = 0\n",
    "    test_pdf['source_notebook_url'] = ' '\n",
    "    test_pdf['actual_to_predicted_pct'] = 0\n",
    "    test_pdf['experiment_info'] = ' '\n",
    "    test_pdf['mo_to_mo_pct'] = 0\n",
    "    \n",
    "    test_pdf.rename(columns={'errs': 'errors_actual_current_mo', 'errs_predict': 'errors_predicted_current_mo'}, inplace=True)\n",
    "    test_pdf['model_score_forecast'] = 0\n",
    "    test_pdf['absolute_difference'] = 0\n",
    "    \n",
    "    return_df=test_pdf[['model_run_type','model_run_num','state_code_numeric','state_code_alpha','daily_rep_pd_date','date_text','date_int','file_type','errors_actual_previous_mo','errors_actual_current_mo','mo_to_mo_difference',\t'mo_to_mo_pct','errors_predicted_current_mo','actual_to_predicted_difference','absolute_difference','actual_to_predicted_pct','model_parent_process','model_name','score_type','model_score_forecast','model_score_train','model_score_validate','model_score_test','source_notebook_url','best_model_url','experiment_info','source_data_table_name','comments']]\n",
    "    \n",
    "    spark_return_df = spark.createDataFrame(return_df) \n",
    "    spark_return_df.write.saveAsTable(\"datalab_scratch.fc_multi_test_forecast_1_kv\",mode=\"append\")\n",
    "    \n",
    "    train_pdf['model_run_type'] = 'E - FC - Auto Multi-Model'\n",
    "    train_pdf['file_type'] = file\n",
    "    train_pdf['state_code_numeric'] = state_numeric\n",
    "    train_pdf['state_code_alpha'] = state_alpha\n",
    "    train_pdf['comments'] = process_type\n",
    "    train_pdf['model_run_num'] = run_nbr\n",
    "    train_pdf['errs'] = train_pdf['errs'].astype('int64')\n",
    "    \n",
    "    return_train_pdf = train_pdf[['model_run_type','model_run_num','state_code_numeric','state_code_alpha','daily_rep_pd_date','date_int','file_type','comments','errs']]\n",
    "    spark_train_pdf = spark.createDataFrame(return_train_pdf) \n",
    "    spark_train_pdf.write.saveAsTable(\"datalab_scratch.fc_multi_train_forecast_1_kv\",mode=\"append\")\n",
    "    \n",
    "  \n",
    "    \n",
    "def get_train_and_test_df(table_name):\n",
    "    query_1 = \"select * from \" + table_name + \" where daily_rep_pd_date >= '2022-01-01' AND daily_rep_pd_date <= '2022-01-18'\"\n",
    "    query_2 = \"select * from \" + table_name + \" where daily_rep_pd_date >= '2022-01-19'\"\n",
    "    \n",
    "    train_df = spark.sql(query_1)\n",
    "    train_pdf = train_df.select(\"*\").toPandas()\n",
    "    \n",
    "    test_df = spark.sql(query_2)\n",
    "    test_pdf = test_df.select(\"*\").toPandas()\n",
    "    \n",
    "    return train_pdf, test_pdf\n",
    "\n",
    "def treat_outliers(df, col):\n",
    "    \"\"\"\n",
    "    treats outliers in a variable\n",
    "    col: str, name of the numerical variable\n",
    "    df: dataframe\n",
    "    col: name of the column\n",
    "    \"\"\"\n",
    "    Q1 = df[col].quantile(0.25)  # 25th quantile\n",
    "    Q3 = df[col].quantile(0.75)  # 75th quantile\n",
    "    IQR = Q3 - Q1                # Inter Quantile Range (75th perentile - 25th percentile)\n",
    "    lower_whisker = Q1 - 1.5 * IQR\n",
    "    upper_whisker = Q3 + 1.5 * IQR\n",
    "\n",
    "    # all the values smaller than lower_whisker will be assigned the value of lower_whisker\n",
    "    # all the values greater than upper_whisker will be assigned the value of upper_whisker\n",
    "    # the assignment will be done by using the clip function of NumPy\n",
    "    df[col] = np.clip(df[col], lower_whisker, upper_whisker)\n",
    "\n",
    "    return df\n",
    "\n",
    "#drop result table\n",
    "try:\n",
    "  spark.sql(\"drop table datalab_scratch.fc_multi_train_forecast_1_kv \")\n",
    "except Exception as e:\n",
    "  print(f\"Table does not exist\")\n",
    "  print(e) \n",
    "\n",
    "try:\n",
    "  spark.sql(\"drop table datalab_scratch.fc_multi_test_forecast_1_kv\")\n",
    "except Exception as e:\n",
    "  print(f\"Table does not exist\")\n",
    "  print(e) \n",
    "\n",
    "state_df_spark = spark.sql(\"select * from datalab_scratch.state_codes where state_code_numeric in ('29', '44') order by State_Code_Numeric\")\n",
    "\n",
    "state_df = state_df_spark.toPandas()\n",
    "file_list = ['CIP','CLT','COT','CRX','ELG','MCR','PRV','TPL']\n",
    "process_type_list = ['Features/Processing: submission_methods','Features/Processing: submission_methods_with_outlier_treatment','Features/Processing: error_category','Features/Processing: error_category_with_outlier_treatment']\n",
    "run_nbr = 0\n",
    "\n",
    "      \n",
    "for process_type in process_type_list:\n",
    "    print(process_type)\n",
    "    run_nbr = run_nbr + 1\n",
    "    for index, row in state_df.iterrows():\n",
    "        state_numeric = row.State_Code_Numeric\n",
    "        state_alpha = row.State_Code_Alpha\n",
    "        print(state_numeric)\n",
    "        print(state_alpha)\n",
    "        for file in file_list:\n",
    "            print(file)\n",
    "            if 'submission_methods' in process_type:\n",
    "               table_name = \"datalab_scratch.daily_\" + state_numeric + \"_\" + state_alpha + \"_\" + file + \"_ready_ml_input_df_ss\"\n",
    "            else:\n",
    "               table_name = \"datalab_scratch.daily_\" + state_numeric + \"_\" + state_alpha + \"_\" + file + \"_ready_ml_input_df\"\n",
    "            \n",
    "            train_pdf, test_pdf = get_train_and_test_df(table_name)\n",
    "            train_pdf_work = train_pdf.copy()\n",
    "            \n",
    "            if 'outlier' in process_type:\n",
    "               train_pdf_work = treat_outliers(train_pdf_work,'errs')\n",
    "              \n",
    "            if train_pdf.empty or test_pdf.empty:\n",
    "               print(\"No Data for the state \" + state_alpha + \" and file type \" + file )\n",
    "            else:\n",
    "               run_multi_timeseries(train_pdf,train_pdf_work,test_pdf,process_type,state_numeric,state_alpha,file,run_nbr)\n",
    "\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5bfa855a-8a56-4128-9615-5d71b8081d86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from  datalab_scratch.fc_multi_train_forecast_1_kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b59638af-3b2d-49ce-832d-f29aa0b4f919",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from  datalab_scratch.fc_multi_test_forecast_1_kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffcac519-a317-40ff-aa5a-c73f7a174e95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table datalab_scratch.fc_multi_test_forecast_2_kv using delta\n",
    "as\n",
    "select model_run_type\n",
    "     , model_run_num\n",
    "     , state_code_numeric\n",
    "     , state_code_alpha\n",
    "     , daily_rep_pd_date\n",
    "     , date_text\n",
    "     , date_int\n",
    "     , file_type\n",
    "     , sum(errors_actual_previous_mo) as errors_actual_previous_mo\n",
    "     , sum(errors_actual_current_mo) as errors_actual_current_mo\n",
    "     , sum(mo_to_mo_difference) as mo_to_mo_difference\n",
    "     , sum(mo_to_mo_pct) as mo_to_mo_pct\n",
    "     , sum(errors_predicted_current_mo) as errors_predicted_current_mo\n",
    "     , sum(actual_to_predicted_difference) as actual_to_predicted_difference\n",
    "     , sum(absolute_difference) as absolute_difference\n",
    "     , sum(actual_to_predicted_pct) as actual_to_predicted_pct\n",
    "     , model_parent_process\n",
    "     , model_name\n",
    "     , score_type\n",
    "     , model_score_forecast\n",
    "     , model_score_train\n",
    "     , model_score_validate\n",
    "     , model_score_test\n",
    "     , source_notebook_url\n",
    "     , best_model_url\n",
    "     , experiment_info\n",
    "     , source_data_table_name\n",
    "     , comments\n",
    "  from datalab_scratch.fc_multi_test_forecast_1_kv\n",
    "-- where model_run_num = 3\n",
    "--   and state_code_numeric = '44'\n",
    "--   and file_type = 'COT'\n",
    " --  and date_int = 19\n",
    " group by model_run_type\n",
    "        , model_run_num\n",
    "        , state_code_numeric\n",
    "        , state_code_alpha\n",
    "        , daily_rep_pd_date\n",
    "        , date_text\n",
    "        , date_int\n",
    "        , file_type\n",
    "        , model_parent_process\n",
    "        , model_name\n",
    "        , score_type\n",
    "        , model_score_forecast\n",
    "        , model_score_train\n",
    "        , model_score_validate\n",
    "        , model_score_test\n",
    "        , source_notebook_url\n",
    "        , best_model_url\n",
    "        , experiment_info\n",
    "        , source_data_table_name\n",
    "        , comments\n",
    " order by model_run_num\n",
    "        , state_code_numeric\n",
    "        , state_code_alpha\n",
    "        , file_type\n",
    "        , date_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "381a6282-a141-4420-90a0-6b79913660f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table datalab_scratch.fc_multi_train_forecast_2_kv using delta\n",
    "as\n",
    "select model_run_type\n",
    "     , model_run_num\n",
    "     , state_code_numeric\n",
    "     , state_code_alpha\n",
    "     , daily_rep_pd_date\n",
    "     , date_int\n",
    "     , file_type\n",
    "     , comments\n",
    "     , sum(errs) as errs\n",
    "  from datalab_scratch.fc_multi_train_forecast_1_kv\n",
    "-- where model_run_num = 3\n",
    "--   and state_code_numeric = '44'\n",
    "--   and file_type = 'COT'\n",
    "--   and date_int = 18\n",
    " group by model_run_type\n",
    "        , model_run_num\n",
    "        , state_code_numeric\n",
    "        , state_code_alpha\n",
    "        , daily_rep_pd_date\n",
    "        , date_int\n",
    "        , file_type\n",
    "        , comments\n",
    "  order by model_run_num\n",
    "        , state_code_numeric\n",
    "        , state_code_alpha\n",
    "        , file_type\n",
    "        , date_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd84ffe9-7d10-438d-b2a0-d87d2a939367",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "final_df = pd.DataFrame(columns=['model_run_type','model_run_num','state_code_numeric','state_code_alpha','daily_rep_pd_date','date_text','date_int','file_type','errors_actual_previous_mo','errors_actual_current_mo','mo_to_mo_difference',\t'mo_to_mo_pct','errors_predicted_current_mo','actual_to_predicted_difference','absolute_difference','actual_to_predicted_pct','model_parent_process','model_name','score_type','model_score_forecast','model_score_train','model_score_validate','model_score_test','source_notebook_url','best_model_url','experiment_info','source_data_table_name','comments'])\n",
    "\n",
    "\n",
    "try:\n",
    "  spark.sql(\"drop table datalab_scratch.fc_multi_final_forecast_kv \")\n",
    "except Exception as e:\n",
    "#except:\n",
    "  print(f\"Table does not esist\")\n",
    "  print(e) \n",
    "\n",
    "test_df_spark = spark.sql(\"select * from datalab_scratch.fc_multi_test_forecast_2_kv \")\n",
    "test_df = test_df_spark.toPandas()\n",
    "\n",
    "train_df_spark = spark.sql(\"select * from datalab_scratch.fc_multi_train_forecast_2_kv \")\n",
    "train_df = train_df_spark.toPandas()\n",
    "\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    previous_month = row.date_int - 1\n",
    "    #print(previous_month)\n",
    "    if row.date_int == 19:\n",
    "       get_previous_month_errors = train_df.loc[(train_df['state_code_numeric'] == row.state_code_numeric) & (train_df['model_run_num'] == row.model_run_num) & (train_df['file_type'] == row.file_type) & (train_df['date_int'] == 18) ]['errs'].values[0]\n",
    "    else:\n",
    "       get_previous_month_errors = test_df.loc[(test_df['state_code_numeric'] == row.state_code_numeric) & (test_df['model_run_num'] == row.model_run_num) & (test_df['file_type'] == row.file_type) & (test_df['date_int'] == previous_month) ]['errors_actual_current_mo'].values[0]\n",
    "    #print(get_previous_month_errors)\n",
    "    \n",
    "    month_to_month_difference = row.errors_actual_current_mo - get_previous_month_errors\n",
    "    month_to_month_pct = float(month_to_month_difference/get_previous_month_errors)\n",
    "    \n",
    "    actual_to_predicted_difference_errors = row.errors_predicted_current_mo - row.errors_actual_current_mo\n",
    "    absolute_diff = abs(actual_to_predicted_difference_errors)\n",
    "    actual_to_predic_pct = float(actual_to_predicted_difference_errors/row.errors_actual_current_mo)\n",
    "    \n",
    "    \n",
    "    final_df = final_df.append({'model_run_type':row.model_run_type,'model_run_num':row.model_run_num,'state_code_numeric':row.state_code_numeric,'state_code_alpha':row.state_code_alpha,'daily_rep_pd_date':row.daily_rep_pd_date,'date_text':row.date_text,'date_int':row.date_int,'file_type':row.file_type,'errors_actual_previous_mo':get_previous_month_errors,'errors_actual_current_mo':row.errors_actual_current_mo,'mo_to_mo_difference':month_to_month_difference,\t'mo_to_mo_pct':month_to_month_pct,'errors_predicted_current_mo':row.errors_predicted_current_mo,'actual_to_predicted_difference':actual_to_predicted_difference_errors,'absolute_difference':absolute_diff,'actual_to_predicted_pct':actual_to_predic_pct,'model_parent_process':row.model_parent_process,'model_name':row.model_name,'score_type':row.score_type,'model_score_forecast':row.model_score_forecast,'model_score_train':row.model_score_train,'model_score_validate':row.model_score_validate,'model_score_test':row.model_score_test,'source_notebook_url':row.source_notebook_url,'best_model_url':row.best_model_url,'experiment_info':row.experiment_info,'source_data_table_name':row.source_data_table_name,'comments':row.comments},ignore_index=True)\n",
    "\n",
    "print(final_df)\n",
    "spark_final_df = spark.createDataFrame(final_df) \n",
    "spark_final_df.write.saveAsTable(\"datalab_scratch.fc_multi_final_forecast_kv\",mode=\"overwrite\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93840510-ceda-47db-ad75-768800d2095d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from datalab_scratch.fc_multi_final_forecast_kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdf6d84b-aac3-4f29-89d9-57bd2adc5a7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "update datalab_scratch.fc_multi_final_forecast_kv\n",
    "   set source_data_table_name = 'datalab_scratch.fc_multi_final_forecast_kv'\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e743187d-bd3d-4de1-9caf-393ac56849f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "update datalab_scratch.fc_multi_final_forecast_kv\n",
    "   set source_notebook_url = 'https://databricks-val-data.macbisdw.cmscloud.local/#notebook/3373505/command/3373512'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfde136c-6f4b-45cc-a6fb-83fb468f72c7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from datalab_scratch.fc_multi_final_forecast_kv\n",
    " where model_run_num = 1\n",
    "   and state_code_numeric = 44\n",
    " order by file_type,date_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbf5f486-e3ab-4b18-90f5-7a6be7b4439d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql --Scoring here is SMAPE\n",
    "--0 would mean model can't be improved further.  100% (1) is worst possible\n",
    "--https://medium.com/@davide.sarra/how-to-interpret-smape-just-like-mape-bf799ba03bdc#:~:text=In%20its%20first%20definition%2C%20sMAPE,between%200%25%20and%20100%25.\n",
    "\n",
    "--Feature generation of type 4 (error category with outlier treatment) performed best both on average accuracy and it's worst prediction\n",
    "select avg(model_score_test), min(model_score_test), max(model_score_test), model_run_num from datalab_scratch.fc_multi_final_forecast_kv\n",
    "group by model_run_num\n",
    "-- where model_run_num = 1\n",
    "--   and state_code_numeric = 44"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "T-MSIS Pilot Final - Auto Multi-Model-09Feb2023",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
