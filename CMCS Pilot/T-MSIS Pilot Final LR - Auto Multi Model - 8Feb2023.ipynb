{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78a40834-48c0-45bf-95d0-bcd430e15200",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import count\n",
    "import sklearn\n",
    "import databricks.automl\n",
    "import logging\n",
    "from databricks import automl\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# To supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"py4j\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"py4j\").setLevel(logging.WARNING)\n",
    "\n",
    "def get_experiment_name(expr_string):\n",
    "    experiment_list = str(expr_string).replace('\\n',' ').split(',')\n",
    "    for name in experiment_list:\n",
    "        if 'mlflow.experiment.sourceName' in name:\n",
    "            #print(name)\n",
    "            experiment_name = name.split(\":\",1)[1]\n",
    "            return experiment_name\n",
    "\n",
    "def get_date_int(in_date):\n",
    "    return int(str(in_date).split('-')[2])\n",
    "  \n",
    "\n",
    "def get_date_text(in_date):\n",
    "    return str(in_date)\n",
    "\n",
    "def run_multi_liner_regression(train_pdf,train_pdf_work,test_pdf,process_type,state_numeric,state_alpha,file,run_nbr):\n",
    "    \n",
    "    test_pdf['date_int'] = test_pdf.daily_rep_pd_date.apply(get_date_int)\n",
    "    train_pdf['date_int'] = train_pdf.daily_rep_pd_date.apply(get_date_int)\n",
    "    train_pdf_work['date_int'] = train_pdf_work.daily_rep_pd_date.apply(get_date_int)\n",
    "    summary = automl.regress(train_pdf_work, time_col=\"daily_rep_pd_date\", target_col=\"errs\", timeout_minutes=120)\n",
    "    best_model = summary.best_trial.model_description\n",
    "    training_score = summary.best_trial.metrics['training_r2_score']\n",
    "    validation_score = summary.best_trial.metrics['val_r2_score']\n",
    "    test_score = summary.best_trial.metrics['test_r2_score']\n",
    "\n",
    "    model_uri = summary.best_trial.model_path\n",
    "\n",
    "    # Prepare test dataset\n",
    "    y_test = test_pdf[\"errs\"]\n",
    "    X_test = test_pdf.drop(\"errs\", axis=1)\n",
    "\n",
    "    # Run inference using the best model\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "\n",
    "    test_pdf[\"errs_predict\"] = predictions\n",
    "    test_pdf['errs_predict'] = test_pdf['errs_predict'].astype('int64')\n",
    "    \n",
    "    test_pdf['file_type'] = file\n",
    "    test_pdf['state_code_numeric'] = state_numeric\n",
    "    test_pdf['state_code_alpha'] = state_alpha\n",
    "    test_pdf['date_text'] = test_pdf.daily_rep_pd_date.apply(get_date_text)\n",
    "\n",
    "    test_pdf['model_score_train'] = training_score\n",
    "    test_pdf['model_score_validate'] = validation_score \n",
    "    test_pdf['model_score_test'] = test_score\n",
    "\n",
    "    test_pdf['model_parent_process'] = 'AutoML-Regress ML'\n",
    "    test_pdf['model_name'] = best_model\n",
    "    test_pdf['score_type'] = 'r2'\n",
    "    test_pdf['errs_predict'] = test_pdf['errs_predict'].astype('int64')\n",
    "\n",
    "    test_pdf[\"best_model_url\"] = summary.best_trial.notebook_url\n",
    "    test_pdf[\"experimant_info\"] = get_experiment_name(str(summary.experiment))\n",
    "    test_pdf[\"model_run_num\"] = run_nbr\n",
    "    test_pdf['model_run_type'] = 'D - LR - Auto Multi-Model'\n",
    "    test_pdf['comments'] = process_type\n",
    "    test_pdf['source_data_table_name'] = ' '\n",
    "    \n",
    "    test_pdf['errors_actual_previous_mo'] = 0\n",
    "    test_pdf['mo_to_mo_difference'] = 0\n",
    "    \n",
    "    test_pdf['errors_actual_previous_mo'] = 0\n",
    "    test_pdf['errors_actual_previous_mo'] = test_pdf['errors_actual_previous_mo'].astype('int64')\n",
    "    test_pdf['actual_to_predicted_difference'] = 0\n",
    "    test_pdf['source_notebook_url'] = ' '\n",
    "    test_pdf['actual_to_predicted_pct'] = 0\n",
    "    test_pdf['experiment_info'] = ' '\n",
    "    test_pdf['mo_to_mo_pct'] = 0\n",
    "    \n",
    "    test_pdf.rename(columns={'errs': 'errors_actual_current_mo', 'errs_predict': 'errors_predicted_current_mo'}, inplace=True)\n",
    "    test_pdf['model_score_forecast'] = 0\n",
    "    test_pdf['absolute_difference'] = 0\n",
    "    \n",
    "    return_df=test_pdf[['model_run_type','model_run_num','state_code_numeric','state_code_alpha','daily_rep_pd_date','date_text','date_int','file_type','errors_actual_previous_mo','errors_actual_current_mo','mo_to_mo_difference',\t'mo_to_mo_pct','errors_predicted_current_mo','actual_to_predicted_difference','absolute_difference','actual_to_predicted_pct','model_parent_process','model_name','score_type','model_score_forecast','model_score_train','model_score_validate','model_score_test','source_notebook_url','best_model_url','experiment_info','source_data_table_name','comments']]\n",
    "    \n",
    "    spark_return_df = spark.createDataFrame(return_df) \n",
    "    spark_return_df.write.saveAsTable(\"datalab_scratch.lr_multi_test_forecast_1_kv\",mode=\"append\")\n",
    "    \n",
    "    train_pdf['model_run_type'] = 'D - LR - Auto Multi-Model'\n",
    "    train_pdf['file_type'] = file\n",
    "    train_pdf['state_code_numeric'] = state_numeric\n",
    "    train_pdf['state_code_alpha'] = state_alpha\n",
    "    train_pdf['comments'] = process_type\n",
    "    train_pdf['model_run_num'] = run_nbr\n",
    "    train_pdf['errs'] = train_pdf['errs'].astype('int64')\n",
    "    \n",
    "    return_train_pdf = train_pdf[['model_run_type','model_run_num','state_code_numeric','state_code_alpha','daily_rep_pd_date','date_int','file_type','comments','errs']]\n",
    "    spark_train_pdf = spark.createDataFrame(return_train_pdf) \n",
    "    spark_train_pdf.write.saveAsTable(\"datalab_scratch.lr_multi_train_forecast_1_kv\",mode=\"append\")\n",
    "    \n",
    "    \n",
    "def get_train_and_test_df(table_name):\n",
    "    query_1 = \"select * from \" + table_name + \" where daily_rep_pd_date >= '2022-01-01' AND daily_rep_pd_date <= '2022-01-18'\"\n",
    "    query_2 = \"select * from \" + table_name + \" where daily_rep_pd_date >= '2022-01-19'\"\n",
    "    \n",
    "    train_df = spark.sql(query_1)\n",
    "    train_pdf = train_df.select(\"*\").toPandas()\n",
    "    \n",
    "    test_df = spark.sql(query_2)\n",
    "    test_pdf = test_df.select(\"*\").toPandas()\n",
    "    \n",
    "    return train_pdf, test_pdf\n",
    "\n",
    "def treat_outliers(df, col):\n",
    "    \"\"\"\n",
    "    treats outliers in a variable\n",
    "    col: str, name of the numerical variable\n",
    "    df: dataframe\n",
    "    col: name of the column\n",
    "    \"\"\"\n",
    "    Q1 = df[col].quantile(0.25)  # 25th quantile\n",
    "    Q3 = df[col].quantile(0.75)  # 75th quantile\n",
    "    IQR = Q3 - Q1                # Inter Quantile Range (75th perentile - 25th percentile)\n",
    "    lower_whisker = Q1 - 1.5 * IQR\n",
    "    upper_whisker = Q3 + 1.5 * IQR\n",
    "\n",
    "    # all the values smaller than lower_whisker will be assigned the value of lower_whisker\n",
    "    # all the values greater than upper_whisker will be assigned the value of upper_whisker\n",
    "    # the assignment will be done by using the clip function of NumPy\n",
    "    df[col] = np.clip(df[col], lower_whisker, upper_whisker)\n",
    "\n",
    "    return df\n",
    "\n",
    "#drop result table\n",
    "try:\n",
    "  spark.sql(\"drop table datalab_scratch.lr_multi_train_forecast_1_kv \")\n",
    "except Exception as e:\n",
    "  print(f\"Table does not esist\")\n",
    "  print(e) \n",
    "\n",
    "try:\n",
    "  spark.sql(\"drop table datalab_scratch.lr_multi_test_forecast_1_kv \")\n",
    "except Exception as e:\n",
    "#except:\n",
    "  print(f\"Table does not esist\")\n",
    "  print(e) \n",
    "\n",
    "state_df_spark = spark.sql(\"select * from datalab_scratch.state_codes where state_code_numeric in ('29', '44') order by State_Code_Numeric\")\n",
    "state_df = state_df_spark.toPandas()\n",
    "file_list = ['ELG','PRV','MCR','TPL','CIP','COT','CLT','CRX']\n",
    "process_type_list = ['Features/Processing: submission_methods','Features/Processing: submission_methods_with_outlier_treatment','Features/Processing: error_category','Features/Processing: error_category_with_outlier_treatment']\n",
    "run_nbr = 0\n",
    "\n",
    "      \n",
    "for process_type in process_type_list:\n",
    "    print(process_type)\n",
    "    run_nbr = run_nbr + 1\n",
    "    for index, row in state_df.iterrows():\n",
    "        state_numeric = row.State_Code_Numeric\n",
    "        state_alpha = row.State_Code_Alpha\n",
    "        print(state_numeric)\n",
    "        print(state_alpha)\n",
    "        for file in file_list:\n",
    "            print(file)\n",
    "            if 'submission_methods' in process_type:\n",
    "               table_name = \"datalab_scratch.daily_\" + state_numeric + \"_\" + state_alpha + \"_\" + file + \"_ready_ml_input_df_ss\"\n",
    "            else:\n",
    "               table_name = \"datalab_scratch.daily_\" + state_numeric + \"_\" + state_alpha + \"_\" + file + \"_ready_ml_input_df\"\n",
    "            \n",
    "            train_pdf, test_pdf = get_train_and_test_df(table_name)\n",
    "            train_pdf_work = train_pdf.copy()\n",
    "            \n",
    "            if 'outlier' in process_type:\n",
    "               train_pdf_work = treat_outliers(train_pdf_work,'errs')\n",
    "              \n",
    "            if train_pdf.empty or test_pdf.empty:\n",
    "               print(\"No Data for the state \" + state_alpha + \" and file type \" + file )\n",
    "            else:\n",
    "               run_multi_liner_regression(train_pdf,train_pdf_work,test_pdf,process_type,state_numeric,state_alpha,file,run_nbr)\n",
    "\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c6da30b-9aca-43ed-b06d-e616223ebc5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from datalab_scratch.lr_multi_train_forecast_1_kv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a31bd7c2-7fe4-4a88-8429-73fb6e5de52c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table datalab_scratch.lr_multi_test_forecast_2_kv using delta\n",
    "as\n",
    "select model_run_type\n",
    "     , model_run_num\n",
    "     , state_code_numeric\n",
    "     , state_code_alpha\n",
    "     , daily_rep_pd_date\n",
    "     , date_text\n",
    "     , date_int\n",
    "     , file_type\n",
    "     , sum(errors_actual_previous_mo) as errors_actual_previous_mo\n",
    "     , sum(errors_actual_current_mo) as errors_actual_current_mo\n",
    "     , sum(mo_to_mo_difference) as mo_to_mo_difference\n",
    "     , sum(mo_to_mo_pct) as mo_to_mo_pct\n",
    "     , sum(errors_predicted_current_mo) as errors_predicted_current_mo\n",
    "     , sum(actual_to_predicted_difference) as actual_to_predicted_difference\n",
    "     , sum(absolute_difference) as absolute_difference\n",
    "     , sum(actual_to_predicted_pct) as actual_to_predicted_pct\n",
    "     , model_parent_process\n",
    "     , model_name\n",
    "     , score_type\n",
    "     , model_score_forecast\n",
    "     , model_score_train\n",
    "     , model_score_validate\n",
    "     , model_score_test\n",
    "     , source_notebook_url\n",
    "     , best_model_url\n",
    "     , experiment_info\n",
    "     , source_data_table_name\n",
    "     , comments\n",
    "  from datalab_scratch.lr_multi_test_forecast_1_kv\n",
    "-- where model_run_num = 3\n",
    "--   and state_code_numeric = '44'\n",
    "--   and file_type = 'COT'\n",
    " --  and date_int = 19\n",
    " group by model_run_type\n",
    "        , model_run_num\n",
    "        , state_code_numeric\n",
    "        , state_code_alpha\n",
    "        , daily_rep_pd_date\n",
    "        , date_text\n",
    "        , date_int\n",
    "        , file_type\n",
    "        , model_parent_process\n",
    "        , model_name\n",
    "        , score_type\n",
    "        , model_score_forecast\n",
    "        , model_score_train\n",
    "        , model_score_validate\n",
    "        , model_score_test\n",
    "        , source_notebook_url\n",
    "        , best_model_url\n",
    "        , experiment_info\n",
    "        , source_data_table_name\n",
    "        , comments\n",
    " order by model_run_num\n",
    "        , state_code_numeric\n",
    "        , state_code_alpha\n",
    "        , file_type\n",
    "        , date_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de9cdb99-e43b-4f9d-a79e-7e4b706402de",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table datalab_scratch.lr_multi_train_forecast_2_kv using delta\n",
    "as\n",
    "select model_run_type\n",
    "     , model_run_num\n",
    "     , state_code_numeric\n",
    "     , state_code_alpha\n",
    "     , daily_rep_pd_date\n",
    "     , date_int\n",
    "     , file_type\n",
    "     , comments\n",
    "     , sum(errs) as errs\n",
    "  from datalab_scratch.lr_multi_train_forecast_1_kv\n",
    "-- where model_run_num = 3\n",
    "--   and state_code_numeric = '44'\n",
    "--   and file_type = 'COT'\n",
    "--   and date_int = 18\n",
    " group by model_run_type\n",
    "        , model_run_num\n",
    "        , state_code_numeric\n",
    "        , state_code_alpha\n",
    "        , daily_rep_pd_date\n",
    "        , date_int\n",
    "        , file_type\n",
    "        , comments\n",
    "  order by model_run_num\n",
    "        , state_code_numeric\n",
    "        , state_code_alpha\n",
    "        , file_type\n",
    "        , date_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73fee396-0d73-4f12-8fd1-8b782115c946",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "final_df = pd.DataFrame(columns=['model_run_type','model_run_num','state_code_numeric','state_code_alpha','daily_rep_pd_date','date_text','date_int','file_type','errors_actual_previous_mo','errors_actual_current_mo','mo_to_mo_difference',\t'mo_to_mo_pct','errors_predicted_current_mo','actual_to_predicted_difference','absolute_difference','actual_to_predicted_pct','model_parent_process','model_name','score_type','model_score_forecast','model_score_train','model_score_validate','model_score_test','source_notebook_url','best_model_url','experiment_info','source_data_table_name','comments'])\n",
    "\n",
    "\n",
    "try:\n",
    "  spark.sql(\"drop table datalab_scratch.lr_multi_final_forecast_kv \")\n",
    "except Exception as e:\n",
    "#except:\n",
    "  print(f\"Table does not esist\")\n",
    "  print(e) \n",
    "\n",
    "test_df_spark = spark.sql(\"select * from datalab_scratch.lr_multi_test_forecast_2_kv \")\n",
    "test_df = test_df_spark.toPandas()\n",
    "\n",
    "train_df_spark = spark.sql(\"select * from datalab_scratch.lr_multi_train_forecast_2_kv \")\n",
    "train_df = train_df_spark.toPandas()\n",
    "\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    previous_month = row.date_int - 1\n",
    "    #print(previous_month)\n",
    "    if row.date_int == 19:\n",
    "       get_previous_month_errors = train_df.loc[(train_df['state_code_numeric'] == row.state_code_numeric) & (train_df['model_run_num'] == row.model_run_num) & (train_df['file_type'] == row.file_type) & (train_df['date_int'] == 18) ]['errs'].values[0]\n",
    "    else:\n",
    "       get_previous_month_errors = test_df.loc[(test_df['state_code_numeric'] == row.state_code_numeric) & (test_df['model_run_num'] == row.model_run_num) & (test_df['file_type'] == row.file_type) & (test_df['date_int'] == previous_month) ]['errors_actual_current_mo'].values[0]\n",
    "    #print(get_previous_month_errors)\n",
    "    \n",
    "    month_to_month_difference = row.errors_actual_current_mo - get_previous_month_errors\n",
    "    month_to_month_pct = float(month_to_month_difference/get_previous_month_errors)\n",
    "    \n",
    "    actual_to_predicted_difference_errors = row.errors_predicted_current_mo - row.errors_actual_current_mo\n",
    "    absolute_diff = abs(actual_to_predicted_difference_errors)\n",
    "    actual_to_predic_pct = float(actual_to_predicted_difference_errors/row.errors_actual_current_mo)\n",
    "    \n",
    "    \n",
    "    final_df = final_df.append({'model_run_type':row.model_run_type,'model_run_num':row.model_run_num,'state_code_numeric':row.state_code_numeric,'state_code_alpha':row.state_code_alpha,'daily_rep_pd_date':row.daily_rep_pd_date,'date_text':row.date_text,'date_int':row.date_int,'file_type':row.file_type,'errors_actual_previous_mo':get_previous_month_errors,'errors_actual_current_mo':row.errors_actual_current_mo,'mo_to_mo_difference':month_to_month_difference,\t'mo_to_mo_pct':month_to_month_pct,'errors_predicted_current_mo':row.errors_predicted_current_mo,'actual_to_predicted_difference':actual_to_predicted_difference_errors,'absolute_difference':absolute_diff,'actual_to_predicted_pct':actual_to_predic_pct,'model_parent_process':row.model_parent_process,'model_name':row.model_name,'score_type':row.score_type,'model_score_forecast':row.model_score_forecast,'model_score_train':row.model_score_train,'model_score_validate':row.model_score_validate,'model_score_test':row.model_score_test,'source_notebook_url':row.source_notebook_url,'best_model_url':row.best_model_url,'experiment_info':row.experiment_info,'source_data_table_name':row.source_data_table_name,'comments':row.comments},ignore_index=True)\n",
    "\n",
    "print(final_df)\n",
    "spark_final_df = spark.createDataFrame(final_df) \n",
    "spark_final_df.write.saveAsTable(\"datalab_scratch.lr_multi_final_forecast_kv\",mode=\"overwrite\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4d28ab0-0c0e-4c5c-be45-54cae2da7f67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from datalab_scratch.lr_multi_final_forecast_kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc4ba027-7651-4020-926a-25bd994cf35e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "update datalab_scratch.lr_multi_final_forecast_kv\n",
    "   set source_data_table_name = 'datalab_scratch.lr_multi_final_forecast_kv'\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4884e6df-4384-4fbf-9d01-3fe504a8515a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "update datalab_scratch.lr_multi_final_forecast_kv\n",
    "   set source_notebook_url = 'https://databricks-val-data.macbisdw.cmscloud.local/#notebook/2831216/command/2831222'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "757f80ed-1b0d-40f4-94d4-002c9b85a3fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from datalab_scratch.lr_multi_final_forecast_kv\n",
    " where model_run_num = 1\n",
    "   and state_code_numeric = 44\n",
    " order by file_type,date_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da23d764-fc31-43c6-97a2-5572d2bb44d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from datalab_scratch.lr_multi_final_forecast_kv\n",
    " where state_code_numeric = 29\n",
    " order by file_type,date_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "969eb6de-0785-497e-b623-513b0f06f923",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql select state_code_numeric, file_type, model_run_num, max(model_score_validate)\n",
    "from datalab_scratch.lr_multi_final_forecast_kv\n",
    "group by state_code_numeric, file_type, model_run_num\n",
    "order by 4 desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28c196aa-0569-4676-9f05-1458f2000708",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql --Avg validation score by state, file type, and model feature type (IE all months for this combo)\n",
    "select state_code_numeric, file_type, model_run_num, avg(model_score_validate)\n",
    "from datalab_scratch.lr_multi_final_forecast_kv\n",
    "group by state_code_numeric, file_type, model_run_num\n",
    "--having avg(model_score_validate) < .5\n",
    "order by 4 desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba4b4631-12d3-4af2-9133-438a5e4f7b3e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql -- Feature generation types with models performing worse than a constant model\n",
    "-- IE feature generation types 3 and 4 where always better than a constant function\n",
    "select model_run_num, count(*) from (\n",
    "select state_code_numeric, file_type, model_run_num, avg(model_score_validate)\n",
    "from datalab_scratch.lr_multi_final_forecast_kv\n",
    "group by state_code_numeric, file_type, model_run_num\n",
    "having avg(model_score_validate) < 0)\n",
    "group by model_run_num\n",
    "order by 2 desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c4052c8-3617-434b-b0ab-ebd31f5c176a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql -- The best model generated with feature set 4 ('Features/Processing: error_category_with_outlier_treatment') always had a .4 r2 score or better\n",
    "select model_run_num, count(*) from (\n",
    "select state_code_numeric, file_type, model_run_num, avg(model_score_validate)\n",
    "from datalab_scratch.lr_multi_final_forecast_kv\n",
    "group by state_code_numeric, file_type, model_run_num\n",
    "having avg(model_score_validate) > .4)\n",
    "group by model_run_num\n",
    "order by 2 desc"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "T-MSIS Pilot Final LR - Auto Multi Model - 8Feb2023",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
