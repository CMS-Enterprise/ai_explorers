{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9552bf54-5086-46e0-9507-3e3e3ba123ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import count\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from scipy.stats import zscore\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from pyspark.sql.functions import col\n",
    "\n",
    "def get_date_int(in_date):\n",
    "    return int(str(in_date).split('-')[2])\n",
    "  \n",
    "\n",
    "def get_date_text(in_date):\n",
    "    return str(in_date)\n",
    "\n",
    "def run_liner_regression(train_pdf,train_pdf_work,test_pdf,process_type,state_numeric,state_alpha,file,run_nbr):\n",
    "    train_pdf['date_int'] = train_pdf.daily_rep_pd_date.apply(get_date_int)\n",
    "    test_pdf['date_int'] = test_pdf.daily_rep_pd_date.apply(get_date_int)\n",
    "    train_pdf_work['date_int'] = train_pdf_work.daily_rep_pd_date.apply(get_date_int)\n",
    "\n",
    "    x_train = train_pdf_work.copy()\n",
    "    x_test = test_pdf.copy()\n",
    "    y_train = x_train[['errs']]\n",
    "    y_test = x_test[['errs']]\n",
    "\n",
    "    #Drop errors from the x dataset\n",
    "    x_train=x_train.drop('errs',axis=1)\n",
    "    x_test=x_test.drop('errs',axis=1)\n",
    "    x_train=x_train.drop('daily_rep_pd_date',axis=1)\n",
    "    x_test=x_test.drop('daily_rep_pd_date',axis=1)\n",
    "\n",
    "    #Fit Linear model\n",
    "    regression_model = LinearRegression()\n",
    "    regression_model.fit(x_train,y_train)\n",
    "\n",
    "    #Model Scores\n",
    "    model_score_train = regression_model.score(x_train,y_train)\n",
    "    #print(\"Model Score on Train set : \" + str(model_score_train) )\n",
    "\n",
    "    model_score_test = regression_model.score(x_test,y_test)\n",
    "    #print(\"Model Score on Test set : \" + str(model_score_test) )\n",
    "\n",
    "    y_predict = pd.DataFrame(regression_model.predict(x_test))\n",
    "    y_predict.rename(columns = {0:'errs_predict'}, inplace = True)\n",
    "\n",
    "    lr_df = pd.concat([test_pdf,y_predict], axis=1, join='inner')\n",
    "    \n",
    "    lr_df['file_type'] = file\n",
    "    lr_df['state_code_numeric'] = state_numeric\n",
    "    lr_df['state_code_alpha'] = state_alpha\n",
    "    lr_df['date_text'] = lr_df.daily_rep_pd_date.apply(get_date_text)\n",
    "\n",
    "    lr_df['model_score_train'] = str(model_score_train)[:4]\n",
    "    lr_df['model_score_validate'] = ' ' \n",
    "    lr_df['model_score_test'] = str(model_score_test)[:4]\n",
    "\n",
    "    lr_df['model_parent_process'] = 'Python ML'\n",
    "    lr_df['model_name'] = 'Linear regression'\n",
    "    lr_df['score_type'] = 'R2'\n",
    "    lr_df['errs_predict'] = lr_df['errs_predict'].astype('int64')\n",
    "\n",
    "    lr_df[\"best_model_url\"] = ''\n",
    "    lr_df[\"experimant_info\"] = ''\n",
    "    lr_df[\"model_run_num\"] = run_nbr\n",
    "    lr_df['model_run_type'] = 'C - LR - Single Model'\n",
    "    lr_df['comments'] = process_type\n",
    "    lr_df['source_data_table_name'] = ' '\n",
    "    \n",
    "    lr_df['errors_actual_previous_mo'] = 0\n",
    "    lr_df['mo_to_mo_difference'] = 0\n",
    "    #lr_df['errors_predicted_current_mo'] = 0\n",
    "    lr_df['errors_actual_previous_mo'] = 0\n",
    "    lr_df['errors_actual_previous_mo'] = lr_df['errors_actual_previous_mo'].astype('int64')\n",
    "    lr_df['actual_to_predicted_difference'] = 0\n",
    "    lr_df['source_notebook_url'] = ' '\n",
    "    lr_df['actual_to_predicted_pct'] = 0\n",
    "    lr_df['experiment_info'] = ' '\n",
    "    lr_df['mo_to_mo_pct'] = 0\n",
    "    #lr_df['errors_actual_current_mo'] = 0\n",
    "    lr_df.rename(columns={'errs': 'errors_actual_current_mo', 'errs_predict': 'errors_predicted_current_mo'}, inplace=True)\n",
    "    lr_df['model_score_forecast'] = 0\n",
    "    lr_df['absolute_difference'] = 0\n",
    "    \n",
    "    return_df=lr_df[['model_run_type','model_run_num','state_code_numeric','state_code_alpha','daily_rep_pd_date','date_text','date_int','file_type','errors_actual_previous_mo','errors_actual_current_mo','mo_to_mo_difference',\t'mo_to_mo_pct','errors_predicted_current_mo','actual_to_predicted_difference','absolute_difference','actual_to_predicted_pct','model_parent_process','model_name','score_type','model_score_forecast','model_score_train','model_score_validate','model_score_test','source_notebook_url','best_model_url','experiment_info','source_data_table_name','comments']]\n",
    "    \n",
    "    spark_return_df = spark.createDataFrame(return_df) \n",
    "    spark_return_df.write.saveAsTable(\"datalab_scratch.lr_test_forecast_1_kv\",mode=\"append\")\n",
    "    \n",
    "    train_pdf['model_run_type'] = 'C - LR - Single Model'\n",
    "    train_pdf['file_type'] = file\n",
    "    train_pdf['state_code_numeric'] = state_numeric\n",
    "    train_pdf['state_code_alpha'] = state_alpha\n",
    "    train_pdf['comments'] = process_type\n",
    "    train_pdf['model_run_num'] = run_nbr\n",
    "    train_pdf['errs'] = train_pdf['errs'].astype('int64')\n",
    "    \n",
    "    return_train_pdf = train_pdf[['model_run_type','model_run_num','state_code_numeric','state_code_alpha','daily_rep_pd_date','date_int','file_type','comments','errs']]\n",
    "    spark_train_pdf = spark.createDataFrame(return_train_pdf) \n",
    "    spark_train_pdf.write.saveAsTable(\"datalab_scratch.lr_train_forecast_1_kv\",mode=\"append\")\n",
    "    \n",
    "def get_train_and_test_df(table_name):\n",
    "    query_1 = \"select * from \" + table_name + \" where daily_rep_pd_date >= '2022-01-01' AND daily_rep_pd_date <= '2022-01-18'\"\n",
    "    query_2 = \"select * from \" + table_name + \" where daily_rep_pd_date >= '2022-01-19'\"\n",
    "    \n",
    "    train_df = spark.sql(query_1)\n",
    "    train_pdf = train_df.select(\"*\").toPandas()\n",
    "    \n",
    "    test_df = spark.sql(query_2)\n",
    "    test_pdf = test_df.select(\"*\").toPandas()\n",
    "    \n",
    "    return train_pdf, test_pdf\n",
    "\n",
    "def treat_outliers(df, col):\n",
    "    \"\"\"\n",
    "    treats outliers in a variable\n",
    "    col: str, name of the numerical variable\n",
    "    df: dataframe\n",
    "    col: name of the column\n",
    "    \"\"\"\n",
    "    Q1 = df[col].quantile(0.25)  # 25th quantile\n",
    "    Q3 = df[col].quantile(0.75)  # 75th quantile\n",
    "    IQR = Q3 - Q1                # Inter Quantile Range (75th perentile - 25th percentile)\n",
    "    lower_whisker = Q1 - 1.5 * IQR\n",
    "    upper_whisker = Q3 + 1.5 * IQR\n",
    "\n",
    "    # all the values smaller than lower_whisker will be assigned the value of lower_whisker\n",
    "    # all the values greater than upper_whisker will be assigned the value of upper_whisker\n",
    "    # the assignment will be done by using the clip function of NumPy\n",
    "    df[col] = np.clip(df[col], lower_whisker, upper_whisker)\n",
    "\n",
    "    return df\n",
    "\n",
    "#drop result table\n",
    "\n",
    "try:\n",
    "  spark.sql(\"drop table datalab_scratch.lr_train_forecast_1_kv \")\n",
    "except Exception as e:\n",
    "  print(f\"Table does not esist\")\n",
    "  print(e) \n",
    "\n",
    "try:\n",
    "  spark.sql(\"drop table datalab_scratch.lr_test_forecast_1_kv \")\n",
    "except Exception as e:\n",
    "  print(f\"Table does not esist\")\n",
    "  print(e) \n",
    "\n",
    "state_df_spark = spark.sql(\"select * from datalab_scratch.state_codes where state_code_numeric in ('29', '44') order by State_Code_Numeric\")\n",
    "\n",
    "state_df = state_df_spark.toPandas()\n",
    "\n",
    "file_list = ['ELG','PRV','MCR','TPL','CIP','COT','CLT','CRX']\n",
    "\n",
    "process_type_list = ['Features/Processing: submission_methods','Features/Processing: submission_methods_with_outlier_treatment','Features/Processing: error_category','Features/Processing: error_category_with_outlier_treatment']\n",
    "run_nbr = 0\n",
    "\n",
    "      \n",
    "for process_type in process_type_list:\n",
    "    print(process_type)\n",
    "    run_nbr = run_nbr + 1\n",
    "    for index, row in state_df.iterrows():\n",
    "        state_numeric = row.State_Code_Numeric\n",
    "        state_alpha = row.State_Code_Alpha\n",
    "        print(state_numeric)\n",
    "        print(state_alpha)\n",
    "        for file in file_list:\n",
    "            print(file)\n",
    "            if 'submission_methods' in process_type:\n",
    "               table_name = \"datalab_scratch.daily_\" + state_numeric + \"_\" + state_alpha + \"_\" + file + \"_ready_ml_input_df_ss\"\n",
    "            else:\n",
    "               table_name = \"datalab_scratch.daily_\" + state_numeric + \"_\" + state_alpha + \"_\" + file + \"_ready_ml_input_df\"\n",
    "            \n",
    "            train_pdf, test_pdf = get_train_and_test_df(table_name)\n",
    "            train_pdf_work = train_pdf.copy()\n",
    "\n",
    "            \n",
    "            if 'outlier' in process_type:\n",
    "               train_pdf_work = treat_outliers(train_pdf_work,'errs')\n",
    "              \n",
    "            if train_pdf.empty or test_pdf.empty:\n",
    "               print(\"No Data for the state \" + state_alpha + \" and file type \" + file )\n",
    "            else:\n",
    "               run_liner_regression(train_pdf,train_pdf_work,test_pdf,process_type,state_numeric,state_alpha,file,run_nbr)\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2dd0752c-690f-4991-8c6c-dc34eb22155a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table datalab_scratch.lr_test_forecast_2_kv using delta\n",
    "as\n",
    "select model_run_type\n",
    "     , model_run_num\n",
    "     , state_code_numeric\n",
    "     , state_code_alpha\n",
    "     , daily_rep_pd_date\n",
    "     , date_text\n",
    "     , date_int\n",
    "     , file_type\n",
    "     , sum(errors_actual_previous_mo) as errors_actual_previous_mo\n",
    "     , sum(errors_actual_current_mo) as errors_actual_current_mo\n",
    "     , sum(mo_to_mo_difference) as mo_to_mo_difference\n",
    "     , sum(mo_to_mo_pct) as mo_to_mo_pct\n",
    "     , sum(errors_predicted_current_mo) as errors_predicted_current_mo\n",
    "     , sum(actual_to_predicted_difference) as actual_to_predicted_difference\n",
    "     , sum(absolute_difference) as absolute_difference\n",
    "     , sum(actual_to_predicted_pct) as actual_to_predicted_pct\n",
    "     , model_parent_process\n",
    "     , model_name\n",
    "     , score_type\n",
    "     , model_score_forecast\n",
    "     , model_score_train\n",
    "     , model_score_validate\n",
    "     , model_score_test\n",
    "     , source_notebook_url\n",
    "     , best_model_url\n",
    "     , experiment_info\n",
    "     , source_data_table_name\n",
    "     , comments\n",
    "  from datalab_scratch.lr_test_forecast_1_kv\n",
    "-- where model_run_num = 3\n",
    "--   and state_code_numeric = '44'\n",
    "--   and file_type = 'COT'\n",
    " --  and date_int = 19\n",
    " group by model_run_type\n",
    "        , model_run_num\n",
    "        , state_code_numeric\n",
    "        , state_code_alpha\n",
    "        , daily_rep_pd_date\n",
    "        , date_text\n",
    "        , date_int\n",
    "        , file_type\n",
    "        , model_parent_process\n",
    "        , model_name\n",
    "        , score_type\n",
    "        , model_score_forecast\n",
    "        , model_score_train\n",
    "        , model_score_validate\n",
    "        , model_score_test\n",
    "        , source_notebook_url\n",
    "        , best_model_url\n",
    "        , experiment_info\n",
    "        , source_data_table_name\n",
    "        , comments\n",
    " order by model_run_num\n",
    "        , state_code_numeric\n",
    "        , state_code_alpha\n",
    "        , file_type\n",
    "        , date_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea8ec2fa-4bec-415c-a7ec-e618a6d981cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql select * from datalab_scratch.lr_test_forecast_2_kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bce3ba0-b322-444d-93bd-1261ee2dddbe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "create or replace table datalab_scratch.lr_train_forecast_2_kv using delta\n",
    "as\n",
    "select model_run_type\n",
    "     , model_run_num\n",
    "     , state_code_numeric\n",
    "     , state_code_alpha\n",
    "     , daily_rep_pd_date\n",
    "     , date_int\n",
    "     , file_type\n",
    "     , comments\n",
    "     , sum(errs) as errs\n",
    "  from datalab_scratch.lr_train_forecast_1_kv\n",
    "-- where model_run_num = 3\n",
    "--   and state_code_numeric = '44'\n",
    "--   and file_type = 'COT'\n",
    "--   and date_int = 18\n",
    " group by model_run_type\n",
    "        , model_run_num\n",
    "        , state_code_numeric\n",
    "        , state_code_alpha\n",
    "        , daily_rep_pd_date\n",
    "        , date_int\n",
    "        , file_type\n",
    "        , comments\n",
    "  order by model_run_num\n",
    "        , state_code_numeric\n",
    "        , state_code_alpha\n",
    "        , file_type\n",
    "        , date_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd334071-472a-494f-9742-f246768a1373",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql select * from datalab_scratch.lr_train_forecast_2_kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b5adf41-7be6-492e-a3e9-c74e134187ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "final_df = pd.DataFrame(columns=['model_run_type','model_run_num','state_code_numeric','state_code_alpha','daily_rep_pd_date','date_text','date_int','file_type','errors_actual_previous_mo','errors_actual_current_mo','mo_to_mo_difference',\t'mo_to_mo_pct','errors_predicted_current_mo','actual_to_predicted_difference','absolute_difference','actual_to_predicted_pct','model_parent_process','model_name','score_type','model_score_forecast','model_score_train','model_score_validate','model_score_test','source_notebook_url','best_model_url','experiment_info','source_data_table_name','comments'])\n",
    "\n",
    "\n",
    "try:\n",
    "  spark.sql(\"drop table datalab_scratch.lr_final_forecast_kv\")\n",
    "except Exception as e:\n",
    "#except:\n",
    "  print(f\"Table does not esist\")\n",
    "  print(e) \n",
    "\n",
    "test_df_spark = spark.sql(\"select * from datalab_scratch.lr_test_forecast_2_kv \")\n",
    "test_df = test_df_spark.toPandas()\n",
    "\n",
    "train_df_spark = spark.sql(\"select * from datalab_scratch.lr_train_forecast_2_kv \")\n",
    "train_df = train_df_spark.toPandas()\n",
    "\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    previous_month = row.date_int - 1\n",
    "    \n",
    "    if row.date_int == 19:\n",
    "       get_previous_month_errors = train_df.loc[(train_df['state_code_numeric'] == row.state_code_numeric) & (train_df['model_run_num'] == row.model_run_num) & (train_df['file_type'] == row.file_type) & (train_df['date_int'] == 18) ]['errs'].values[0]\n",
    "    else:\n",
    "       get_previous_month_errors = test_df.loc[(test_df['state_code_numeric'] == row.state_code_numeric) & (test_df['model_run_num'] == row.model_run_num) & (test_df['file_type'] == row.file_type) & (test_df['date_int'] == previous_month) ]['errors_actual_current_mo'].values[0]\n",
    "    \n",
    "    month_to_month_difference = row.errors_actual_current_mo - get_previous_month_errors\n",
    "    month_to_month_pct = float(month_to_month_difference/get_previous_month_errors)\n",
    "    \n",
    "    actual_to_predicted_difference_errors = row.errors_predicted_current_mo - row.errors_actual_current_mo\n",
    "    absolute_diff = abs(actual_to_predicted_difference_errors)\n",
    "    actual_to_predic_pct = float(actual_to_predicted_difference_errors/row.errors_actual_current_mo)\n",
    "    \n",
    "    \n",
    "    final_df = final_df.append({'model_run_type':row.model_run_type,'model_run_num':row.model_run_num,'state_code_numeric':row.state_code_numeric,'state_code_alpha':row.state_code_alpha,'daily_rep_pd_date':row.daily_rep_pd_date,'date_text':row.date_text,'date_int':row.date_int,'file_type':row.file_type,'errors_actual_previous_mo':get_previous_month_errors,'errors_actual_current_mo':row.errors_actual_current_mo,'mo_to_mo_difference':month_to_month_difference,\t'mo_to_mo_pct':month_to_month_pct,'errors_predicted_current_mo':row.errors_predicted_current_mo,'actual_to_predicted_difference':actual_to_predicted_difference_errors,'absolute_difference':absolute_diff,'actual_to_predicted_pct':actual_to_predic_pct,'model_parent_process':row.model_parent_process,'model_name':row.model_name,'score_type':row.score_type,'model_score_forecast':row.model_score_forecast,'model_score_train':row.model_score_train,'model_score_validate':row.model_score_validate,'model_score_test':row.model_score_test,'source_notebook_url':row.source_notebook_url,'best_model_url':row.best_model_url,'experiment_info':row.experiment_info,'source_data_table_name':row.source_data_table_name,'comments':row.comments},ignore_index=True)\n",
    "\n",
    "print(final_df)\n",
    "spark_final_df = spark.createDataFrame(final_df) \n",
    "spark_final_df.write.saveAsTable(\"datalab_scratch.lr_final_forecast_kv\",mode=\"overwrite\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d51db582-4f5c-4b25-a93b-1a46c4df88ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from datalab_scratch.lr_final_forecast_kv\n",
    " where state_code_numeric = '29' \n",
    " order by file_type,date_int, model_run_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85e5d620-13cb-434f-97c7-9d1cd3af543c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "update datalab_scratch.lr_final_forecast_kv\n",
    "   set source_data_table_name = 'datalab_scratch.lr_final_forecast_kv'\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9de127a4-b087-4d14-8eaa-4d246df03131",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "update datalab_scratch.lr_final_forecast_kv\n",
    "   set source_notebook_url = 'https://databricks-val-data.macbisdw.cmscloud.local/#notebook/2783134/command/2830675'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b57d0ea8-0038-46ec-9310-8d341fce0c9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from datalab_scratch.lr_final_forecast_kv\n",
    " where model_run_num = 1\n",
    "   and state_code_numeric = 44\n",
    " order by file_type,date_int"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "T-MSIS Pilot Final LR - Single Model - 7Feb2023",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
