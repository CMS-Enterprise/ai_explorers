{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faebebbf-b43a-4bb1-9872-db877b5b80cc",
   "metadata": {},
   "source": [
    "#### <font color=\"darkblue\"> 1. This script builds data to train custom classification model in Comprehend. <br> 2. The training files are picked in such a way that they representat the topics accurately. <br> 3. The messages with highest confidence (probability) values and more number of keywords (topic-terms) are selected. <br> 4. The confidence and terms are obtained from previous unsupervised model run. <br> 5. Also, the messages which were origninated from CMS RDS Center are not considered. <br> 6. Prerequisites: <br> &nbsp; &nbsp; a) Run /root/comp_predictions/training_data.sh first (This script collects messages with highest confidence scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9feeee-c592-41f2-a575-b5c51fbd16be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a910fe2-31b6-4eb0-b561-998adfaf0414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f068cc-d937-45fc-84b3-d44f3e16e01d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# from pathlib import Path\n",
    "import boto3\n",
    "import csv\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0c45ee-e17b-4386-9452-f86a0214d2fc",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\"> Functions to read and write to PostgreSQL database tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5870515-ecef-4314-aa5b-91e202642970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------ Function to print errors from PostgreSQL ------------------------------#\n",
    "\n",
    "def print_psycopg2_exception(err):\n",
    "    err_type, err_obj, traceback = sys.exc_info()\n",
    "    line_num = traceback.tb_lineno\n",
    "    print (\"\\npsycopg2 ERROR:\", err, \"on line number:\", line_num)\n",
    "    print (\"psycopg2 traceback:\", traceback, \"-- type:\", err_type)\n",
    "    print (\"\\nextensions.Diagnostics:\", err.diag)\n",
    "    print (\"pgerror:\", err.pgerror)\n",
    "    print (\"pgcode:\", err.pgcode, \"\\n\")\n",
    "    input(\"Press Enter to continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29afab3e-0dab-41b7-8132-b3175731f86e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#-------------- Read PostgreSQL and get processed email keys into a list first -------------------------#\n",
    "\n",
    "def read_postgres(email_key):\n",
    "    records_in_pgres = []\n",
    "    try:    \n",
    "        cursor.execute(\"SELECT sender FROM ml_extract_track_v2 WHERE email_key = '\" + email_key + \"'; \")\n",
    "        row = cursor.fetchone()\n",
    "        # print('sender:', row[0])\n",
    "\n",
    "    except Exception as err:\n",
    "        print_psycopg2_exception(err)\n",
    "\n",
    "    return row[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e7626-6388-4e99-938c-23567b3c7574",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\"> Mention s3 bukets and folders to read and write to here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4502fc16-9459-4cd5-a007-816e97c464b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl_bucket = \"pro-ads-datalake\"\n",
    "s3_file_path = \"ml-training-files/\"\n",
    "s3_read_folder = \"ml-cleaned-emails/\"\n",
    "s3_write_folder = \"ml-training-data/\"\n",
    "\n",
    "cdo_path = \"/root/ml_orgtxt_emails/\"\n",
    "cdc_path = \"/root/ml_cleaned_emails/\"\n",
    "\n",
    "resource = boto3.resource('s3')\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "bucket = resource.Bucket(dl_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa149d68-69e7-4857-a26f-8af55ecb2f52",
   "metadata": {},
   "source": [
    "####  <font color=\"blue\"> 1. Define top 7 keywords (topic-terms) to search from the messages shortlisted in training_data.csv <br> 2. Define s3 folder names to write the training files to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bc8c3-b9ff-4f74-8c7b-a3b42121f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_matches = [ ( \"request\", \"support\", \"ref\", \"program\", \"inquiry\", \"continue\", \"response\", \"resolve\" ),\n",
    "                 ( \"account\", \"password\", \"login\", \"log\", \"lock\", \"reset\", \"website\", \"mfa\" ), \n",
    "                 ( \"account\", \"manager\", \"plan\", \"user\", \"sponsor\", \"authorize\", \"representative\", \"role\" ), \n",
    "                 ( \"application\", \"plan\", \"submit\", \"sponsor\", \"id\", \"deadline\", \"year\", \"annual\" ), \n",
    "                 ( \"reconciliation\", \"step\", \"complete\", \"retiree\", \"cover\", \"process\", \"list\", \"finalize\" ), \n",
    "                 ( \"information\", \"contact\", \"sponsor\", \"additional\", \"overpayment\", \"email\", \"need\", \"action\", \"require\", \"py\"),\n",
    "                 ( \"request\", \"payment\", \"support\", \"ref\", \"setup\", \"interim\", \"notification\", \"hold\" ),\n",
    "                 ( \"cost\", \"report\", \"submit\", \"adjustment\", \"option\", \"vendor\", \"reporter\", \"benefit\" ) ]\n",
    "\n",
    "Old_train_folder = [ \"topic1-account-login-password-reset\", \"topic2-account-manager-auth-rep-reassignment\", \n",
    "                 \"topic3-appl-plan-submission-annual-deadline\", \"topic4-reconciliation-steps-processing\", \n",
    "                 \"topic5-information-contact-overpayment-inquiries\", \"topic6-cost-report-vendor-benefit-adjustment\", \n",
    "                 \"topic7-retiree-file-upload-notification\", \"topic8-support-request-payment-program-resolution\" ]\n",
    "\n",
    "train_folder = [ \"topic1-support-ref-program-response-request\", \"topic2-account-login-password-reset\",  \n",
    "                 \"topic3-acct-mgr-auth-rep-reassignments\", \"topic4-appl-plan-sub-deadline-approval\", \n",
    "                 \"topic5-recon-steps-retiree-process-finalization\", \"topic6-info-contact-addl-overpayment-req\", \n",
    "                 \"topic7-payment-request-support-setup-notification\", \"topic8-cost-report-vendor-option-benefit-adj\" ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532bf21-a12c-4773-af2b-58cc58eec968",
   "metadata": {},
   "source": [
    "####  <font color=\"blue\"> Connect to PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb75d9-6a64-4c8b-a061-245ccc67a9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#------------------------------- Connect to PostgreSQL and read records ---------------------------------#\n",
    "\n",
    "# cursor.close()\n",
    "# conn.close()\n",
    "conn = psycopg2.connect(database=\"YOUR_DATABASE\", user='<YOUR_USER>', password='<YOUR_PASSWORD>', \n",
    "                        host='<DATABASE_HOST>', port= '5432')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c55f07-5775-4e5a-93ea-cf9472c392a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "####  <font color=\"blue\"> Read the filenames from training_data.csv and determine which messages can be considered for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a08bc-978c-47d8-a499-63c7a5663556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnt = 1\n",
    "topic_no = 0\n",
    "topic_words = topic_matches[topic_no]\n",
    "\n",
    "df = pd.read_csv(\"/root/comp_predictions/training_data.csv\")\n",
    "# print(df.head(20))\n",
    "df.sort_values([\"topic\", \"proportion\"], inplace=True, ascending=[True, False])\n",
    "# print(df.head(20))\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    filename = row['docname']\n",
    "    topicNum = row['topic']\n",
    "    # print (i, filename, topicNum)\n",
    "    \n",
    "    if topic_no != topicNum: \n",
    "        continue\n",
    "    else:\n",
    "        if cnt < 61: \n",
    "            email_key = filename[0:-6]\n",
    "            sender = read_postgres(email_key)\n",
    "            sender = sender.lower()\n",
    "            # print(email_key, \" sender:\", sender)\n",
    "            \n",
    "            if sender.find(\"cms.hhs.gov\") != -1 or sender.find(\"mailer-daemon\") != -1:\n",
    "                continue \n",
    "            \n",
    "            with open(cdc_path + filename, 'r') as cdcfile:\n",
    "                fileContent = cdcfile.read()\n",
    "            \n",
    "            if len(fileContent) < 100:\n",
    "                continue\n",
    "                \n",
    "            score = 0\n",
    "            for word in topic_words:\n",
    "                if fileContent.find(word) != -1:\n",
    "                    score += 1\n",
    "            \n",
    "            # print('topic #:', topic_no, '  score now:', score)\n",
    "                \n",
    "            if score >= 4:\n",
    "                print('file:', email_key, 'sender:', sender)\n",
    "                # x = input(\"Hit enter to continue..\")\n",
    "                read_file = cdo_path + filename\n",
    "                write_path = s3_file_path + train_folder[topic_no]\n",
    "                read_s3_file = s3_read_folder + filename\n",
    "                write_s3_file = s3_write_folder + train_folder[topic_no] + \"/\" + filename\n",
    "                print(cnt, \") \", filename, dl_bucket, '%s %s %s' % (write_path, read_s3_file, write_s3_file))\n",
    "                s3.upload_file(read_file, dl_bucket, '%s/%s' % (write_path, filename))\n",
    "                # input(\"Enter to continue..\")\n",
    "                copy_source = {'Bucket': dl_bucket, 'Key': read_s3_file}\n",
    "                resource.meta.client.copy(copy_source, dl_bucket, write_s3_file)\n",
    "                   \n",
    "                cnt += 1\n",
    "                score = 0\n",
    "            # else:\n",
    "                # print('score is', score, ' skipping...', score)  \n",
    "        else:\n",
    "            # reset count and move to the next topic\n",
    "            cnt = 1\n",
    "            topic_no += 1\n",
    "            if topic_no == 8: break\n",
    "            topic_words = topic_matches[topic_no]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95b9b73-a236-4479-b619-8fd2fb88fa59",
   "metadata": {},
   "source": [
    "####  <font color=\"blue\"> This code is a variation of previous code segment, which <br> &nbsp; &nbsp; a) runs for a particular topic number and <br> &nbsp; &nbsp; b) doesn't advance to the next topic automatically when done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b3017-b965-4b76-b580-59bd7232b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a specific topic and score lower than 6.. \n",
    "\n",
    "cnt = 1\n",
    "topic_no = 5\n",
    "topic_words = topic_matches[topic_no]\n",
    "\n",
    "df = pd.read_csv(\"/root/comp_predictions/training_data.csv\")\n",
    "# print(df.head(20))\n",
    "df.sort_values([\"topic\", \"proportion\"], inplace=True, ascending=[True, False])\n",
    "# print(df.head(20))\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    filename = row['docname']\n",
    "    topicNum = row['topic']\n",
    "    # print (i, filename, topicNum)\n",
    "    \n",
    "    if topic_no != topicNum: \n",
    "        continue\n",
    "    else:\n",
    "        if cnt < 32: \n",
    "            email_key = filename[0:-6]\n",
    "            sender = read_postgres(email_key)\n",
    "            sender = sender.lower()\n",
    "            # print(email_key, \" sender:\", sender)\n",
    "            \n",
    "            if sender.find(\"cms.hhs.gov\") != -1 or sender.find(\"mailer-daemon\") != -1:\n",
    "                continue \n",
    "            \n",
    "            with open(cdc_path + filename, 'r') as cdcfile:\n",
    "                fileContent = cdcfile.read()\n",
    "            \n",
    "            if len(fileContent) < 100:\n",
    "                continue\n",
    "                \n",
    "            score = 0\n",
    "            for word in topic_words:\n",
    "                if fileContent.find(word) != -1:\n",
    "                    score += 1\n",
    "            \n",
    "            # print('topic #:', topic_no, '  score now:', score)\n",
    "                \n",
    "            if score >= 3:\n",
    "                print('file:', email_key, 'sender:', sender)\n",
    "                # x = input(\"Hit enter to continue..\")\n",
    "                read_file = cdo_path + filename\n",
    "                write_path = s3_file_path + train_folder[topic_no]\n",
    "                read_s3_file = s3_read_folder + filename\n",
    "                write_s3_file = s3_write_folder + train_folder[topic_no] + \"/\" + filename\n",
    "                print(cnt, \") \", filename, dl_bucket, '%s %s %s' % (write_path, read_s3_file, write_s3_file))\n",
    "                s3.upload_file(read_file, dl_bucket, '%s/%s' % (write_path, filename))\n",
    "                # input(\"Enter to continue..\")\n",
    "                copy_source = {'Bucket': dl_bucket, 'Key': read_s3_file}\n",
    "                resource.meta.client.copy(copy_source, dl_bucket, write_s3_file)\n",
    "                   \n",
    "                cnt += 1\n",
    "                score = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129eceb1-57d4-4f33-b200-2ed73ba86f29",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\"> Define output file locations (temporary and final output) for the csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe9a09-42eb-4a6d-bdf4-a45a66bf994f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# csv_file = open(\"/tmp/train_model_topic1.csv\", \"w\", newline='')\n",
    "# writer = csv.writer(csv_file, quoting=csv.QUOTE_NONNUMERIC, delimiter=',')\n",
    "# outFile = \"ml-training-data-csv/train_model_topic1.csv\"\n",
    "\n",
    "csv_file = open(\"/tmp/train_model.csv\", \"w\", newline='')\n",
    "writer = csv.writer(csv_file, quoting=csv.QUOTE_NONNUMERIC, delimiter=',')\n",
    "outFile = \"ml-training-data-csv/train_model.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62588857-b9b1-4568-88b4-fec8debaf7ec",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\"> Build CSV file from the training data written to s3 folder <i>(ml-training-data)</i> for training the custom classification model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136cc661-39c3-49b6-a969-169300bfac55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnt = 1\n",
    "for obj in bucket.objects.filter(Prefix='ml-training-data/'):\n",
    "    key = obj.key\n",
    "    if (obj.size > 0):\n",
    "        labelStPos = key.find('/') + 1\n",
    "        labelEndPos = key.find('/', labelStPos) \n",
    "        label = key[labelStPos:labelEndPos]\n",
    "        # if not label.startswith(\"topic1\"): continue\n",
    "        fileName = key[labelEndPos+1:] \n",
    "        fileContent = obj.get()['Body'].read().decode('utf-8')\n",
    "        print(str(cnt) + \") \", 'file:', key, '  label:', label)\n",
    "        fileContent = fileName + \" : \" + fileContent\n",
    "        writer.writerow([label, fileContent])\n",
    "        # input(\"Enter to continue\")\n",
    "        label = \"\"\n",
    "        fileContent = \"\"\n",
    "        cnt = cnt + 1\n",
    "        csv_file.flush()\n",
    "    # if cnt > 100: break\n",
    "    \n",
    "csv_file.close()\n",
    "data = pd.read_csv(\"/tmp/train_model.csv\", header = None)\n",
    "shuffled_df = data.sample(frac=1)\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "# shuffled_df.to_csv(csv_buffer, index=False, header=False)\n",
    "shuffled_df.to_csv(csv_buffer, index=False, header=None)\n",
    "resource.Object(dl_bucket, outFile).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9013e6-966b-45ab-aafb-2e46535eba0a",
   "metadata": {},
   "source": [
    "####  <font color=\"blue\"> This code is a variation of previous code segment, to run standalone, to read and shuffle the train_model.csv file once generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1252a7-22fc-4110-8b0a-5d443b16544f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/tmp/train_model.csv\", header = None)\n",
    "shuffled_df = data.sample(frac=1)\n",
    "len(shuffled_df.index)\n",
    "# shuffled_df.shape[0]\n",
    "# len(data.index)\n",
    "csv_buffer = StringIO()\n",
    "# shuffled_df.to_csv(csv_buffer, index=False, header=False)\n",
    "shuffled_df.to_csv(csv_buffer, index=False, header=None)\n",
    "resource.Object(dl_bucket, outFile).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5eaf86-e3dd-424e-b581-a24a70a5253b",
   "metadata": {},
   "source": [
    "####  <font color=\"blue\"> Create custom classifier model using the training data (csv file)<br> Note: Make sure to change the name of the model in <i>DocumentClassifierName</i> option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c065ff5f-d36e-48cc-9890-d3cc55fd23d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = boto3.client('comprehend', region_name='us-east-1')\n",
    "data_access_role_arn = \"arn:aws:iam::XXXXXXXXX:role/service-role/AmazonSageMaker-ExecutionRole-20230418T155781\"\n",
    "\n",
    "input_csv_url = \"s3://pro-ads-datalake/ml-training-data-csv/train_model.csv\"\n",
    "input_data_config = {\"S3Uri\": input_csv_url}\n",
    "output_s3_url = \"s3://pro-ads-datalake/ml-comp-predictions/\"\n",
    "output_data_config = {\"S3Uri\": output_s3_url}\n",
    "\n",
    "# Create a document classifier\n",
    "create_response = client.create_document_classifier(\n",
    "    InputDataConfig=input_data_config, \n",
    "    OutputDataConfig=output_data_config,\n",
    "    DataAccessRoleArn=data_access_role_arn, \n",
    "    DocumentClassifierName='TopicClassifierSept7', \n",
    "    LanguageCode='en'\n",
    ")\n",
    "print(\"Create response: %s\\n\", create_response)\n",
    "\n",
    "# Check the status of the classifier\n",
    "describe_response = client.describe_document_classifier(\n",
    "    DocumentClassifierArn=create_response['DocumentClassifierArn'])\n",
    "print(\"Describe response: %s\\n\", describe_response)\n",
    "\n",
    "# List all classifiers in account \n",
    "list_response = client.list_document_classifiers()\n",
    "print(\"List response: %s\\n\", list_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d2918d-59e2-4da4-8c19-65a6d732cfc1",
   "metadata": {},
   "source": [
    "####  <font color=\"blue\"> Check the status of the model creation job. Please provide the name of the model that is being built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf82111-b7db-4bea-a4b2-3cc5b838f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = 'TopicClassifierSept7'\n",
    "\n",
    "list_response = client.list_document_classifiers(\n",
    "    Filter={'Status': 'TRAINING'})\n",
    "    \n",
    "print(\"\\nJobs in TRAINING Status:\\n\", list_response)\n",
    "\n",
    "list_response = client.list_document_classifiers(\n",
    "    Filter={'DocumentClassifierName': 'TopicClassifierSept7'})\n",
    "    \n",
    "print(\"\\nStatus of Job:\", job_name, \"\\n\", list_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3686e674-8dd2-43e0-aff2-77982c0d4c36",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\"> Create endpoint.  Make sure to update the model-name in <i><font color=\"darkred\"> ModelArn</i></font> <font color=\"blue\">argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604fab52-8216-4097-9496-85cb77c4086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "import time\n",
    "\n",
    "client = boto3.client('comprehend', region_name='us-east-1')\n",
    "data_access_role_arn = \"arn:aws:iam::XXXXXXXXX:role/service-role/AmazonSageMaker-ExecutionRole-20230418T155781\"\n",
    "\n",
    "response = client.create_endpoint(\n",
    "    EndpointName=\"rdsEmailClassifier\",\n",
    "    ModelArn=\"arn:aws:comprehend:us-east-1:XXXXXXXXX:document-classifier/TopicClassifierSept7\",\n",
    "    DesiredInferenceUnits=1,\n",
    "    DataAccessRoleArn=data_access_role_arn\n",
    ")\n",
    "print(response)\n",
    "'''\n",
    "DocumentClassifierArn=create_response['DocumentClassifierArn']\n",
    "realtime_endpoint_name = \"TopicClassifierSept7\"\n",
    "'''\n",
    "\n",
    "endpoint_arn = response['EndpointArn']\n",
    "describe_response = client.describe_endpoint(EndpointArn=endpoint_arn)\n",
    "while describe_response['EndpointProperties']['Status'] == 'CREATING':\n",
    "    describe_response = client.describe_endpoint(EndpointArn=endpoint_arn)\n",
    "    print(describe_response['EndpointProperties']['Status'])\n",
    "    time.sleep(30)\n",
    "describe_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aea25c-c45c-4dd7-bf49-b17e060b21de",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\"> Test the newly built supervised model above (<i>TopicClassifierSept7</i>). Make sure the endpoint was created before testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71a33d-9c3a-4485-b39d-1b96617283c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boto3\n",
    "\n",
    "# client = boto3.client('comprehend', region_name='us-east-1')\n",
    "\n",
    "cleanedTxt = \"response file plan year rds support please review this issue again submitted an upload on received response file back today and all zeros are still appearing on response file continues to be missing reason codes and eligibility time frames please let me know why this error is still occurring as we need to get this solved to complete reopening by deadline thank you in advance for your assistance\"\n",
    "cleanedTxt = \"unable to access site am unable to access site to complete my reconciliation it appears as though site is down\"\n",
    "cleanedTxt = \"help thank you for your inquiry we're very sorry you're experiencing difficulties registering as account manager to begin your registration click account manager registration page or copy and paste following link into address bar of your browser refer to account manager registration for guidance on this process including step by step instructions\"\n",
    "cleanedTxtx = \"change vendor for cost reporting thank you for your inquiry application id is currently in an incomplete status plan sponsors can only complete payment setup when an application is in any of following statuses approved reconciliation initiated reconciliation cost reporting opened reconciliation cost reporting closed reconciliation request completed as such you cannot complete payment setup for this application at this time after this application has been submitted and approved then you can complete payment setup\"\n",
    "cleanedTxt = \"withdraw application rds application thank you for this information will update application status for application id to withdrawn an email notification will be sent once this action is complete\"\n",
    "cleanedTxt = \"reconciliation issue with app id evansville please instruct me on why am unable to enter costs for this reconciliation manage final costs option is greyed out and not selectable even though finalize covered retirees step is completed\"\n",
    "cleanedtxt = \"request we would like to receive so we can process our overpayment\"\n",
    "cleanedTxt = \"re critical information about reconciliation deadline of your application in it had been determined there's no action needed by group health plan since there are no retirees for plan year we worked with from to close out cy application please refer to two emails for reference please let me know if you have any questions\"\n",
    "# cleanedTxt = \"unable to request payment am unable to request payment at this time it doesn't allow me to confirm cost even after have reviewed it please advise me on how to proceed thank you school business executive cincinnatus csd opt opt\"\n",
    "# cleanedtxt = \"plan id application cost reporter designee to whom can be of assistance our cost reporter for calendar year application is although he was previously assigned as designee st attached he stated he is unable to access application to report cost tried to remove his privilege and re enter him but website won't save and accept his designations to report costs and view send receive files attachment please review and advise as troubleshooting steps within guide has been unsuccessful\"\n",
    "# cleanedTxt = \"upport request ref reporting interim costs cost reporting wanted to make sure taht vendor id is now properly identified on our application so that costs can be uploaded apparently costs had previoulsy been rejected believe that have fixed issue but wanted to confirm before next upload thank you for any assistance you can provide\"\n",
    "cleanedTxt = \"rds reopening request approved this notice is to inform that retiree drug subsidy rds center has approved following reopening appeal tracking number determination that is subject of reopening request reconciliation final payment date reopening request was received by person who requested reopening new reconciliation deadline will allow plan sponsor to submit cost data beyond month timeframe set forth in and reopen pursuant to if plan sponsor wishes to increase amount of its subsidy for this application as stated in its reopening request plan sponsor must recomplete reconciliation by reconciliation deadline specified previously in this email in manner that reflects data and or subsidy amount plan sponsor specified in its request for reopening however plan sponsor is not required to recomplete reconciliation by that deadline if plan sponsor fails to or chooses not to will reinstate previous payment determination and amount of subsidy for application will not change if plan sponsor wishes to recomplete reconciliation read following for important information and steps plan sponsor must take for this application completing reconciliation changed status of this application to reconciliation initiated reconciliation step request list of covered retirees is marked with blue arrow to indicate that it is next step to be completed you are required to submit retiree list as described in to prior to requesting covered retiree list in reconciliation step this retiree list should contain at least one row for each beneficiary for which you are requesting subsidy please complete reconciliation step through step by reconciliation deadline specified in this email for more information go to reconciliation covered retirees after your retiree list has been processed and you have received retiree response file pursuant to matches names and identifying information for individuals submitted as qualifying covered retirees with database to determine which retirees are part eligible individuals who are not enrolled in part plan provides information concerning results of search such as names and other identifying information if necessary to sponsor or to designee please request covered retiree list in reconciliation step covered retiree list should be available within approximately minutes from time of request please download and evaluate covered retirees contained in this list if retiree record that was expected to be on covered retiree list crl is absent or if any of subsidy periods do not match plan sponsor's internal records discrepancy must be resolved before proceeding with remaining steps of reconciliation for more information on resolving discrepancies in covered retiree list go to request covered retiree lists the plan sponsor is required to review and agree to covered retiree list in reconciliation step consistent with sponsor will receive subsidy payment for each qualifying covered retiree enrolled with sponsor of qualified retiree prescription drug plan in plan year plan sponsors may only submit cost data for qualifying covered retirees benefit options and subsidy periods listed in covered retiree list that was downloaded from cost reporting cost data will be duplicated if same report is sent by both mainframe and data entry methods if this occurs one of reports must be deleted zeroed out to resolve duplication before reconciliation is submitted to after all corrected cost reports are received consistent with plan sponsor must close cost reporting and complete remaining steps of reconciliation by reconciliation deadline mainframe cost reports if revised mainframe cost report is submitted by same source that previously submitted cost report then revised cost report is replaced by old cost report if there are mainframe cost reports that plan sponsor wishes to retain plan sponsor does not have to do anything status remains mainframe submitted for more information go to reconciliation data entry cost reports the status of data entry cost reports has changed to data entry update entry required all data entry cost reports must be re saved or re submitted consistent with an account manager or designee may perform this action if they have appropriate privileges account managers with report costs privileges assigned data entry reporting method may access final cost data by selecting either enter update costs action within reconciliation step manage submission of final cost reports or final costs action on application list page designees with report costs privileges assigned data entry reporting method may access cost reports by selecting final costs on application list page for more information go to submit final cost data if further action is required on behalf of plan sponsor to effectuate this decision plan sponsor will be notified by if you need more information contact\"\n",
    "\n",
    "response = client.classify_document(\n",
    "    Text=cleanedTxt, \n",
    "    EndpointArn='arn:aws:comprehend:us-east-1:029309145300:document-classifier-endpoint/rdsEmailClassifier'\n",
    ")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
