{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aaa5400-a5ac-4ec2-ac59-859f72af56d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.6.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.21.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e02ffe-9b79-4c10-8dfd-8bcc84260aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Hardcode so we can use in any notebook\n",
    "module_path = \"/root/HAIP/services\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2549ae45-4d6d-4a6a-8dee-38890701a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sharepoint_transfer.src import main as sharepoint_transfer_svc\n",
    "from data_consolidation.src import main as data_consolidation_svc\n",
    "from feature_engineering.src import main as feature_engineering_svc\n",
    "from model_selection.src import main as model_selection_svc\n",
    "from outcome_analysis.src import main as outcome_analysis_svc\n",
    "from model_training.src import main as model_training_svc\n",
    "from final_fitting.src import main as final_fitting_svc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4146dc4-51e2-4e68-b1f3-4636f8f2ff33",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set Measure Specific Settings\n",
    "\n",
    "These will augment and override settings in \"/root/HAIP/notebooks/services/config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29069647-d283-4af1-b5f4-1f3ee37fc741",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    # Measure specific options\n",
    "    \"MEASURE_SPECIFIC_FILENAME\": \"SEP-1.csv\",\n",
    "    \"FULL_MEASURE_S3_PREFIX\": \"SEP-1\",\n",
    "    \"filter_measure\": \"SEP_1\", # make sure this is _ not -\n",
    "\n",
    "    \"run_save_path\": \"model_runs\",\n",
    "    \"shift_range\": range(30, 50), # for isolation_forest\n",
    "    \n",
    "    # Feature Engineering options\n",
    "    \"backfill_prov_mean\": False, # set to false to not backfill prov mean\n",
    "    \"backfill_lag\": False, # set to false to not backfill lag\n",
    "    \"lag_to_add\": 2, # add lag1/lag2\n",
    "}\n",
    "\n",
    "settings['save_modeling_dataset_path'] = f\"/root/HAIP/data/{settings.get('MEASURE_SPECIFIC_FILENAME')}\"\n",
    "settings['model_dataset_path'] = settings['save_modeling_dataset_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23cf898-eb23-42c3-a2de-c36e30dd3a54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Move Sharepoint files to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bad155-a543-4e6a-ad1a-b8f8c21fdf4d",
   "metadata": {},
   "source": [
    "This is not possible in SageMaker Studio because we are trying to figure out Client ID/Secret for the Sharepoint REST API. For now, run the service locally using your own Office365 username/password"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96178b95-e1d4-4eaf-ab7c-8348d37e5b2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Consolidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93001470-b92c-40c4-b4a3-e523e9534df2",
   "metadata": {},
   "source": [
    "Make sure the measure `settings` are changed.\n",
    "\n",
    "\n",
    "Call `data_consolidation_main.main(settings)`\n",
    "\n",
    "\n",
    "This will download the full-measure-data in S3, load it into a single data frame, normalize the columns, filter to only include `filter_measure` and then upload the result to S3.\n",
    "\n",
    "\n",
    "Result csv and metadata are uploaded to https://s3.console.aws.amazon.com/s3/buckets/haip-measure-specific-data?region=us-east-1&tab=objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80dce529-eb49-4e82-bc63-2b0f16629fd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_consolidation_svc.main(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816349c0-2807-42b1-8aae-2733f48f3712",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905fd4e9-b475-4435-a869-66c991821969",
   "metadata": {},
   "source": [
    "Call `feature_engineering_main.main(settings)`\n",
    "\n",
    "This will download the consolidated measure-specific-data in S3, normalize the columns, and add the new features, then upload the result to S3.\n",
    "Results should also be saved locally automatically, but that is not yet implemented. For now download from the link below and upload the file to SageMaker Studio.\n",
    "\n",
    "\n",
    "Result csv and metadata are uploaded to https://s3.console.aws.amazon.com/s3/buckets/haip-modeling-dataset?region=us-east-1&tab=objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3c01c99-c47a-4c2b-887b-bba8ae1361c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature_engineering_svc.main(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e3d0ec-6ce2-4f86-9324-0a5e5ffac807",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff729e-aec3-4bc5-b633-cf28a8e160a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e20c88a-dff3-4c46-89df-424ecd401c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_feature_importance_settings = {\n",
    "    \"model_type\": \"XGBRegression\", \n",
    "    \"drop_cols\": ['provider_id'],\n",
    "}\n",
    "\n",
    "settings = {**settings, **xgbr_feature_importance_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91353f6b-7837-4bba-99d3-ab5e9389986e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApAAAAHFCAYAAABFHsmJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzde3zP9f//8dt7M+8dDWNzGnOYsVCKMYpJ5pRDEh+yDIVqxgeR0ac5K0oOUenzMeVcciqtJDo5hKacc1oTRiwbxo6v3x9+e3+9bbT3jL1xv14uu9jr+Xq+Xq/H6/3E7nu+Xq/322QYhoGIiIiISD45FHUBIiIiInJ3UYAUEREREZsoQIqIiIiITRQgRURERMQmCpAiIiIiYhMFSBERERGxiQKkiIiIiNhEAVJEREREbKIAKSIiIiI2UYAUkXtaTEwMJpMpz6/hw4fftuNu3ryZ6Ohozp8/f9uOcSv8/PwIDw8v6jIKbN++fURHRxMfH1/UpYjcl4oVdQEiInfC/PnzqVWrllVbhQoVbtvxNm/ezNixYwkPD6dkyZK37TgFtXLlSkqUKFHUZRTYvn37GDt2LCEhIfj5+RV1OSL3HQVIEbkv1KlThwYNGhR1Gbfs8uXLODs7YzKZbmk/9evXL6SK7qyMjIxbPncRuXW6hC0iAhiGwZw5c3jooYdwcXGhVKlSdO3alaNHj1r1W79+PZ06daJSpUo4OztTo0YNBgwYwNmzZy19oqOjeeWVVwCoWrWq5ZL5pk2bADCZTERHR+eq4frLyjmX37/++mv69u1L2bJlcXV1JS0tDYBDhw7Rs2dPvL29MZvN1K5dm3fffTdf53v9sTZt2oTJZGLx4sWMHDmS8uXL4+7uTocOHTh9+jQXLlygf//+lClThjJlytCnTx8uXrxotU+TyURERATvv/8+NWvWxGw2ExgYyNKlS3Mdf8+ePXTq1IlSpUrh7OzMQw89xIIFC6z65NT08ccfM2zYMCpWrIjZbObDDz/kmWeeAaBFixaW1zcmJibfYwRXx8lkMrF371569OiBp6cnPj4+9O3bl+TkZKu+2dnZzJo1y/L3o2TJkjRu3Jg1a9ZY9Vu2bBnBwcG4ubnh7u5O69atiYuLy9eYiNxNNAMpIveFrKwsMjMzrdqKFfu//wIHDBhATEwMkZGRvPHGGyQlJTFu3DiaNGnCr7/+io+PDwBHjhwhODiY559/Hk9PT+Lj43n77bd59NFH2b17N05OTjz//PMkJSUxa9YsPvvsM8qXLw9AYGBggWrv27cv7du35+OPP+bSpUs4OTmxb98+mjRpQuXKlXnrrbcoV64cX331FZGRkZw9e5bXX3+9QMeKioqiRYsWxMTEEB8fz/Dhw+nRowfFihXjwQcfZMmSJcTFxREVFYWHhwczZ8602n7NmjVs3LiRcePG4ebmxpw5cyzbd+3aFYCDBw/SpEkTvL29mTlzJl5eXixcuJDw8HBOnz7NiBEjrPY5atQogoODee+993BwcKBBgwb8/fffREVF8e677/Lwww8DUL16dSB/Y3Stp59+mu7du9OvXz92797NqFGjAPjf//5n6RMeHs7ChQvp168f48aNo3jx4vzyyy9W92BOmjSJMWPG0KdPH8aMGUN6ejpTp07lscce4+effy7w+IvYJUNE5B42f/58A8jzKyMjwzAMw9iyZYsBGG+99ZbVtsePHzdcXFyMESNG5Lnv7OxsIyMjw/jjjz8MwFi9erVl3dSpUw3AOHbsWK7tAOP111/P1V6lShWjd+/euWp/7rnncvVt3bq1UalSJSM5OdmqPSIiwnB2djaSkpJu9JLkeayNGzcagNGhQwerfkOGDDEAIzIy0qq9c+fORunSpXOdl4uLi5GYmGhpy8zMNGrVqmXUqFHD0vavf/3LMJvNRkJCgtX2bdu2NVxdXY3z589b1dSsWbNc9X/yyScGYGzcuPGm53mzMXr99dcNwHjzzTettnnppZcMZ2dnIzs72zAMw/j+++8NwBg9evQNj5OQkGAUK1bMGDRokFX7hQsXjHLlyhndunW7aZ0idxtdwhaR+8JHH33E9u3brb5yZiA///xzTCYTvXr1IjMz0/JVrlw5HnzwQculZ4AzZ84wcOBAfH19KVasGE5OTlSpUgWA/fv335ban376aavlK1eusGHDBp566ilcXV2tam7Xrh1Xrlxh69atBTrWk08+abVcu3ZtANq3b5+rPSkpKddl7JYtW1pmawEcHR3p3r07hw8f5s8//wTg22+/pWXLlvj6+lptGx4eTmpqKlu2bLFqv/78/4mtY9SxY0er5Xr16nHlyhXOnDkDwJdffgnAyy+/fMNjfvXVV2RmZvLcc89ZjYezszPNmze3+jskci/QJWwRuS/Url37hg/RnD59GsMwrILPtapVqwZcvQ8uNDSUkydP8tprr1G3bl3c3NzIzs6mcePGXL58+bbUnnMJPMe5c+fIzMxk1qxZzJo1K89trr/fL79Kly5ttVy8ePGbtl+5cgV3d3dLe7ly5XLtM6ft3LlzVKpUiXPnzuU6J/i/p+LPnTtn1Z5X3xspyBh5eXlZLZvNZgBL37/++gtHR8c8zy3H6dOnAWjYsGGe6x0cNF8j9xYFSBG575UpUwaTycQPP/xgCQ/Xymnbs2cPv/76KzExMfTu3duy/vDhwzYdz2w2Wx6Eudb1wSnH9U8dlypVCkdHR8LCwm44K1a1alWbaiosiYmJN2zLCWpeXl6cOnUqV7+TJ08CV8fjWrY8dV1YY3StsmXLkpWVRWJi4g3DbE7Nn376qWW2U+RepgApIve9J598kilTpnDixAm6det2w345Qeb6kPn+++/n6nv9LNa1/Pz8+O2336zavv3221yXg2/E1dWVFi1aEBcXR7169SyzgfZgw4YNnD592jKbm5WVxbJly6hevTqVKlUCrl7mXrlyJSdPnrR6L86PPvoIV1dXGjdu/I/HudHra8sY5Vfbtm2ZPHkyc+fOZdy4cXn2ad26NcWKFePIkSM2X3IXuRspQIrIfa9p06b079+fPn36sGPHDpo1a4abmxunTp3ixx9/pG7durz44ovUqlWL6tWr8+qrr2IYBqVLl2bt2rWsX78+1z7r1q0LwIwZM+jduzdOTk4EBATg4eFBWFgYr732Gv/5z39o3rw5+/btY/bs2Xh6eua75hkzZvDoo4/y2GOP8eKLL+Ln58eFCxc4fPgwa9eu5dtvvy2018cWZcqU4fHHH+e1116zPIV94MABq7fyef311/n8889p0aIF//nPfyhdujSLFi3iiy++4M0338zX61CnTh0APvjgAzw8PHB2dqZq1ao2jVF+PfbYY4SFhTFhwgROnz7Nk08+idlsJi4uDldXVwYNGoSfnx/jxo1j9OjRHD16lDZt2lCqVClOnz7Nzz//jJubG2PHji1wDSL2RgFSRISrM1SNGzfm/fffZ86cOWRnZ1OhQgWaNm1KUFAQAE5OTqxdu5bBgwczYMAAihUrxhNPPME333xD5cqVrfYXEhLCqFGjWLBgAfPmzSM7O5uNGzcSEhLCK6+8QkpKCjExMUybNo2goCCWL19Op06d8l1vYGAgv/zyC+PHj2fMmDGcOXOGkiVL4u/vT7t27Qr1tbFFx44deeCBBxgzZgwJCQlUr16dRYsW0b17d0ufgIAANm/eTFRUFC+//DKXL1+mdu3azJ8/P98fr1i1alXeeecdZsyYQUhICFlZWZbt8ztGtoiJieHhhx/mv//9LzExMbi4uBAYGEhUVJSlz6hRowgMDGTGjBksWbKEtLQ0ypUrR8OGDRk4cGCBjy1ij0yGYRhFXYSIiNz9TCYTL7/8MrNnzy7qUkTkNtNjYSIiIiJiEwVIEREREbGJ7oEUEZFCoTuiRO4fmoEUEREREZsoQIqIiIiITRQgRURERMQmugdSCkV2djYnT57Ew8PDpo8dExERkaJjGAYXLlygQoUKNn1muwKkFIqTJ0/i6+tb1GWIiIhIARw/ftzycaP5oQAphcLDwwOAY8eOUbp06SKuRgAyMjL4+uuvCQ0NxcnJqajLkf9P42J/NCb2R2Ny56SkpODr62v5OZ5fCpBSKHIuW3t4eFCiRIkirkbg6n/Arq6ulChRQv8B2xGNi/3RmNgfjcmdZ+vtZ3qIRkRERERsogApIiIiIjZRgBQRERERmyhAioiIiIhNFCBFRERExCYKkCIiIiJiEwVIEREREbGJAqSIiIiI2EQBUkRERERsogApIiIiIjZRgBQRERERmyhAioiIiIhNFCBFRERExCYKkCIiIiJiEwVIEREREbGJAqSIiIiI2EQBUkRERERsogApIiIiIjZRgBQRERERmyhAioiIiIhNFCBFRERExCYKkCIiIiJiEwVIEREREbGJAqSIiIiI2EQBUkRERERsogApIiIiIjZRgBQRERERmyhAioiIiIhNFCBFRERExCYKkCIiIiJiEwVIEREREbGJAqSIiIiI2EQBUkRERERsogApIiIiIjZRgBQRERERmyhAioiIiIhNFCBFRERExCYKkCIiIiJiEwXI2ygkJIQhQ4YU2fFjYmIoWbKkZTk6OpqHHnrIqk90dDQ+Pj6YTCZWrVp1wzYRERHJn8mTJ9OwYUM8PDzw9vamc+fOHDx40LI+KSmJQYMGERAQgKurK5UrVyYyMpLk5GRLn19//ZUePXrg6+uLi4sLtWvXZsaMGTc85k8//USxYsVy/ZzPy+7du2nevDkuLi7UqlULAMMwbDrHYjb1lrva8OHDGTRokGV5//79jB07lpUrV9K4cWNKlSqVZ5stGk3eQGYxt8IuXQrA7GjwZhDUif6KtCxTUZcj/5/Gxf5oTOzP3Twm8VPa89133/Hyyy/TsGFDMjMzGT16NKGhoezbtw83NzdOnjzJyZMnmTZtGoGBgfzxxx8MHDiQkydP8umnnwKwc+dOypYty8KFC/H19WXz5s30798fR0dHIiIirI6ZnJzMc889R8uWLTl9+vRN60tJSaFVq1a0aNGC7du3s2vXLsLCwpg9ezajR4/O93kqQN5H3N3dcXd3tywfOXIEgE6dOmEymW7YJiIiIvkXGxtrtTx//ny8vb3ZuXMnzZo1o06dOqxYscKyvnr16kycOJFevXqRmZlJsWLF6Nu3r9U+qlWrxpYtW/jss89yBcgBAwbQs2dPHB0d//HK4aJFi7hy5QoxMTGYzWYqV64MwLvvvktUVFS+f/brEvYdsnDhQho0aICHhwflypWjZ8+enDlzxqrPmjVr8Pf3x8XFhRYtWrBgwQJMJhPnz5/P1zFiYmKoXLkyrq6uPPXUU5w7d85q/bWXsKOjo+nQoQMADg4OmEymPNtERETk1uRcmi5duvRN+5QoUYJixW48t5ecnJxrH/Pnz+fIkSO8/vrr+aply5YtNG/eHLPZbNV+6tQp4uPj87UP0AzkHZOens748eMJCAjgzJkz/Pvf/yY8PJx169YBEB8fT9euXRk8eDDPP/88cXFxDB8+PN/737ZtG3379mXSpEl06dKF2NjYm/5lGj58OH5+fvTp04dTp04BV2cor2+7kbS0NNLS0izLKSkpAJgdDBwdbbuPQm4Ps4Nh9afYB42L/dGY2J+7eUwyMjKslg3DYMiQITRt2pSAgIBc6wHOnTvH+PHjef755/NcD7B161aWL1/O6tWrLX0OHTrEq6++yrfffothGGRlZWEYxg33AVeDYpUqVSx9ru2bmJhI1apV83WeCpB3yLVT0dWqVWPmzJkEBQVx8eJF3N3dee+99wgICGDq1KkABAQEsGfPHiZOnJiv/c+YMYPWrVvz6quvAlCzZk02b96caxo9h7u7u+UBm3Llylna82rLy+TJkxk7dmyu9jH1s3F1zcpXzXJnjG+QXdQlSB40LvZHY2J/7sYxyZkYyvH++++zY8cOJk+enGsdQGpqKtHR0ZQpU4YGDRrk2SchIYHXXnuNZ555hvT0dNatW0dWVhYjR46kS5cuHD58mMOHD3Po0CFSUlLy3EeOv/76CwcHB0uf1NRUyzpbrjwqQN4hcXFxREdHs2vXLpKSksjOvvqPIiEhgcDAQA4ePEjDhg2ttgkKCsr3/vfv389TTz1l1RYcHHzDAHmrRo0axdChQy3LKSkp+Pr6MiHOgUwnx9tyTLGN2cFgfINsXtvhQFq2bkewFxoX+6MxsT9385jsiW5t+X7IkCHs3r2bH3/8Mc+ZvQsXLtC+fXsqVarEqlWrcHZ2ztVn37599O/fn4EDBzJ+/HhL+/nz5zl8+DDHjh1j3rx5AGRnZ2MYBk8//TTr1q2jRYsWufb3ySefkJycTLt27YD/u4II4OPjk+/zVIC8Ay5dukRoaCihoaEsXLiQsmXLkpCQQOvWrUlPTweuTnFfn/xteaTe1sfvb5XZbM51/wRAWraJzLvsibl7XVq26a57ivF+oHGxPxoT+3M3jomTkxOGYTBo0CBWrVrFpk2b8Pf3z9UvJSWF9u3bYzabWbt2La6urrn67N27l9DQUHr37s2UKVOs1nl5ebF7926rtjlz5vDtt9/y6aefUrVqVZycnHLts2nTpkRFRWEYBsWLF7f0KV++PH5+fvk+Tz1EcwccOHCAs2fPMmXKFB577DFq1aqV6wGaWrVqsX37dqu2HTt25PsYgYGBbN261art+mURERG5/V5++WUWLlzI4sWL8fDwIDExkcTERC5fvgxcnXkMDQ3l0qVL/Pe//yUlJcXSJyvr6m1ge/fupUWLFrRq1YqhQ4da1v/111/A1Ydd69SpY/Xl7e2Ns7MzderUwc3t6lvqzZ49m5YtW1pq69mzJ2azmfDwcPbs2cPatWstNdtyCVsB8g6oXLkyxYsXZ9asWRw9epQ1a9ZYTUPD1UfwDxw4wMiRI/n9999Zvnw5MTExQP7uSYiMjCQ2NpY333yT33//ndmzZ9+2y9ciIiJyY3PnziU5OZmQkBDKly9v+Vq2bBlw9T0et23bxu7du6lRo4ZVn+PHjwNXLzX/9ddfLFq0yGr99be7/ZOzZ89a3qIPwNPTk/Xr1/Pnn3/SoEEDhg0bBpDrrYH+kSG3TfPmzY3BgwcbhmEYixcvNvz8/Ayz2WwEBwcba9asMQAjLi7O0n/16tVGjRo1DLPZbISEhBhz5841AOPy5cv5Ot5///tfo1KlSoaLi4vRoUMHY9q0aYanp6dl/euvv248+OCDluWVK1ca1/8VyKstP5KTkw3AOHv2rM3byu2Rnp5urFq1ykhPTy/qUuQaGhf7ozGxPxqTOyfn53dycrJN25kM4w7fPCf5NnHiRN577z3LbyP2LCUlBU9PT86ePYuXl1dRlyNcfWuGdevW0a5duzzvg5GioXGxPxoT+6MxuXNyfn7nvA9lfukhGjsyZ84cGjZsiJeXFz/99BNTp061fUpZRERE5DbTPZB25NChQ3Tq1InAwEDGjx/PsGHDiI6OBqBt27aWjyK8/mvSpElFW7iIiIjcVzQDaUemT5/O9OnT81z34YcfWp7eut7NPhpJREREpLApQN4lKlasWNQliIiIiAC6hC0iIiIiNlKAFBERERGbKECKiIiIiE0UIEVERETEJgqQIiIiImITBUgRERERsYkCpIiIiIjYRAFSRERERGyiACkiIiIiNlGAFBERERGbKECKiIiIiE0UIEVERETEJgqQIiIiImITBUgRERERsYkCpIiIiIjYRAFSRERERGyiACkiIiIiNlGAFBERERGbKECKiIiIiE0UIEVERETEJgqQIiIiImITBUgRERERsYkCpIiIiIjYRAFSRERERGyiACkiIiIiNlGAFBERERGbKECKiIiIiE0UIEVERETEJgqQIiIiImITBUgRERERsYkC5F0mJCSEIUOGFHUZIiIiBfL999/ToUMHKlSogMlkYtWqVVbrT58+Tb9+/ejTpw+enp60adOGQ4cO5bkvwzBo27ZtnvtJSEigQ4cOuLm5UaZMGSIjI0lPT79pbX///TdhYWF4enri6elJWFgY58+fv7UTvkcVK+oCpGhduXKFgQMHsnPnTvbv38+TTz6Z6x+hLRpN3kBmMbdCrFAKyuxo8GYQ1In+irQsU1GXI/+fxsX+aEzujPgp7QG4dOkSDz74IH369OHpp5+26mMYBp07d6ZYsWJERUXRpk0bZs2axRNPPMG+fftwc7P++fLOO+9gMuUes6ysLNq3b0/ZsmX58ccfOXfuHL1798YwDGbNmnXDGnv27Mmff/5JbGwsAP379ycsLIy1a9fe6unfcxQg73NZWVm4uLgQGRnJihUrirocERG5x7Vt25a2bdvmue7QoUNs3bqVuLg4/vjjDwICApgzZw7e3t4sWbKE559/3tL3119/5e2332b79u2UL1/eaj9ff/01+/bt4/jx41SoUAGAt956i/DwcCZOnEiJEiVyHXv//v3ExsaydetWGjVqBMC8efMIDg7m4MGDBAQEFNZLcE/QJey72MKFC2nQoAEeHh6UK1eOnj17cubMGas+a9aswd/fHxcXF1q0aMGCBQswmUyWKXk3Nzfmzp3LCy+8QLly5YriNERERABIS0sDwNnZ2dLm6OhI8eLF+fHHHy1tqamp9OjRg9mzZ+f5s2vLli3UqVPHEh4BWrduTVpaGjt37szz2Fu2bMHT09MSHgEaN26Mp6cnmzdvvuVzu9coQN7F0tPTGT9+PL/++iurVq3i2LFjhIeHW9bHx8fTtWtXOnfuzK5duxgwYACjR48uuoJFRERuolatWlSpUoUxY8Zw8eJF0tPTmTJlComJiZw6dcrS79///jdNmjShU6dOee4nMTERHx8fq7ZSpUpRvHhxEhMTb7iNt7d3rnZvb+8bbnM/0yXsu1jfvn0t31erVo2ZM2cSFBTExYsXcXd357333iMgIICpU6cCEBAQwJ49e5g4ceItHzstLc3ymyJASkoKAGYHA0dH45b3L7fO7GBY/Sn2QeNifzQmd0ZGRkae7ZmZmVbrli1bxgsvvECvXr1wdHSkZcuWtGnTxrKPtWvX8u233/Lzzz9bbXftfrKzs/M8pmEYZGVl5VlLVlbWDbfJzs6+Yf13u4KelwLkXSwuLo7o6Gh27dpFUlKS5R9MQkICgYGBHDx4kIYNG1ptExQUVCjHnjx5MmPHjs3VPqZ+Nq6uWYVyDCkc4xtkF3UJkgeNi/3RmNxe69aty7N9586dODk5WbWNHz+eS5cukZmZiaenJ6+88go1atRg3bp1zJ8/nyNHjlCmTBmrbbp3707t2rWZOHEiFy5c4NChQ1bHvHjxIhkZGcTHx+dZy5kzZzhx4kSudSdPnuT06dM3rP9ul5qaWqDtFCDvUpcuXSI0NJTQ0FAWLlxI2bJlSUhIoHXr1pa3KTAMI9fTaYZROL9hjxo1iqFDh1qWU1JS8PX1ZUKcA5lOjoVyDLk1ZgeD8Q2yeW2HA2nZerLUXmhc7I/G5M7YE906z/ZHHnmEdu3aWbVlZGSwfv16WrVqRXx8PEeOHOGdd96hVatWPPzww5w9e9aq/8MPP8y0adNo3749VatWxcHBgU8//ZT69etbHrBZvnw5ZrOZF198Mc+HaKpWrcrs2bMpW7asZfLl559/JjU1lf79+9+zD9HkXEG0lQLkXerAgQOcPXuWKVOm4OvrC8COHTus+tSqVSvXb0zX9ykos9mM2WzO1Z6WbSJTb4NhV9KyTXprEjukcbE/GpPbK2eW8eLFixw+fNjSfvz4cfbu3Uvp0qWpXLkyn3zyCaVKlSIxMZEvv/ySYcOG0blzZ0vI9PX1tfzcu1bVqlWpWbMmAO3atSMwMJC+ffsydepUkpKSePXVV3nhhRfw8vICrobD5557jg0bNlCxYkXq1atHmzZtePHFF3n//fcBePHFF3nyySepU6fObX1titL1s7/5pYdo7lKVK1emePHizJo1i6NHj7JmzRrGjx9v1WfAgAEcOHCAkSNH8vvvv7N8+XJiYmIArGYm9+3bZ7kMnpyczK5du9i1a9edPB0REblP7Nixg/r161O/fn0Ahg4dSv369fnPf/4DwKlTp+jTpw8REREMHTqUsLAwlixZYtMxHB0d+eKLL3B2dqZp06Z069aNzp07M23aNEuf1NRUDh48aHUP4KJFi6hbt67lCl+9evX4+OOPC+Gs70GG3FWaN29uDB482DAMw1i8eLHh5+dnmM1mIzg42FizZo0BGHFxcZb+q1evNmrUqGGYzWYjJCTEmDt3rgEYly9ftvSpUqWKAeT6skVycrIBGGfPni2cE5Vblp6ebqxatcpIT08v6lLkGhoX+6MxsT8akzsn5+d3cnKyTdvpEvZdZtOmTZbve/ToQY8ePazWG9fd49ixY0c6duxoWZ44cSKVKlWyeo+t+Pj421KriIiI3JsUIO9xc+bMoWHDhnh5efHTTz8xdepUIiIiirosERERuYspQN7jDh06xIQJE0hKSqJy5coMGzaMUaNGFXVZIiIichdTgLzHTZ8+nenTpxd1GSIiInIP0VPYIiIiImITBUgRERERsYkCpIiIiIjYRAFSRERERGyiACkiIiIiNlGAFBERERGbKECKiIiIiE0UIEVERETEJgqQIiIiImITBUgRERERsYkCpIiIiIjYRAFSRERERGyiACkiIiIiNlGAFBERERGbKECKiIiIiE0UIEVERETEJgqQIiIiImITBUgRERERsYkCpIiIiIjYRAFSRERERGyiACkiIiIiNlGAFBERERGbKECKiIiIiE0UIEVERETEJgqQIiIiImITBUgRERERsYkCpIiIiIjYRAFSRERERGyiACkiIiIiNlGAFBERERGbKECKiIiIiE0UIO8yISEhDBkypKjLEBvMnTuXevXqUaJECUqUKEFwcDBffvmlZf2AAQOoXr06Li4ulC1blk6dOnHgwAGrfWzYsIEmTZrg4eFB+fLlGTlyJJmZmTc9blpaGh988AHly5fHzc2Njh078ueff96WcxQRkftLsaIuQIrWpk2bmD59Oj///DMpKSn4+/vzyiuv8OyzzxZof40mbyCzmFshV3n3ip/SnkqVKjFlyhRq1KgBwIIFC+jUqRNxcXE88MADPPLIIzz77LNUrlyZpKQkouaQYKQAACAASURBVKOjCQ0N5dixYzg6OvLbb7/Rrl07Ro8ezUcffcSJEycYOHAgWVlZTJs27YbHHjZsGNu2bWPhwoX4+PgwbNgwnnzySXbu3Imjo+OdeglEROQepBnI+9zmzZupV68eK1as4LfffqNv374899xzrF27tqhLu2d06NCBdu3aUbNmTWrWrMnEiRNxd3dn69atAPTv359mzZrh5+fHww8/zIQJEzh+/Djx8fEALF26lHr16vGf//yHGjVq0Lx5cyZPnsy7777LhQsX8jxmcnIy8+fPp0+fPrRs2ZL69euzcOFCdu/ezTfffHOnTl1ERO5RCpB3sYULF9KgQQM8PDwoV64cPXv25MyZM1Z91qxZg7+/Py4uLrRo0YIFCxZgMpk4f/48AFFRUYwfP54mTZpQvXp1IiMjadOmDStXriyKU7rnZWVlsXTpUi5dukRwcHCu9ZcuXWL+/PlUrVoVX19f4OqlaGdnZ6t+Li4uXLlyhZ07d+Z5nJ07d5KRkcFDDz1kaatQoQJ16tRh8+bNhXhGIiJyP1KAvIulp6czfvx4fv31V1atWsWxY8cIDw+3rI+Pj6dr16507tyZXbt2MWDAAEaPHv2P+01OTqZ06dK3sfL7z+7du3F3d8dsNjNw4EBWrlxJYGCgZf2cOXNwd3fH3d2d2NhY1q9fT/HixQFo3bo1mzdvZsmSJWRlZXHixAkmTJgAwKlTp/I8XmJiIsWLF8fd3d2q3cfHh8TExNt0liIicr/QPZB3sb59+1q+r1atGjNnziQoKIiLFy/i7u7Oe++9R0BAAFOnTgUgICCAPXv2MHHixBvu89NPP2X79u28//77Nz12WloaaWlpluWUlBQAzA4Gjo7GrZzWPSUjIwO4Oj7bt28nOTmZzz77jN69e/PNN99YQmS3bt0ICQkhMTGRt99+m2eeeYbvvvsOZ2dnWrRowZQpUxg4cCBhYWGYzWaioqL48ccfMQzDcoxrXfuAzbXrs7Ozb7iN3Bk5r73GwH5oTOyPxuTOKehrrAB5F4uLiyM6Oppdu3aRlJREdnY2AAkJCQQGBnLw4EEaNmxotU1QUNAN97dp0ybCw8OZN28eDzzwwE2PPXnyZMaOHZurfUz9bFxdswpwNvemdevW5Wpr2rQpX331FSNGjOCll17KtT48PJxevXoRHR1Ns2bNAKhZsyYLFizg77//xs3NzXKrwsmTJ/M8xh9//EF6ejoXL15k/fr1lvYjR45QpkyZPLeRO+vacRH7oDGxPxqT2y81NbVA2ylA3qUuXbpEaGgooaGhLFy4kLJly5KQkEDr1q1JT08HwDAMTCaT1XaGkffs4HfffUeHDh14++23ee655/7x+KNGjWLo0KGW5ZSUFHx9fZkQ50Cmk57wzbEnunWe7TNmzMDHx4d27drlWpeeno6DgwOBgYF5rgeIjo7G19eXiIiIPJ+obtq0KePHj2fXrl2MHTsWJycnTp06RUJCArNnzyY0NPTWTkwKLCMjg/Xr19OqVSucnJyKuhxBY2KPNCZ3Ts4VRFspQN6lDhw4wNmzZ5kyZYrlYYsdO3ZY9alVq1aumabr+8DVmccnn3ySN954g/79++fr+GazGbPZnKs9LdtEZpYpjy3uT05OTkRFRdG2bVt8fX25cOECS5cu5bvvviM2Npbjx4+zbNkyQkNDKVu2LCdOnOCNN97AxcWFDh06WP7jnDp1Km3atMHBwYHPPvuMqVOnsnz5csvDNSdOnKBly5Z89NFHBAUFUaZMGfr06cP8+fN54okn8Pb2Zvjw4dStW5c2bdrobXzsgJOTk34w2hmNif3RmNx+BX199RDNXapy5coUL16cWbNmcfToUdasWcP48eOt+gwYMIADBw4wcuRIfv/9d5YvX05MTAyAZWZy06ZNtG/fnsjISJ5++mkSExNJTEwkKSnpTp/SPev06dOEhYUREBBAy5Yt2bZtG7GxsbRq1QpnZ2d++OEH2rVrR40aNejWrRtubm5s3rwZb29vyz6+/PJLHnvsMRo0aMAXX3zB6tWr6dy5s2V9RkYGBw8etLoUMW3aNBo1akTPnj1p2rQprq6urF27VuFRRERunSF3lebNmxuDBw82DMMwFi9ebPj5+Rlms9kIDg421qxZYwBGXFycpf/q1auNGjVqGGaz2QgJCTHmzp1rAMbly5cNwzCM3r17G0Cur+bNm9tUV3JysgEYZ8+eLbRzlVuTnp5urFq1ykhPTy/qUuQaGhf7ozGxPxqTOyfn53dycrJN2+kS9l1m06ZNlu979OhBjx49rNYb193j2LFjRzp27GhZnjhxIpUqVbJc+oyJibHMSoqIiIjkhwLkPW7OnDk0bNgQLy8vfvrpJ6ZOnUpERERRlyUiIiJ3MQXIe9yhQ4eYMGECSUlJVK5cmWHDhjFq1KiiLktERETuYgqQ97jp06czffr0oi5DRERE7iF6CltEREREbKIAKSIiIiI2UYAUEREREZsoQIqIiIiITRQgRURERMQmCpAiIiIiYhMFSBERERGxiQKkiIiIiNhEAVJEREREbKIAKSIiIiI2KbQAef78+cLalYiIiIjYsQIFyDfeeINly5ZZlrt164aXlxcVK1bk119/LbTiRERERMT+FChAvv/++/j6+gKwfv161q9fz5dffknbtm155ZVXCrVAEREREbEvxQqy0alTpywB8vPPP6dbt26Ehobi5+dHo0aNCrVAEREREbEvBZqBLFWqFMePHwcgNjaWJ554AgDDMMjKyiq86kRERETE7hRoBrJLly707NkTf39/zp07R9u2bQHYtWsXNWrUKNQCRURERMS+FChATp8+HT8/P44fP86bb76Ju7s7cPXS9ksvvVSoBYqIiIiIfSlQgHRycmL48OG52ocMGXLLBYmIiIiIfSvw+0B+/PHHPProo1SoUIE//vgDgHfeeYfVq1cXWnEiIiIiYn8KFCDnzp3L0KFDadu2LefPn7c8OFOyZEneeeedQi1QREREROxLgQLkrFmzmDdvHqNHj8bR0dHS3qBBA3bv3l1oxYmIiIiI/SlQgDx27Bj169fP1W42m7l06dItFyUiIiIi9qtAAbJq1ars2rUrV/uXX35JYGDgLRclIiIiIvarQE9hv/LKK7z88stcuXIFwzD4+eefWbJkCZMnT+bDDz8s7BpFRERExI4UKED26dOHzMxMRowYQWpqKj179qRixYrMmDGDf/3rX4Vdo4iIiIjYEZsDpGEYJCQk0KtXL1544QXOnj1LdnY23t7et6M+EREREbEzNt8DaRgG/v7+/PnnnwCUKVNG4VFERETkPmJzgHRwcLB8BraIiIiI3H8K9BT2m2++ySuvvMKePXsKux4RERERsXMFeoimV69epKam8uCDD1K8eHFcXFys1iclJRVKcSIiIiJifwoUIPVxhSIiIiL3rwIFyN69exd2HSJ3lcmTJ/PZZ59x4MABXFxcaNKkCW+88QYBAQGWPomJibzyyiusX7+eCxcuEBAQQFRUFF27drX08fPz448//rDa98iRI5kyZcoNj20YBmPHjuWDDz7g77//plGjRrz77rs88MADhX+iIiIieShQgExISLjp+sqVKxeoGCl8JpOJlStX0rlzZ+Lj46latSpxcXE89NBDAPz0008MHDiQAwcO0L59e1atWpVnW341mryBzGJut+t07EL8lPZ89913vPzyyzRs2JDMzExGjx5NaGgo+/btw83t6vmHhYWRnJzMmjVrKFOmDIsXL6Z79+7s2LHD6qNAx40bxwsvvGBZdnd3v+nx33zzTd5++21iYmKoWbMmEyZMoFWrVhw8eBAPD4/bc9IiIiLXKFCA9PPzw2Qy3XB9VlZWgQuS28fX15dTp05RpkwZS9vQoUN56KGH+PLLLy3BJa82sRYbG2u1PH/+fLy9vdm5cyfNmjUDYMuWLcydO5egoCAAxowZw/Tp0/nll1+sAqSHhwflypXL13ENw+Cdd95h9OjRdOnSBYAFCxbg4+PD4sWLGTBgQGGcnoiIyE0V6CnsuLg4fvnlF8vXtm3beO+996hZsyaffPJJYddokZ6eftv2fT9wdHSkXLlyFCv2f783HDlyhMcff5xKlSpRsmTJG7bJzSUnJwNQunRpS9ujjz7KsmXLSEpKIjs7m6VLl5KWlkZISIjVtm+88QZeXl489NBDTJw48aZ/z48dO0ZiYiKhoaGWNrPZTPPmzdm8eXPhnpSIiMgNFChAPvjgg1ZfDRo04IUXXmDatGnMnDkz3/sJCQkhIiKCiIgISpYsiZeXF2PGjMEwDODqTOeECRMIDw/H09PTcplv9+7dPP7447i4uODl5UX//v25ePEiAF999RXOzs6cP3/e6liRkZE0b978H2uKiYmhZMmSfP755wQEBODq6krXrl25dOkSCxYswM/Pj1KlSjFo0CCrmdb09HRGjBhBxYoVcXNzo1GjRmzatMmy/ty5c/To0YNKlSrh6upK3bp1WbJkSa7XIzIykhEjRlC6dGnKlStHdHR0vl/PQ4cO0axZM5ydnQkMDGT9+vVW6+Pj4zGZTOzatcvy/blz5+jbty8mk4mYmJg82+TmDMNg6NChPProo9SpU8fSvmzZMjIzM/Hy8sJsNjNgwABWrlxJ9erVLX0GDx7M0qVL2bhxIxEREbzzzju89NJLNzxWYmIiAD4+PlbtPj4+lnUiIiK3W4EuYd9IzZo12b59u03bLFiwgH79+rFt2zZ27NhB//79qVKliiUsTp06lddee40xY8YAkJqaSps2bWjcuDHbt2/nzJkzPP/880RERBATE8MTTzxByZIlWbFiBf369QOuXlJfvnw548aNy1dNqampzJw5k6VLl3LhwgW6dOlCly5dKFmyJOvWrePo0aM8/fTTPProo3Tv3h24+vng8fHxLF26lAoVKrBy5UratGnD7t278ff358qVKzzyyCOMHDmSEiVK8MUXXxAWFka1atVo1KiR1esxdOhQtm3bxpYtWwgPD6dp06a0atXqpjVnZ2fTpUsXypQpw9atW0lJSWHIkCE37J9zOTsgIIBx48bRvXt3PDw8aNOmjVWbp6dnntunpaWRlpZmWU5JSQHA7GDg6Gjk63W+W2VkZFgtR0ZG8ttvv7Fx40ardVFRUSQlJREbG4uXlxdr1qzhmWee4dtvv6Vu3boAREREWPrXrl0bDw8P/vWvfzFhwgS8vLxyHTszM9Py57XHyvll5tq2nO+vr1eKlsbF/mhM7I/G5M4p6GtcoACZExZyGIbBqVOniI6Oxt/f36Z9+fr6Mn36dEwmEwEBAezevZvp06dbAuTjjz/O8OHDLf3nzZvH5cuX+eijjywPK8yePZsOHTrwxhtv4OPjQ/fu3Vm8eLElQG7YsIG///6bZ555Jl81ZWRkMHfuXMtMUdeuXfn44485ffo07u7uBAYG0qJFCzZu3Ej37t05cuQIS5Ys4c8//6RChQoADB8+nNjYWObPn8+kSZOoWLGi1XkMGjSI2NhYPvnkE6sAWa9ePV5//XUA/P39mT17Nhs2bPjHAPnNN9+wf/9+4uPjqVSpEgCTJk2ibdu2efbPuZxtMpnw9PS03IPn5uaWqy0vkydPZuzYsbnax9TPxtX13r4Hdt26dZbvP/jgA7Zt28akSZP47bff+O233wA4deoUc+bMYebMmVy5coUTJ07wyCOPUKVKFaKionjxxRfz3PelS5cA+Pjjj6lZs2au9TmzjCtWrKBatWqW9j179uDm5mZVW47rZ6LFPmhc7I/GxP5oTG6/1NTUAm1XoABZsmTJXA/RGIaBr68vS5cutWlfjRs3ttpXcHAwb731lmVGpUGDBlb99+/fz4MPPmgJjwBNmzYlOzubgwcP4uPjw7PPPktwcDAnT56kQoUKLFq0iHbt2lGqVKl81eTq6mp1mdHHxwc/Pz+rB0p8fHw4c+YMAL/88guGYeT6gZ+WlmaZRcrKymLKlCksW7aMEydOWGbwrj0PuBogr1W+fHnLcW5m//79VK5c2RIe4eprebuMGjWKoUOHWpZTUlLw9fVlQpwDmU6Ot+249mBPdGsMw2DIkCHs2rWL77//PtcvTrt37wagefPm1K5d29L+7rvvUqlSJdq1a5fnvr/44gsAunTpkue7GRiGQXR0NFeuXLHsIz09nd69ezNp0iSr/WZkZLB+/XpatWqFk5PTrZ20FBqNi/3RmNgfjcmdc/2kYH4VKEBu3LjRatnBwYGyZctSo0YNqwc0CsP1AcswjBs+AZ7THhQURPXq1Vm6dCkvvvgiK1euZP78+fk+5vV/WU0mU55t2dnZwNXLx46OjuzcuRNHR+vwlBM633rrLaZPn84777xD3bp1cXNzY8iQIbkemLjZcW4m577R67e9XcxmM2azOVd7WraJzKzbd1x74OTkxEsvvcTixYtZvXo1pUuXtnw2vKenJy4uLtStW5caNWoQERHBtGnT8PLyYtWqVXzzzTd8/vnnODk5sWXLFrZu3UqLFi3w9PRk+/bt/Pvf/6Zjx45Wv8DUqlWLyZMn89RTTwEwZMgQJk+eTK1atfD392fSpEm4uroSFhaW53+0Tk5O+g/YDmlc7I/GxP5oTG6/gr6+BUp7JpOJJk2a5AqLmZmZfP/995a3McmPrVu35lr29/fPFcRyBAYGsmDBAi5dumQJlz/99BMODg5WM4A9e/Zk0aJFVKpUCQcHB9q3b5/vmmxVv359srKyOHPmDI899liefX744Qc6depEr169gKuh89ChQ1azU7ciMDCQhIQEy6wrXH0bGbk95s6dC5Drier58+cTHh6Ok5MT69at49VXX6VDhw5cvHiRGjVqsGDBAsssodlsZtmyZYwdO5a0tDTLvb8jRoyw2ufBgwctT3kDjBgxgsuXL/PSSy9Z3kj866+/1ntAiojIHVOgANmiRQtOnTqFt7e3VXtycjItWrSw6X0gjx8/ztChQxkwYAC//PILs2bN4q233rph/2effZbXX3+d3r17Ex0dzV9//cWgQYMICwuzejL12WefZezYsUycOJGuXbvi7Oxs+4nmU82aNXn22Wd57rnneOutt6hfvz5nz561PCzRrl07atSowYoVK9i8eTOlSpXi7bffJjExsdAC5BNPPEFAQIClhpSUFEaPHl0o+5bc8prxvZ6/vz8rVqy44fqHH3441y9Q+TmWyWQiOjrapif0RUREClOBAuSNLiOfO3cu1yXnf/Lcc89x+fJlgoKCcHR0ZNCgQfTv3/+G/V1dXfnqq68YPHgwDRs2xNXVlaeffpq3337bqp+/vz8NGzZk+/btd+Szu+fPn8+ECRMYNmwYJ06cwMvLi+DgYMts02uvvcaxY8do3bo1rq6u9O/fn86dO1vNLN0KBwcHVq5cSb9+/QgKCsLPz4+ZM2fSpk2bQtl/fm0b1TLPp4dFRETk3mEy8jOV8v/lfPLF6tWradOmjdU9cFlZWfz2228EBATk+pSOGwkJCeGhhx66IwFPbq+UlBQ8PT05e/asAqSdyMjIYN26dbRr1073ENkRjYv90ZjYH43JnZPz8zs5OZkSJUrkezubZiBz3hPQMAw8PDxwcXGxrCtevDiNGze2+kxfEREREbn32BQgc55k9vPzY/jw4TZfrrYHbdu25YcffshzXVRUFFFRUXe4ovxZtGjRDT/nuEqVKuzdu/cOVyQiIiL3qwLdA5nzRte36tqP+rtTPvzwQy5fvpznums/x9jedOzY0eoNx6+l6X0RERG5kwr8po2ffvopy5cvJyEhIdd7Gf7yyy+3XNjtUrFixaIuoUA8PDz0Ni0iIiJiFxwKstHMmTPp06cP3t7exMXFERQUhJeXF0ePHr3hR+eJiIiIyL2hQAFyzpw5fPDBB8yePZvixYszYsQI1q9fT2RkZKG9LY2IiIiI2KcCBciEhASaNGkCgIuLCxcuXAAgLCyMJUuWFF51IiIiImJ3ChQgy5UrZ/ns3ypVqlg+TePYsWP5+oQOEREREbl7FShAPv7446xduxaAfv368e9//5tWrVrRvXt3nnrqqUItUERERETsS4Gewv7ggw/Izs4GYODAgZQuXZoff/yRDh06MHDgwEItUERERETsS4ECpIODAw4O/zd52a1bN7p161ZoRYmIiIiI/SrQJWyAH374gV69ehEcHMyJEycA+Pjjj/nxxx8LrTgRERERsT8FCpArVqygdevWuLi4EBcXR1paGgAXLlxg0qRJhVqgiIiIiNiXAgXICRMm8N577zFv3jyrj9Fr0qSJXX8KjYiIiIjcugIFyIMHD9KsWbNc7SVKlOD8+fO3XJSIiIiI2K8CBcjy5ctz+PDhXO0//vgj1apVu+WiRERERMR+FShADhgwgMGDB7Nt2zZMJhMnT55k0aJFDB8+nJdeeqmwaxQRERERO1Kgt/EZMWIEycnJtGjRgitXrtCsWTPMZjPDhw8nIiKisGsUERERETtiU4A8evQoVatWxWQyMXHiREaPHs2+ffvIzs4mMDAQd3f321WniIiIiNgJmy5h+/v789dff1mW+/Tpg6+vL0FBQQqPIiIiIvcJmwKkYRhWy+vWrePSpUuFWpCIiIiI2LcCfxKNiIiIiNyfbAqQJpMJk8mUq01ERERE7h82PURjGAbh4eGYzWYArly5wsCBA3Fzc7Pq99lnnxVehSIiIiJiV2wKkL1797Za7tWrV6EWIyIiIiL2z6YAOX/+/NtVh4iIiIjcJfQQjYiIiIjYRAFSRERERGyiACkiIiIiNlGAFBERERGbKECKiIiIiE0UIEVERETEJgqQIiIiImITBUi5702ePJmGDRvi4eGBt7c3nTt35uDBg5b1SUlJDBo0iICAAFxdXalcuTKRkZEkJydb+vz666/06NEDX19fXFxcqF27NjNmzPjHY//999+EhYXh6emJp6cnYWFhnD9//racp4iISGFRgJT73nfffcfLL7/M1q1bWb9+PZmZmYSGhnLp0iUATp48ycmTJ5k2bRq7d+8mJiaG2NhY+vXrZ9nHzp07KVu2LAsXLmTv3r2MHj2aUaNGMXv27Jseu2fPnuzatYvY2FhiY2PZtWsXYWFht/V8RUREbpVNn0Qj8k8aTd5AZjG3f+5oJ+KntCc2Ntaqbf78+Xh7e7Nz506aNWtGnTp1WLFihWV99erVmThxIr169SIzM5NixYrRt29fq31Uq1aNLVu28NlnnxEREZHnsffv309sbCxbt26lUaNGAMybN4/g4GAOHjxIQEBAIZ+tiIhI4dAMZD6kp6cXdQlyB+Vcmi5duvRN+5QoUYJixW78O1hycvJN97FlyxY8PT0t4RGgcePGeHp6snnz5gJULiIicmfclwEyJCSEiIgIIiIiKFmyJF5eXowZMwbDMADw8/NjwoQJhIeH4+npyQsvvADA7t27efzxx3FxccHLy4v+/ftz8eJFAL766iucnZ1z3b8WGRlJ8+bN/7GmmJgYSpYsyeeff265165r165cunSJBQsW4OfnR6lSpRg0aBBZWVmW7dLT0xkxYgQVK1bEzc2NRo0asWnTJsv6c+fO0aNHDypVqoSrqyt169ZlyZIluV6PyMhIRowYQenSpSlXrhzR0dEFeWnveoZhMHToUB599FHq1KmTZ59z584xfvx4BgwYcMP9bNmyheXLl9+0T2JiIt7e3rnavb29SUxMtL14ERGRO+S+vYS9YMEC+vXrx7Zt29ixYwf9+/enSpUqlrA4depUXnvtNcaMGQNAamoqbdq0oXHjxmzfvp0zZ87w/PPPExERQUxMDE888QQlS5ZkxYoVlnvjsrKyWL58OePGjctXTampqcycOZOlS5dy4cIFunTpQpcuXShZsiTr1q3j6NGjPP300zz66KN0794dgD59+hAfH8/SpUupUKECK1eupE2bNuzevRt/f3+uXLnCI488wsiRIylRogRffPEFYWFhVKtWzWrma8GCBQwdOpRt27axZcsWwsPDadq0Ka1atcqz1rS0NNLS0izLKSkpAJgdDBwdDRtHo+hkZGRYLUdGRvLbb7+xcePGXOvg6nm2a9eO2rVrExUVlWefvXv30qlTJ0aPHk1ISEiefQDLLwLXrzcMg+zs7Btul18529/qfqRwaVzsj8bE/mhM7pyCvsYmI2fa7T4SEhLCmTNn2Lt3LyaTCYBXX32VNWvWsG/fPvz8/Khfvz4rV660bDNv3jxGjhzJ8ePHcXO7eo/funXr6NChAydPnsTHx4fBgwezZ88eNmzYAMDXX39Nhw4dSExMpFSpUjetKSYmhj59+nD48GGqV68OwMCBA/n44485ffo07u7uALRp0wY/Pz/ee+89jhw5gr+/P3/++ScVKlSw7OuJJ54gKCiISZMm5Xms9u3bU7t2baZNm2Z5PbKysvjhhx8sfYKCgnj88ceZMmVKnvuIjo5m7NixudoXL16Mq6vrTc/VXn3wwQds27aNSZMm4ePjk2v95cuXiY6Oxmw2M2bMGIoXL56rz/HjxxkzZgytWrWiV69eNz3eN998w//+9z8WL15s1d6zZ0/69etHy5Ytb+2ERERE/kFqaio9e/a03JqVX/ftDGTjxo0t4REgODiYt956yzIr1KBBA6v++/fv58EHH7SER4CmTZuSnZ3NwYMH8fHx4dlnnyU4OJiTJ09SoUIFFi1aRLt27f4xPOZwdXW1hEcAHx8f/Pz8LOExp+3MmTMA/PLLLxiGQc2aNa32k5aWhpeXF3B1lmvKlCksW7aMEydOWGYOrz0PgHr16lktly9f3nKcvIwaNYqhQ4dallNSUvD19WVCnAOZTo75Ol97sCe6NYZhMGTIEHbt2sX333+Pv79/rn4pKSm0b98eHx8f1qxZk2dI3rt3L/3796dfv343DN7Xqlq1KrNnz6Zs2bI0bNgQgJ9//pnU1FT69+9/yw/RZGRksH79elq1aoWTk9Mt7UsKj8bF/mhM7I/G5M7Jx8exJgAAIABJREFUuYJoq/s2QP6T6wOWYRhWgfNaOe1BQUFUr16dpUv/X3v3HldVlfdx/IsIh4uCiSKgBF6yxvGOVuooaiN4zdLMzLxMdtFEUhlrrOlJqydzCkMrTa1QR0fMUcuZyMt4KxRLURO1cVBBJ8MczTheua7nD8fzdAIvW7nzeb9e5/XyrL32Omvtn8CXvfc5JGjMmDFatWqV4uPjb/g1f/lF4uLiUmRbQUGBJKmgoECurq5KSUmRq6tzaLsSOmNjY/X2228rLi5OLVq0kLe3t8aPH1/ojUHXep2i2Gw22Wy2Qu3ZBS7Kyy/6OJVHbm5ueuaZZ/SXv/xFn376qWrXrq3Tp09Lknx9feXp6amzZ8+qT58+unDhgpYsWaKLFy/q4sWLkqS6devK1dVV+/fvV0REhCIiIjRp0iTHGK6urqpbt66ky+Fw+PDh2rBhg+rXr6+WLVuqZ8+eGjNmjObOnStJGjNmjPr27XvV+y9vdo18Ay5/qEv5Q03KH2pS8m72+FbZALl9+/ZCz++4445CQeyKZs2aaeHChTp//rwjXG7dulXVqlVzOgP46KOPasmSJWrQoIGqVaumPn36lNga2rRpo/z8fJ08eVKdO3cuss+XX36p/v37Oy6nFhQUKC0tTb/61a9KbF4VzZw5cyRdvpT/c/Hx8Ro5cqRSUlL01VdfSZKaNGni1Cc9PV2hoaFavny5/vOf/2jJkiVasmSJY3tISIgyMjIkXb5McPDgQaf7TZYsWaLo6GhFRERIku6///7rfnYkAABlrUq+C1u6fK/axIkTdfDgQS1dulTvvPOOnn322av2Hzp0qDw8PDRixAjt27dPmzZt0rhx4zRs2DCn++WGDh2qXbt26X//93/10EMPycPDo8TW0LRpUw0dOlTDhw/XypUrlZ6erh07dmj69OlKTEyUdDnwrF+/Xtu2bdO3336rp59+mnf4/oIxpsjHyJEjJV0OllfrExoaKunyPaFFbb8SHn8+zpV9pMsfFbR48WLZ7XbZ7XYtXrxYtWrVKr3FAwBwE6rsGcjhw4fr4sWLuvvuu+Xq6qpx48bpqaeeump/Ly8vrV27Vs8++6zat28vLy8vDRw4UDNmzHDqd8cdd6h9+/basWOH4uLiSnoZio+P12uvvaaYmBgdP35cfn5+6tChg3r37i1Jeumll5Senq7IyEh5eXnpqaee0gMPPOD0Z/iK01eT73PcfwkAACqnKvsu7NatW5dKwKsq7Ha7fH19derUKQJkOZGbm6vExET17t2be4jKEepS/lCT8oealJ4rP7+tvgu7yl7CBgAAwM0hQJaSXr16qUaNGkU+rvZ5jQAAAOVRlbwH8ud/6q+0fPDBB46Pfvmla/29ZAAAgPKmSgbIslC/fv2yngIAAECx4BI2AAAALCFAAgAAwBICJAAAACwhQAIAAMASAiQAAAAsIUACAADAEgIkAAAALCFAAgAAwBICJAAAACwhQAIAAMASAiQAAAAsIUACAADAEgIkAAAALCFAAgAAwBICJAAAACwhQAIAAMASAiQAAAAsIUACAADAEgIkAAAALCFAAgAAwBICJAAAACwhQAIAAMASAiQAAAAsIUACAADAEgIkAAAALCFAAgAAwBICJAAAACwhQAIAAMASAiQAAAAsIUACAADAEgIkyo3jx4/rsccek5+fn7y8vNS6dWulpKQ4tru4uBT5ePPNN6857uzZs9WwYUN5eHgoLCxMX375ZUkvBQCASq16WU8Alcs90zYor7r3DffPeKOPJOnMmTPq1KmTunXrps8//1z+/v46fPiwatWq5eibmZnptO/nn3+uUaNGaeDAgVcdf9myZRo/frxmz56tTp06ae7cuerVq5cOHDig22+/3eLqAACARIDENeTn58vFxUXVqpX8ierp06crODhY8fHxjrbQ0FCnPgEBAU7PP/30U3Xr1k2NGjW66rgzZszQqFGj9MQTT0iS4uLitHbtWs2ZM0fTpk0rvgUAAFCFcAm7gli0aJH8/PyUnZ3t1D5w4EANHz5ckvS3v/1NYWFh8vDwUKNGjTR16lTl5eU5+s6YMUMtWrSQt7e3goOD9cwzz+jcuXOO7QsWLFCtWrX097//Xc2aNZPNZtPRo0dLZX2rV69Wu3btNGjQIPn7+6tNmzaaP3/+Vfv/8MMP+uyzzzRq1Kir9snJyVFKSooiIiKc2iMiIrRt27ZimzsAAFUNZyAriEGDBik6OlqrV6/WoEGDJEmnTp3S3//+d61Zs0Zr167VY489plmzZqlz5846fPiwnnrqKUnSyy+/LEmqVq2aZs2apdDQUKWnp+uZZ57Rc889p9mzZzte58KFC5o2bZo++OAD+fn5yd/fv8j5ZGdnO4VZu90uSbJVM3J1NTe8rtzcXEnSkSNHNGfOHD377LOaNGmSdu7cqejoaLm6umrYsGGF9vvoo49Us2ZN9evXzzHGL2VmZio/P19+fn5OferUqaPMzMyr7ldZXFlfZV9nRUNdyh9qUv5Qk9Jzs8fYxRhz4z/tUaaeeeYZZWRkKDExUZI0c+ZMzZo1S4cOHVJ4eLh69eqlyZMnO/ovXrxYzz33nL7//vsix1u+fLnGjBmjU6dOSbp8BvJ3v/ud9uzZo1atWl1zLlOmTNHUqVMLtf/lL3+Rl5eX5bU99NBDaty4saZPn+5omz9/vg4dOuTUdsXYsWPVqlUrR0guyo8//qjHH39cb7zxhu666y5H+/Lly7V582a99957lucJAEBlcuHCBT366KPKysqSj4/PDe9HgKxAdu/erfbt2+vo0aOqX7++WrdurYEDB+qll16St7e3CgoK5Orq6uifn5+vS5cu6fz58/Ly8tKmTZv0+uuv68CBA7Lb7crLy9OlS5d07tw5eXt7a8GCBXr66ad16dIlubi4XHMuRZ2BDA4OVrNJCcpzu/E30eybEilJatKkie677z7NnTvXsW3u3LmaNm2aMjIynPZJSkpS9+7dtWPHjmsG3ZycHPn6+mrp0qV64IEHHO0TJ07UN998ow0bNtzwPCui3NxcrV+/Xj169JCbm1tZTwf/RV3KH2pS/lCT0mO321WnTh3LAZJL2BVImzZt1KpVKy1atEiRkZFKTU3V3/72N0lSQUGBpk6dqgEDBhTaz8PDQ0ePHlXv3r01evRovfrqq6pdu7aSkpI0atQop9PXnp6e1w2PkmSz2WSz2Qq1Zxe4KC//+vtfceUbQ6dOnZSWlub0jeLw4cMKCQkp9M1j4cKFCgsLU7t27a47dlhYmDZt2uS47C9JGzZsUP/+/avMNyU3N7cqs9aKhLqUP9Sk/KEmJe9mjy8BsoJ54okn9Pbbb+v48eP67W9/q+DgYElS27ZtdfDgQTVp0qTI/Xbu3Km8vDzFxsY63lX98ccfl9q8r2fChAnq2LGjXn/9dT388MP6+uuvNW/ePM2bN8+pn91u1/LlyxUbG1vkOPfdd58efPBBRUVFSbp8tnHYsGFq166dOnTooHnz5unYsWMaPXp0ia8JAIDKigBZwQwdOlS///3vNX/+fC1atMjR/j//8z/q27evgoODNWjQIFWrVk179+5VamqqXnvtNTVu3Fh5eXl655131K9fP23dulXvv/9+Ga7EWfv27bVq1SpNnjxZr7zyiho2bKi4uDgNHTrUqV9CQoKMMRoyZEiR4xw+fNhxT6ckDR48WKdPn9Yrr7yizMxMNW/eXImJiQoJCSnR9QAAUKkZVDjDhg0ztWvXNpcuXXJqX7NmjenYsaPx9PQ0Pj4+5u677zbz5s1zbJ8xY4YJDAw0np6eJjIy0ixatMhIMmfOnDHGGBMfH298fX1vak5ZWVlGkjl16tTNLwzFKicnx3zyyScmJyenrKeCn6Eu5Q81KX+oSem58vM7KyvL0n6cgayAMjMzNXTo0EL3IEZGRioyMvKq+02YMEETJkxwavv5R+SMHDlSI0eOLNa5AgCAyocAWYH8+OOPWrdunTZu3Kh33323rKcDAACqKAJkBdK2bVudOXNG06dP15133lnW0wEAAFUUAbIC+eXnIQIAAJQF/hY2AAAALCFAAgAAwBICJAAAACwhQAIAAMASAiQAAAAsIUACAADAEgIkAAAALCFAAgAAwBICJAAAACwhQAIAAMASAiQAAAAsIUACAADAEgIkAAAALCFAAgAAwBICJAAAACwhQAIAAMASAiQAAAAsIUACAADAEgIkAAAALCFAAgAAwBICJAAAACwhQAIAAMASAiQAAAAsIUACAADAEgIkAAAALCFAAgAAwBICJAAAACwhQAIAAMASAiQAAAAsIUACAADAEgIkAAAALCFAolw4fvy4HnvsMfn5+cnLy0utW7dWSkqKY/vIkSPl4uLi9Lj33nuvO+6KFSvUrFkz2Ww2NWvWTKtWrSrJZQAAUCVUL+sJoGR07dpVrVu3VlxcXKm+7j3TNiivuvcN9894o4/OnDmjTp06qVu3bvr888/l7++vw4cPq1atWk59e/bsqfj4eMdzd3f3a46dnJyswYMH69VXX9WDDz6oVatW6eGHH1ZSUpLuueceawsDAAAOBMhKJjc3V25ubsU2Xk5OznWD2q2aPn26goODncJhaGhooX42m00BAQE3PG5cXJx69OihyZMnS5ImT56sLVu2KC4uTkuXLr3leQMAUFVxCbsEnT9/XsOHD1eNGjUUGBio2NhYde3aVePHj5ckubi46JNPPnHap1atWlqwYIHj+fPPP6+mTZvKy8tLjRo10ksvvaTc3FzH9ilTpqh169b66KOP1KhRI9lsNo0YMUJbtmzRzJkzHZd7MzIyJEkHDhxQ7969VaNGDdWrV0/Dhg3TqVOnHON17dpVUVFRmjhxourUqaMePXqU3AH6r9WrV6tdu3YaNGiQ/P391aZNG82fP79Qv82bN8vf319NmzbVk08+qZMnT15z3OTkZEVERDi1RUZGatu2bcU6fwAAqhoCZAmaNGmSNm3apFWrVmndunXavHmz0319N6JmzZpasGCBDhw4oJkzZ2r+/Pl6++23nfocOnRIH3/8sVasWKE9e/Zo1qxZ6tChg5588kllZmYqMzNTwcHByszMVHh4uFq3bq2dO3dqzZo1+uGHH/Twww87jbdw4UJVr15dW7du1dy5c2/5OFzPkSNHNGfOHN1xxx1au3atRo8erejoaC1atMjRp1evXlqyZIk2btyo2NhY7dixQ927d1d2dvZVxz1x4oTq1avn1FavXj2dOHGixNYCAEBVwCXsEnLu3Dl9+OGHWrRokeMs3sKFC9WgQQNL4/zxj390/Ds0NFQxMTFatmyZnnvuOUd7Tk6O/vznP6tu3bqONnd3d3l5eTld8p0zZ47atm2r119/3dH20UcfKTg4WP/617/UtGlTSVKTJk30pz/96Zrzys7OdgpvdrtdkmSrZuTqam54fbm5uSooKFBYWJimTp0qSWrevLlSU1M1e/ZsDRkyRJI0YMAAxz533nmnWrVqpSZNmujTTz/Vgw8+eNXx8/Pznc7Y5ubmysXFxamtsrqyxqqw1oqEupQ/1KT8oSal52aPMQGyhBw+fFg5OTnq0KGDo6127dq68847LY3z17/+VXFxcTp06JDOnTunvLw8+fj4OPUJCQlxCo9Xk5KSok2bNqlGjRpFzvdKgGzXrt11x5o2bZoj8P3cH9sUyMsr/7r7X5GYmKhatWqpRo0aSkxMdLTn5eUpLS3Nqe2X6tSpo88++0w2m63I7b6+vtq8ebPT8friiy/k4+NzzXErm/Xr15f1FFAE6lL+UJPyh5qUvAsXLtzUfgTIEmLM9c/Cubi4FOr3898Etm/frkceeURTp05VZGSkfH19lZCQoNjYWKd9vL1v7F3PBQUF6tevn6ZPn15oW2BgoKXxJk+erIkTJzqe2+12BQcH67Xd1ZTn5npD85GkfVMi1b17d3333Xfq3bu3o33jxo1q2rSpU9vPnT59Wj/++KPCw8Ov2qdr1676/vvvnbbPmTNH3bp1u+o+lUlubq7Wr1+vHj16FOsbq3BrqEv5Q03KH2pSeq5cQbSKAFlCmjRpIjc3N23fvl233367JOnMmTP617/+pfDwcElS3bp1lZmZ6dgnLS3N6TeBrVu3KiQkRC+++KKj7ejRozf0+u7u7srPdz4T2LZtW61YsUKhoaGqXv3WSm+z2Yo885dd4KK8fJcbHsfNzU0xMTHq2LGj3nzzTT388MP6+uuv9cEHH2jevHlyc3PTuXPnNGXKFA0cOFCBgYHKyMjQCy+8oDp16mjQoEGOby7Dhw9X/fr1NW3aNEnShAkT1KVLF82YMUP9+/fXp59+qg0bNigpKalKfUNyc3OrUuutKKhL+UNNyh9qUvJu9vjyJpoSUqNGDY0aNUqTJk3Shg0btG/fPo0cOVLVqv3/Ie/evbveffdd7dq1Szt37tTo0aOdCtmkSRMdO3ZMCQkJOnz4sGbNmnXDH4QdGhqqr776ShkZGTp16pQKCgo0duxY/fjjjxoyZIi+/vprHTlyROvWrdPjjz9eKGyWpvbt22vVqlVaunSpmjdvrldffVVxcXEaOnSoJMnV1VWpqanq37+/mjZtqhEjRqhp06ZKTk5WzZo1HeMcO3bMKZB37NhRCQkJio+PV8uWLbVgwQItW7aMz4AEAOAWcQayBL355ps6d+6c7r//ftWsWVMxMTHKyspybI+NjdXvfvc7denSRUFBQZo5c6bTu7T79++vCRMmKCoqStnZ2erTp49eeuklTZky5bqv/fvf/14jRoxQs2bNdPHiRaWnpys0NFRbt27V888/r8jISGVnZyskJEQ9e/Z0Cra34qvJ98nPz8/yfn379lXfvn2L3Obp6am1a9ded4zNmzcXanvooYf00EMPWZ4PAAC4OhdzIzfrodiU1V+IKWl2u12+vr46derUTQVIFL/c3FwlJiaqd+/eXAIqR6hL+UNNyh9qUnqu/PzOysoq9Cbda+ESNgAAACwhQAIAAMAS7oEsZUXdpwcAAFCRcAYSAAAAlhAgAQAAYAkBEgAAAJYQIAEAAGAJARIAAACWECABAABgCQESAAAAlhAgAQAAYAkBEgAAAJYQIAEAAGAJARIAAACWECABAABgCQESAAAAlhAgAQAAYAkBEgAAAJYQIAEAAGAJARIAAACWECABAABgCQESAAAAlhAgAQAAYAkBEgAAAJYQIAEAAGAJARIAAACWECABAABgCQESAAAAlhAgAQAAYAkBEgAAAJYQIAEAAGAJARIAAACWECABAABgCQESAAAAlhAgAQAAYAkBEgAAAJYQIAEAAGAJARIAAACWECABAABgSfWyngAqB2OMJOns2bNyc3Mr49lAknJzc3XhwgXZ7XZqUo5Ql/KHmpQ/1KT02O12Sf//c/xGESBRLE6fPi1JatiwYRnPBAAAWHX27Fn5+vrecH8CJIpF7dq1JUnHjh2z9B8QJcdutys4OFj//ve/5ePjU9bTwX9Rl/KHmpQ/1KT0GGN09uxZBQUFWdqPAIliUa3a5dtpfX19+WIvZ3x8fKhJOURdyh9qUv5Qk9JxMyd+eBMNAAAALCFAAgAAwBLXKVOmTCnrSaBycHV1VdeuXVW9OndGlBfUpHyiLuUPNSl/qEn55mKsvm8bAAAAVRqXsAEAAGAJARIAAACWECABAABgCQESAAAAlhAgcctmz56thg0bysPDQ2FhYfryyy/LekqV1pQpU+Ti4uL0CAgIcGw3xmjKlCkKCgqSp6enunbtqv379zuNcebMGQ0bNky+vr7y9fXVsGHD9NNPP5X2Uiq0L774Qv369VNQUJBcXFz0ySefOG0vrjqkpqYqPDxcnp6eql+/vl555RXLf6+2qrheTUaOHFnoa+fee+916pOdna1x48apTp068vb21v3336/vvvvOqc+xY8fUr18/eXt7q06dOoqOjlZOTk6Jr68imjZtmtq3b6+aNWvK399fDzzwgA4ePOjUp7iO+ZYtWxQWFiYPDw81atRI77//fomvr6ojQOKWLFu2TOPHj9eLL76o3bt3q3PnzurVq5eOHTtW1lOrtH79618rMzPT8UhNTXVs+9Of/qQZM2bo3Xff1Y4dOxQQEKAePXro7Nmzjj6PPvqo9uzZozVr1mjNmjXas2ePhg0bVhZLqbDOnz+vVq1a6d133y1ye3HUwW63q0ePHgoKCtKOHTv0zjvv6K233tKMGTNKfH0V0fVqIkk9e/Z0+tpJTEx02j5+/HitWrVKCQkJSkpK0rlz59S3b1/l5+dLkvLz89WnTx+dP39eSUlJSkhI0IoVKxQTE1Oia6uotmzZorFjx2r79u1av3698vLyFBERofPnzzv6FMcxT09PV+/evdW5c2ft3r1bL7zwgqKjo7VixYpSX3OVYoBbcPfdd5vRo0c7td11113mD3/4QxnNqHJ7+eWXTatWrYrcVlBQYAICAswbb7zhaLt06ZLx9fU177//vjHGmAMHDhhJZvv27Y4+ycnJRpL55z//WbKTr6QkmVWrVjmeF1cdZs+ebXx9fc2lS5ccfaZNm2aCgoJMQUFBSS+rQvtlTYwxZsSIEaZ///5X3eenn34ybm5uJiEhwdF2/PhxU61aNbNmzRpjjDGJiYmmWrVq5vjx444+S5cuNTabzWRlZRXzKiqfkydPGklmy5YtxpjiO+bPPfecueuuu5xe6+mnnzb33ntvSS+pSuMMJG5aTk6OUlJSFBER4dQeERGhbdu2ldGsKr+0tDQFBQWpYcOGeuSRR3TkyBFJl38LP3HihFM9bDabwsPDHfVITk6Wr6+v7rnnHkefe++9V76+vtSsmBRXHZKTkxUeHi6bzeboExkZqe+//14ZGRmls5hKZvPmzfL391fTpk315JNP6uTJk45tKSkpys3NdapbUFCQmjdv7lST5s2bKygoyNEnMjJS2dnZSklJKb2FVFBZWVmSpNq1a0sqvmOenJxc6OdQZGSkdu7cqdzc3BJdU1VGgMRNO3XqlPLz81WvXj2n9nr16unEiRNlNKvK7Z577tGiRYu0du1azZ8/XydOnFDHjh11+vRpxzG/Vj1OnDghf3//QuP6+/tTs2JSXHU4ceJEkWP8/DVw43r16qUlS5Zo48aNio2N1Y4dO9S9e3dlZ2dLunxM3d3dddtttznt98u6/bImt912m9zd3anJdRhjNHHiRP3mN79R8+bNJRXfMb/a10peXp5OnTpVUkuq8vj7QLhlLi4uTs+NMYXaUDx69erl+HeLFi3UoUMHNW7cWAsXLnS8IeB69SiqNtSs+BVHHYoa42r74toGDx7s+Hfz5s3Vrl07hYSE6LPPPtOAAQOuuh9fP8UjKipKe/fuVVJS0nX78rVSMXAGEjetTp06cnV1LfSb98mTJwv9NoiS4e3trRYtWigtLc3xbuxr1SMgIEA//PBDoXH+85//ULNiUlx1CAgIKHIMqfDZTVgXGBiokJAQpaWlSbp8vHNycnTmzBmnfr+s2y9rcubMGeXm5lKTaxg3bpxWr16tTZs2qUGDBo724jrmV/taqV69uvz8/EpiSRABErfA3d1dYWFhWr9+vVP7+vXr1bFjxzKaVdWSnZ2tb7/9VoGBgWrYsKECAgKc6pGTk6MtW7Y46tGhQwdlZWXp66+/dvT56quvlJWVRc2KSXHVoUOHDvriiy+cPq5k3bp1CgoKUmhoaOksphI7ffq0/v3vfyswMFCSFBYWJjc3N6e6ZWZmat++fU412bdvnzIzMx191q1bJ5vNprCwsNJdQAVgjFFUVJRWrlypjRs3qmHDhk7bi+uYd+jQodDPoXXr1qldu3Zyc3MrqeWhTN66g0ojISHBuLm5mQ8//NAcOHDAjB8/3nh7e5uMjIyynlqlFBMTYzZv3myOHDlitm/fbvr27Wtq1qzpON5vvPGG8fX1NStXrjSpqalmyJAhJjAw0NjtdscYPXv2NC1btjTJyckmOTnZtGjRwvTt27esllQhnT171uzevdvs3r3bSDIzZswwu3fvNkePHjXGFE8dfvrpJ1OvXj0zZMgQk5qaalauXGl8fHzMW2+9VerrrQiuVZOzZ8+amJgYs23bNpOenm42bdpkOnToYOrXr+9Uk9GjR5sGDRqYf/zjH2bXrl2me/fuplWrViYvL88YY0xeXp5p3ry5ue+++8yuXbvMP/7xD9OgQQMTFRVVVssu18aMGWN8fX3N5s2bTWZmpuNx4cIFR5/iOOZHjhwxXl5eZsKECebAgQPmww8/NG5ubuavf/1rqa+5KiFA4pa99957JiQkxLi7u5u2bds6PqIBxW/w4MEmMDDQuLm5maCgIDNgwACzf/9+x/aCggLz8ssvm4CAAGOz2UyXLl1Mamqq0xinT582Q4cONTVr1jQ1a9Y0Q4cONWfOnCntpVRomzZtMpIKPUaMGGGMKb467N2713Tu3NnYbDYTEBBgpkyZwkf4XMW1anLhwgUTERFh6tata9zc3Mztt99uRowYYY4dO+Y0xsWLF01UVJSpXbu28fT0NH379i3U5+jRo6ZPnz7G09PT1K5d20RFRTl91BL+X1H1kGTi4+MdfYrrmG/evNm0adPGuLu7m9DQUDNnzpzSWGKV5mIMf9YAAAAAN457IAEAAGAJARIAAACWECABAABgCQESAAAAlhAgAQAAYAkBEgAAAJYQIAEAAGAJARIAAACWECABoBIYOXKkXFxcCj0OHTpU1lMDUAlVL+sJAACKR8+ePRUfH+/UVrdu3TKajbPc3Fy5ubmV9TQAFBPOQAJAJWGz2RQQEOD0cHV1LbLv0aNH1a9fP912223y9vbWr3/9ayUmJjq279+/X3369JGPj49q1qypzp076/Dhw5KkgoICvfLKK2rQoIFsNptat26tNWvWOPbNyMiQi4uLPv74Y3Xt2lUeHh5avHixJGnbtm3q0qWLPD09FRwcrOjoaJ0/f74EjwqAkkCABICel6o+AAADUUlEQVQqaOzYscrOztYXX3yh1NRUTZ8+XTVq1JAkHT9+XF26dJGHh4c2btyolJQUPf7448rLy5MkzZw5U7GxsXrrrbe0d+9eRUZG6v7771daWprTazz//POKjo7Wt99+q8jISKWmpioyMlIDBgzQ3r17tWzZMiUlJSkqKqrU1w/g1rgYY0xZTwIAcGtGjhypxYsXy8PDw9HWq1cvLV++vMj+LVu21MCBA/Xyyy8X2vbCCy8oISFBBw8eLPKyc/369TV27Fi98MILjra7775b7du313vvvaeMjAw1bNhQcXFxevbZZx19hg8fLk9PT82dO9fRlpSUpPDwcJ0/f95p7gDKN+6BBIBKolu3bpozZ47jube391X7RkdHa8yYMVq3bp1++9vfauDAgWrZsqUkac+ePercuXOR4dFut+v7779Xp06dnNo7deqkb775xqmtXbt2Ts9TUlJ06NAhLVmyxNFmjFFBQYHS09P1q1/96sYXC6BMcQkbACoJb29vNWnSxPEIDAy8at8nnnhCR44c0bBhw5Samqp27drpnXfekSR5enpe97VcXFycnhtjCrX9MsAWFBTo6aef1p49exyPb775RmlpaWrcuPGNLhNAOUCABIAqKjg4WKNHj9bKlSsVExOj+fPnS7p8efvLL79Ubm5uoX18fHwUFBSkpKQkp/Zt27Zd9wxi27ZttX//fqeQe+Xh7u5efAsDUOIIkABQBY0fP15r165Venq6du3apY0bNzoCYFRUlOx2ux555BHt3LlTaWlp+vOf/6yDBw9KkiZNmqTp06dr2bJlOnjwoP7whz9oz549Tvc7FuX5559XcnKyxo4dqz179igtLU2rV6/WuHHjSny9AIoX90ACQBWUn5+vsWPH6rvvvpOPj4969uypt99+W5Lk5+enjRs3atKkSQoPD5erq6tat27tuO8xOjpadrtdMTExOnnypJo1a6bVq1frjjvuuOZrtmzZUlu2bNGLL76ozp07yxijxo0ba/DgwSW+XgDFi3dhAwAAwBIuYQMAAMASAiQAAAAsIUACAADAEgIkAAAALCFAAgAAwBICJAAAACwhQAIAAMASAiQAAAAsIUACAADAEgIkAAAALCFAAgAAwBICJAAAACz5P35eBrcfmbueAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = model_training_svc.get_model_trainer(settings)\n",
    "trainer.plot_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e5a8058-3633-4565-86c2-f26f3ad98b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_drop_cols = ['provider_id', 'lag2', 'lag_diff', 'prov_mean_diff', 'year', 'quarter']\n",
    "xgbr_feature_importance_settings = {\n",
    "    \"model_type\": \"XGBRegression\",\n",
    "    \"drop_cols\": xgbr_drop_cols,\n",
    "}\n",
    "\n",
    "settings = {**settings, **xgbr_feature_importance_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acae6779-82b8-47f0-8722-98d07b353a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = model_training_svc.get_model_trainer(settings)\n",
    "trainer.plot_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eae499-1ae8-4ab0-8aa2-97f4060728bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1121c589-ac9c-4bbd-918a-fa1517be4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_feature_importance_settings = {\n",
    "    \"model_type\": \"Isolation Forest\",\n",
    "    \"drop_cols\": ['provider_id'],\n",
    "}\n",
    "\n",
    "settings = {**settings, **if_feature_importance_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76882b9f-5353-4f4a-83e6-a2b48ae1f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = model_training_svc.get_model_trainer(settings)\n",
    "# trainer.plot_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed66f231-baaf-4567-90dd-a9635981657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_drop_cols = ['provider_id', 'lag2', 'year', 'quarter']\n",
    "if_feature_importance_settings = {\n",
    "    \"model_type\": \"Isolation Forest\",\n",
    "    \"drop_cols\": xgbr_drop_cols,\n",
    "}\n",
    "\n",
    "settings = {**settings, **if_feature_importance_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c3e004-478c-43e5-ad14-86548f879a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = model_training_svc.get_model_trainer(settings)\n",
    "# trainer.plot_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f77ae11-c8f3-486e-adb9-d0dcb73a0887",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ensamble Model (To Do)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396fe435-7abe-4733-8eaf-752ec61e6394",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfccde5-a52f-464c-9451-fbd055cfb007",
   "metadata": {},
   "source": [
    "### XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f0cb370-8139-4bc4-a50e-fa7e0208a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_initial_training_settings = {\n",
    "    \"model_type\": \"XGBRegression\", \n",
    "    \"xgbr_parameters\": {\n",
    "        'eta': [[0.05, 0.1, 0.2, 0.3]],\n",
    "        'gamma': [range(0, 3)],  # [range(0, 2)]\n",
    "        'max_depth': [range(5, 10)],  # [range(5, 9)]\n",
    "        'min_child_weight': [range(3, 10)],  # [range(3, 9)]\n",
    "        'subsample': [[1]],\n",
    "        'alpha': [[0, 1, 2]]\n",
    "    },\n",
    "    \"drop_cols\": xgbr_drop_cols,\n",
    "}\n",
    "\n",
    "settings = {**settings, **xgbr_initial_training_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e917fc1d-f8c7-459b-90ea-5e4393357776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 1260 candidates, totalling 63000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 480 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1120 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1536 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2016 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2560 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3168 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3840 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4576 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5376 tasks      | elapsed: 26.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6240 tasks      | elapsed: 28.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7168 tasks      | elapsed: 31.8min\n",
      "[Parallel(n_jobs=-1)]: Done 8160 tasks      | elapsed: 34.4min\n",
      "[Parallel(n_jobs=-1)]: Done 9216 tasks      | elapsed: 37.4min\n",
      "[Parallel(n_jobs=-1)]: Done 10336 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 11520 tasks      | elapsed: 42.8min\n",
      "[Parallel(n_jobs=-1)]: Done 12768 tasks      | elapsed: 45.0min\n",
      "[Parallel(n_jobs=-1)]: Done 14080 tasks      | elapsed: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done 15456 tasks      | elapsed: 49.7min\n",
      "[Parallel(n_jobs=-1)]: Done 16896 tasks      | elapsed: 51.9min\n",
      "[Parallel(n_jobs=-1)]: Done 18400 tasks      | elapsed: 54.2min\n",
      "[Parallel(n_jobs=-1)]: Done 19968 tasks      | elapsed: 56.4min\n",
      "[Parallel(n_jobs=-1)]: Done 21600 tasks      | elapsed: 60.6min\n",
      "[Parallel(n_jobs=-1)]: Done 23296 tasks      | elapsed: 69.2min\n",
      "[Parallel(n_jobs=-1)]: Done 25056 tasks      | elapsed: 77.9min\n",
      "[Parallel(n_jobs=-1)]: Done 26880 tasks      | elapsed: 85.7min\n",
      "[Parallel(n_jobs=-1)]: Done 28768 tasks      | elapsed: 90.8min\n",
      "[Parallel(n_jobs=-1)]: Done 30720 tasks      | elapsed: 96.2min\n",
      "[Parallel(n_jobs=-1)]: Done 32736 tasks      | elapsed: 100.7min\n",
      "[Parallel(n_jobs=-1)]: Done 34816 tasks      | elapsed: 104.7min\n",
      "[Parallel(n_jobs=-1)]: Done 36960 tasks      | elapsed: 108.5min\n",
      "[Parallel(n_jobs=-1)]: Done 39168 tasks      | elapsed: 111.7min\n",
      "[Parallel(n_jobs=-1)]: Done 41440 tasks      | elapsed: 115.1min\n",
      "[Parallel(n_jobs=-1)]: Done 43776 tasks      | elapsed: 124.8min\n",
      "[Parallel(n_jobs=-1)]: Done 46176 tasks      | elapsed: 136.1min\n",
      "[Parallel(n_jobs=-1)]: Done 48640 tasks      | elapsed: 145.3min\n",
      "[Parallel(n_jobs=-1)]: Done 51168 tasks      | elapsed: 150.0min\n",
      "[Parallel(n_jobs=-1)]: Done 53760 tasks      | elapsed: 153.2min\n",
      "[Parallel(n_jobs=-1)]: Done 56416 tasks      | elapsed: 155.7min\n",
      "[Parallel(n_jobs=-1)]: Done 59136 tasks      | elapsed: 158.0min\n",
      "[Parallel(n_jobs=-1)]: Done 61920 tasks      | elapsed: 159.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:56.04072\n",
      "[1]\tvalidation_0-rmse:53.27726\n",
      "[2]\tvalidation_0-rmse:50.65385\n",
      "[3]\tvalidation_0-rmse:48.16346\n",
      "[4]\tvalidation_0-rmse:45.79986\n",
      "[5]\tvalidation_0-rmse:43.55564\n",
      "[6]\tvalidation_0-rmse:41.42659\n",
      "[7]\tvalidation_0-rmse:39.40597\n",
      "[8]\tvalidation_0-rmse:37.48809\n",
      "[9]\tvalidation_0-rmse:35.66764\n",
      "[10]\tvalidation_0-rmse:33.94253\n",
      "[11]\tvalidation_0-rmse:32.30533\n",
      "[12]\tvalidation_0-rmse:30.75324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 63000 out of 63000 | elapsed: 160.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13]\tvalidation_0-rmse:29.28195\n",
      "[14]\tvalidation_0-rmse:27.88702\n",
      "[15]\tvalidation_0-rmse:26.56491\n",
      "[16]\tvalidation_0-rmse:25.31255\n",
      "[17]\tvalidation_0-rmse:24.12637\n",
      "[18]\tvalidation_0-rmse:23.00363\n",
      "[19]\tvalidation_0-rmse:21.94028\n",
      "[20]\tvalidation_0-rmse:20.93413\n",
      "[21]\tvalidation_0-rmse:19.98308\n",
      "[22]\tvalidation_0-rmse:19.08285\n",
      "[23]\tvalidation_0-rmse:18.23277\n",
      "[24]\tvalidation_0-rmse:17.42950\n",
      "[25]\tvalidation_0-rmse:16.67120\n",
      "[26]\tvalidation_0-rmse:15.95537\n",
      "[27]\tvalidation_0-rmse:15.28151\n",
      "[28]\tvalidation_0-rmse:14.64589\n",
      "[29]\tvalidation_0-rmse:14.04737\n",
      "[30]\tvalidation_0-rmse:13.48406\n",
      "[31]\tvalidation_0-rmse:12.95558\n",
      "[32]\tvalidation_0-rmse:12.45796\n",
      "[33]\tvalidation_0-rmse:11.99162\n",
      "[34]\tvalidation_0-rmse:11.55445\n",
      "[35]\tvalidation_0-rmse:11.14476\n",
      "[36]\tvalidation_0-rmse:10.76128\n",
      "[37]\tvalidation_0-rmse:10.40301\n",
      "[38]\tvalidation_0-rmse:10.06921\n",
      "[39]\tvalidation_0-rmse:9.75729\n",
      "[40]\tvalidation_0-rmse:9.46687\n",
      "[41]\tvalidation_0-rmse:9.19729\n",
      "[42]\tvalidation_0-rmse:8.94657\n",
      "[43]\tvalidation_0-rmse:8.71422\n",
      "[44]\tvalidation_0-rmse:8.49940\n",
      "[45]\tvalidation_0-rmse:8.30037\n",
      "[46]\tvalidation_0-rmse:8.11661\n",
      "[47]\tvalidation_0-rmse:7.94657\n",
      "[48]\tvalidation_0-rmse:7.79057\n",
      "[49]\tvalidation_0-rmse:7.64707\n",
      "[50]\tvalidation_0-rmse:7.51530\n",
      "[51]\tvalidation_0-rmse:7.39370\n",
      "[52]\tvalidation_0-rmse:7.28221\n",
      "[53]\tvalidation_0-rmse:7.18035\n",
      "[54]\tvalidation_0-rmse:7.08617\n",
      "[55]\tvalidation_0-rmse:7.00121\n",
      "[56]\tvalidation_0-rmse:6.92297\n",
      "[57]\tvalidation_0-rmse:6.85224\n",
      "[58]\tvalidation_0-rmse:6.78784\n",
      "[59]\tvalidation_0-rmse:6.72821\n",
      "[60]\tvalidation_0-rmse:6.67455\n",
      "[61]\tvalidation_0-rmse:6.62654\n",
      "[62]\tvalidation_0-rmse:6.58203\n",
      "[63]\tvalidation_0-rmse:6.54156\n",
      "[64]\tvalidation_0-rmse:6.50524\n",
      "[65]\tvalidation_0-rmse:6.47242\n",
      "[66]\tvalidation_0-rmse:6.44347\n",
      "[67]\tvalidation_0-rmse:6.41727\n",
      "[68]\tvalidation_0-rmse:6.39358\n",
      "[69]\tvalidation_0-rmse:6.37157\n",
      "[70]\tvalidation_0-rmse:6.35189\n",
      "[71]\tvalidation_0-rmse:6.33376\n",
      "[72]\tvalidation_0-rmse:6.31732\n",
      "[73]\tvalidation_0-rmse:6.30249\n",
      "[74]\tvalidation_0-rmse:6.28917\n",
      "[75]\tvalidation_0-rmse:6.27684\n",
      "[76]\tvalidation_0-rmse:6.26632\n",
      "[77]\tvalidation_0-rmse:6.25652\n",
      "[78]\tvalidation_0-rmse:6.24796\n",
      "[79]\tvalidation_0-rmse:6.24043\n",
      "[80]\tvalidation_0-rmse:6.23278\n",
      "[81]\tvalidation_0-rmse:6.22741\n",
      "[82]\tvalidation_0-rmse:6.22125\n",
      "[83]\tvalidation_0-rmse:6.21623\n",
      "[84]\tvalidation_0-rmse:6.21128\n",
      "[85]\tvalidation_0-rmse:6.20654\n",
      "[86]\tvalidation_0-rmse:6.20214\n",
      "[87]\tvalidation_0-rmse:6.19915\n",
      "[88]\tvalidation_0-rmse:6.19680\n",
      "[89]\tvalidation_0-rmse:6.19396\n",
      "[90]\tvalidation_0-rmse:6.19159\n",
      "[91]\tvalidation_0-rmse:6.18984\n",
      "[92]\tvalidation_0-rmse:6.18793\n",
      "[93]\tvalidation_0-rmse:6.18618\n",
      "[94]\tvalidation_0-rmse:6.18456\n",
      "[95]\tvalidation_0-rmse:6.18362\n",
      "[96]\tvalidation_0-rmse:6.18234\n",
      "[97]\tvalidation_0-rmse:6.18110\n",
      "[98]\tvalidation_0-rmse:6.18012\n",
      "[99]\tvalidation_0-rmse:6.17913\n",
      "[100]\tvalidation_0-rmse:6.17817\n",
      "[101]\tvalidation_0-rmse:6.17803\n",
      "[102]\tvalidation_0-rmse:6.17781\n",
      "[103]\tvalidation_0-rmse:6.17710\n",
      "[104]\tvalidation_0-rmse:6.17621\n",
      "[105]\tvalidation_0-rmse:6.17571\n",
      "[106]\tvalidation_0-rmse:6.17516\n",
      "[107]\tvalidation_0-rmse:6.17566\n",
      "[108]\tvalidation_0-rmse:6.17576\n",
      "[109]\tvalidation_0-rmse:6.17546\n",
      "[110]\tvalidation_0-rmse:6.17486\n",
      "[111]\tvalidation_0-rmse:6.17445\n",
      "[112]\tvalidation_0-rmse:6.17483\n",
      "[113]\tvalidation_0-rmse:6.17447\n",
      "[114]\tvalidation_0-rmse:6.17444\n",
      "[115]\tvalidation_0-rmse:6.17425\n",
      "[116]\tvalidation_0-rmse:6.17411\n",
      "[117]\tvalidation_0-rmse:6.17397\n",
      "[118]\tvalidation_0-rmse:6.17408\n",
      "[119]\tvalidation_0-rmse:6.17388\n",
      "[120]\tvalidation_0-rmse:6.17421\n",
      "[121]\tvalidation_0-rmse:6.17422\n",
      "[122]\tvalidation_0-rmse:6.17520\n",
      "[123]\tvalidation_0-rmse:6.17495\n",
      "[124]\tvalidation_0-rmse:6.17603\n",
      "[125]\tvalidation_0-rmse:6.17605\n",
      "[126]\tvalidation_0-rmse:6.17616\n",
      "[127]\tvalidation_0-rmse:6.17617\n",
      "[128]\tvalidation_0-rmse:6.17594\n",
      "[129]\tvalidation_0-rmse:6.17682\n",
      "[130]\tvalidation_0-rmse:6.17678\n",
      "[131]\tvalidation_0-rmse:6.17657\n",
      "[132]\tvalidation_0-rmse:6.17660\n",
      "[133]\tvalidation_0-rmse:6.17658\n",
      "[134]\tvalidation_0-rmse:6.17726\n",
      "[135]\tvalidation_0-rmse:6.17777\n",
      "[136]\tvalidation_0-rmse:6.17778\n",
      "[137]\tvalidation_0-rmse:6.17791\n",
      "[138]\tvalidation_0-rmse:6.17810\n"
     ]
    }
   ],
   "source": [
    "trainer = model_training_svc.get_model_trainer(settings)\n",
    "candidate = trainer.tune()\n",
    "# candidate = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326225b1-4c3b-4488-8482-a468e573df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005332a1-00a1-4add-8c77-96e49f29e6e3",
   "metadata": {},
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63ec156f-e6d4-4f8c-8168-fc65b136afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_training_settings = {\n",
    "    \"model_type\": \"Isolation Forest\", \n",
    "    \"if_parameters\": {\n",
    "        # Features to include\n",
    "        'features_included': [['lag_diff', 'prov_mean_diff']],\n",
    "        # The number of base estimators in the ensemble.\n",
    "        'n_estimators': [50, 100, 200, 300],\n",
    "        # The number of samples to draw from X to train each base estimator.\n",
    "        'max_samples': ['auto', 200, 175, 128],\n",
    "        # The number of features to draw from X to train each base estimator.\n",
    "        'max_features': [1],\n",
    "        # If True, individual trees are fit on random subsets of the training data sampled with replacement.\n",
    "        # If False, sampling without replacement is performed.\n",
    "        'bootstrap': [False, True]\n",
    "    },\n",
    "    \"drop_cols\": if_drop_cols, # use just lag1, prov_mean\n",
    "}\n",
    "\n",
    "settings = {**settings, **if_training_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3292d288-9f49-4c57-bdc7-3a146c251825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Model #5\n",
      "Testing Model #10\n",
      "Testing Model #15\n",
      "Testing Model #20\n",
      "Testing Model #25\n",
      "Testing Model #30\n",
      "Model tuning complete!\n"
     ]
    }
   ],
   "source": [
    "trainer = model_training_svc.get_model_trainer(settings)\n",
    "candidate = trainer.tune()\n",
    "# candidate = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f180ae1-d93c-48cd-9365-dd698db4428e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>features</th>\n",
       "      <th>model_params</th>\n",
       "      <th>auroc_total</th>\n",
       "      <th>unweighted_aat_score_0.5</th>\n",
       "      <th>weighted_aat_score_0.5</th>\n",
       "      <th>auroc_threshold_0.5</th>\n",
       "      <th>unweighted_aat_score_0.51</th>\n",
       "      <th>weighted_aat_score_0.51</th>\n",
       "      <th>auroc_threshold_0.51</th>\n",
       "      <th>unweighted_aat_score_0.52</th>\n",
       "      <th>weighted_aat_score_0.52</th>\n",
       "      <th>auroc_threshold_0.52</th>\n",
       "      <th>unweighted_aat_score_0.53</th>\n",
       "      <th>weighted_aat_score_0.53</th>\n",
       "      <th>auroc_threshold_0.53</th>\n",
       "      <th>unweighted_aat_score_0.54</th>\n",
       "      <th>weighted_aat_score_0.54</th>\n",
       "      <th>auroc_threshold_0.54</th>\n",
       "      <th>unweighted_aat_score_0.55</th>\n",
       "      <th>weighted_aat_score_0.55</th>\n",
       "      <th>auroc_threshold_0.55</th>\n",
       "      <th>unweighted_aat_score_0.56</th>\n",
       "      <th>weighted_aat_score_0.56</th>\n",
       "      <th>auroc_threshold_0.56</th>\n",
       "      <th>unweighted_aat_score_0.57</th>\n",
       "      <th>weighted_aat_score_0.57</th>\n",
       "      <th>auroc_threshold_0.57</th>\n",
       "      <th>unweighted_aat_score_0.58</th>\n",
       "      <th>weighted_aat_score_0.58</th>\n",
       "      <th>auroc_threshold_0.58</th>\n",
       "      <th>unweighted_aat_score_0.59</th>\n",
       "      <th>weighted_aat_score_0.59</th>\n",
       "      <th>auroc_threshold_0.59</th>\n",
       "      <th>unweighted_aat_score_0.6</th>\n",
       "      <th>weighted_aat_score_0.6</th>\n",
       "      <th>auroc_threshold_0.6</th>\n",
       "      <th>unweighted_aat_score_0.61</th>\n",
       "      <th>weighted_aat_score_0.61</th>\n",
       "      <th>auroc_threshold_0.61</th>\n",
       "      <th>unweighted_aat_score_0.62</th>\n",
       "      <th>weighted_aat_score_0.62</th>\n",
       "      <th>auroc_threshold_0.62</th>\n",
       "      <th>unweighted_aat_score_0.63</th>\n",
       "      <th>weighted_aat_score_0.63</th>\n",
       "      <th>auroc_threshold_0.63</th>\n",
       "      <th>unweighted_aat_score_0.64</th>\n",
       "      <th>weighted_aat_score_0.64</th>\n",
       "      <th>auroc_threshold_0.64</th>\n",
       "      <th>unweighted_aat_score_0.65</th>\n",
       "      <th>weighted_aat_score_0.65</th>\n",
       "      <th>auroc_threshold_0.65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995030</td>\n",
       "      <td>0.997270</td>\n",
       "      <td>0.997565</td>\n",
       "      <td>0.913175</td>\n",
       "      <td>0.996385</td>\n",
       "      <td>0.996785</td>\n",
       "      <td>0.924610</td>\n",
       "      <td>0.995250</td>\n",
       "      <td>0.995777</td>\n",
       "      <td>0.935937</td>\n",
       "      <td>0.993545</td>\n",
       "      <td>0.994252</td>\n",
       "      <td>0.943545</td>\n",
       "      <td>0.991590</td>\n",
       "      <td>0.992463</td>\n",
       "      <td>0.949130</td>\n",
       "      <td>0.989645</td>\n",
       "      <td>0.990712</td>\n",
       "      <td>0.953932</td>\n",
       "      <td>0.987900</td>\n",
       "      <td>0.989122</td>\n",
       "      <td>0.958213</td>\n",
       "      <td>0.986095</td>\n",
       "      <td>0.987489</td>\n",
       "      <td>0.962575</td>\n",
       "      <td>0.984360</td>\n",
       "      <td>0.985895</td>\n",
       "      <td>0.965803</td>\n",
       "      <td>0.982255</td>\n",
       "      <td>0.983981</td>\n",
       "      <td>0.968137</td>\n",
       "      <td>0.979865</td>\n",
       "      <td>0.981821</td>\n",
       "      <td>0.970407</td>\n",
       "      <td>0.976760</td>\n",
       "      <td>0.979006</td>\n",
       "      <td>0.971695</td>\n",
       "      <td>0.973760</td>\n",
       "      <td>0.976327</td>\n",
       "      <td>0.972572</td>\n",
       "      <td>0.969485</td>\n",
       "      <td>0.972494</td>\n",
       "      <td>0.972225</td>\n",
       "      <td>0.963615</td>\n",
       "      <td>0.967204</td>\n",
       "      <td>0.970755</td>\n",
       "      <td>0.957215</td>\n",
       "      <td>0.961424</td>\n",
       "      <td>0.969248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995494</td>\n",
       "      <td>0.997595</td>\n",
       "      <td>0.997830</td>\n",
       "      <td>0.907912</td>\n",
       "      <td>0.997225</td>\n",
       "      <td>0.997503</td>\n",
       "      <td>0.921185</td>\n",
       "      <td>0.996685</td>\n",
       "      <td>0.997014</td>\n",
       "      <td>0.932292</td>\n",
       "      <td>0.996040</td>\n",
       "      <td>0.996436</td>\n",
       "      <td>0.940845</td>\n",
       "      <td>0.995075</td>\n",
       "      <td>0.995594</td>\n",
       "      <td>0.949612</td>\n",
       "      <td>0.994085</td>\n",
       "      <td>0.994729</td>\n",
       "      <td>0.955640</td>\n",
       "      <td>0.992365</td>\n",
       "      <td>0.993209</td>\n",
       "      <td>0.960625</td>\n",
       "      <td>0.989830</td>\n",
       "      <td>0.990923</td>\n",
       "      <td>0.964593</td>\n",
       "      <td>0.987705</td>\n",
       "      <td>0.988989</td>\n",
       "      <td>0.967385</td>\n",
       "      <td>0.985930</td>\n",
       "      <td>0.987372</td>\n",
       "      <td>0.970220</td>\n",
       "      <td>0.983535</td>\n",
       "      <td>0.985212</td>\n",
       "      <td>0.972093</td>\n",
       "      <td>0.980805</td>\n",
       "      <td>0.982771</td>\n",
       "      <td>0.973455</td>\n",
       "      <td>0.977650</td>\n",
       "      <td>0.979894</td>\n",
       "      <td>0.974145</td>\n",
       "      <td>0.973310</td>\n",
       "      <td>0.975961</td>\n",
       "      <td>0.973923</td>\n",
       "      <td>0.968395</td>\n",
       "      <td>0.971567</td>\n",
       "      <td>0.973185</td>\n",
       "      <td>0.962755</td>\n",
       "      <td>0.966526</td>\n",
       "      <td>0.971765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995886</td>\n",
       "      <td>0.997615</td>\n",
       "      <td>0.997852</td>\n",
       "      <td>0.915858</td>\n",
       "      <td>0.997190</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>0.926875</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>0.997078</td>\n",
       "      <td>0.937597</td>\n",
       "      <td>0.996045</td>\n",
       "      <td>0.996450</td>\n",
       "      <td>0.945610</td>\n",
       "      <td>0.995205</td>\n",
       "      <td>0.995715</td>\n",
       "      <td>0.952557</td>\n",
       "      <td>0.994390</td>\n",
       "      <td>0.994989</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.993020</td>\n",
       "      <td>0.993785</td>\n",
       "      <td>0.962795</td>\n",
       "      <td>0.991035</td>\n",
       "      <td>0.992037</td>\n",
       "      <td>0.966680</td>\n",
       "      <td>0.988365</td>\n",
       "      <td>0.989643</td>\n",
       "      <td>0.968577</td>\n",
       "      <td>0.985405</td>\n",
       "      <td>0.986975</td>\n",
       "      <td>0.970608</td>\n",
       "      <td>0.982820</td>\n",
       "      <td>0.984628</td>\n",
       "      <td>0.972300</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>0.982134</td>\n",
       "      <td>0.973180</td>\n",
       "      <td>0.976720</td>\n",
       "      <td>0.979106</td>\n",
       "      <td>0.973935</td>\n",
       "      <td>0.972655</td>\n",
       "      <td>0.975412</td>\n",
       "      <td>0.973888</td>\n",
       "      <td>0.968355</td>\n",
       "      <td>0.971580</td>\n",
       "      <td>0.973140</td>\n",
       "      <td>0.962820</td>\n",
       "      <td>0.966603</td>\n",
       "      <td>0.972060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.996053</td>\n",
       "      <td>0.997825</td>\n",
       "      <td>0.998018</td>\n",
       "      <td>0.917050</td>\n",
       "      <td>0.997385</td>\n",
       "      <td>0.997627</td>\n",
       "      <td>0.928710</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>0.997148</td>\n",
       "      <td>0.938825</td>\n",
       "      <td>0.996140</td>\n",
       "      <td>0.996519</td>\n",
       "      <td>0.946175</td>\n",
       "      <td>0.995420</td>\n",
       "      <td>0.995877</td>\n",
       "      <td>0.953085</td>\n",
       "      <td>0.994505</td>\n",
       "      <td>0.995067</td>\n",
       "      <td>0.958488</td>\n",
       "      <td>0.993325</td>\n",
       "      <td>0.994031</td>\n",
       "      <td>0.962875</td>\n",
       "      <td>0.991515</td>\n",
       "      <td>0.992437</td>\n",
       "      <td>0.966827</td>\n",
       "      <td>0.989200</td>\n",
       "      <td>0.990372</td>\n",
       "      <td>0.969085</td>\n",
       "      <td>0.986760</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>0.971233</td>\n",
       "      <td>0.984265</td>\n",
       "      <td>0.985901</td>\n",
       "      <td>0.972842</td>\n",
       "      <td>0.981630</td>\n",
       "      <td>0.983489</td>\n",
       "      <td>0.973945</td>\n",
       "      <td>0.978590</td>\n",
       "      <td>0.980770</td>\n",
       "      <td>0.974853</td>\n",
       "      <td>0.974800</td>\n",
       "      <td>0.977315</td>\n",
       "      <td>0.974712</td>\n",
       "      <td>0.970895</td>\n",
       "      <td>0.973837</td>\n",
       "      <td>0.974085</td>\n",
       "      <td>0.965475</td>\n",
       "      <td>0.969023</td>\n",
       "      <td>0.972978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995433</td>\n",
       "      <td>0.997540</td>\n",
       "      <td>0.997809</td>\n",
       "      <td>0.908532</td>\n",
       "      <td>0.997040</td>\n",
       "      <td>0.997370</td>\n",
       "      <td>0.921120</td>\n",
       "      <td>0.996360</td>\n",
       "      <td>0.996762</td>\n",
       "      <td>0.931750</td>\n",
       "      <td>0.995380</td>\n",
       "      <td>0.995891</td>\n",
       "      <td>0.941220</td>\n",
       "      <td>0.994035</td>\n",
       "      <td>0.994706</td>\n",
       "      <td>0.948615</td>\n",
       "      <td>0.992305</td>\n",
       "      <td>0.993148</td>\n",
       "      <td>0.954095</td>\n",
       "      <td>0.990075</td>\n",
       "      <td>0.991128</td>\n",
       "      <td>0.958565</td>\n",
       "      <td>0.988450</td>\n",
       "      <td>0.989629</td>\n",
       "      <td>0.962530</td>\n",
       "      <td>0.986885</td>\n",
       "      <td>0.988230</td>\n",
       "      <td>0.966185</td>\n",
       "      <td>0.985120</td>\n",
       "      <td>0.986642</td>\n",
       "      <td>0.968708</td>\n",
       "      <td>0.981700</td>\n",
       "      <td>0.983586</td>\n",
       "      <td>0.970315</td>\n",
       "      <td>0.977970</td>\n",
       "      <td>0.980225</td>\n",
       "      <td>0.970880</td>\n",
       "      <td>0.974250</td>\n",
       "      <td>0.976779</td>\n",
       "      <td>0.971653</td>\n",
       "      <td>0.970490</td>\n",
       "      <td>0.973408</td>\n",
       "      <td>0.971645</td>\n",
       "      <td>0.966665</td>\n",
       "      <td>0.969901</td>\n",
       "      <td>0.971302</td>\n",
       "      <td>0.962620</td>\n",
       "      <td>0.966285</td>\n",
       "      <td>0.970373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995725</td>\n",
       "      <td>0.997940</td>\n",
       "      <td>0.998152</td>\n",
       "      <td>0.904305</td>\n",
       "      <td>0.997385</td>\n",
       "      <td>0.997653</td>\n",
       "      <td>0.919230</td>\n",
       "      <td>0.996940</td>\n",
       "      <td>0.997255</td>\n",
       "      <td>0.929652</td>\n",
       "      <td>0.996285</td>\n",
       "      <td>0.996666</td>\n",
       "      <td>0.939865</td>\n",
       "      <td>0.995660</td>\n",
       "      <td>0.996114</td>\n",
       "      <td>0.947115</td>\n",
       "      <td>0.994700</td>\n",
       "      <td>0.995262</td>\n",
       "      <td>0.953635</td>\n",
       "      <td>0.993325</td>\n",
       "      <td>0.994050</td>\n",
       "      <td>0.959278</td>\n",
       "      <td>0.990980</td>\n",
       "      <td>0.991985</td>\n",
       "      <td>0.963685</td>\n",
       "      <td>0.988890</td>\n",
       "      <td>0.990075</td>\n",
       "      <td>0.966755</td>\n",
       "      <td>0.987005</td>\n",
       "      <td>0.988355</td>\n",
       "      <td>0.969560</td>\n",
       "      <td>0.985600</td>\n",
       "      <td>0.987087</td>\n",
       "      <td>0.971730</td>\n",
       "      <td>0.983155</td>\n",
       "      <td>0.984935</td>\n",
       "      <td>0.973290</td>\n",
       "      <td>0.978810</td>\n",
       "      <td>0.980957</td>\n",
       "      <td>0.973725</td>\n",
       "      <td>0.974635</td>\n",
       "      <td>0.977113</td>\n",
       "      <td>0.973933</td>\n",
       "      <td>0.970800</td>\n",
       "      <td>0.973674</td>\n",
       "      <td>0.973633</td>\n",
       "      <td>0.965130</td>\n",
       "      <td>0.968530</td>\n",
       "      <td>0.972110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995990</td>\n",
       "      <td>0.997720</td>\n",
       "      <td>0.997950</td>\n",
       "      <td>0.907470</td>\n",
       "      <td>0.997425</td>\n",
       "      <td>0.997674</td>\n",
       "      <td>0.920960</td>\n",
       "      <td>0.997035</td>\n",
       "      <td>0.997322</td>\n",
       "      <td>0.932345</td>\n",
       "      <td>0.996620</td>\n",
       "      <td>0.996956</td>\n",
       "      <td>0.940683</td>\n",
       "      <td>0.995960</td>\n",
       "      <td>0.996374</td>\n",
       "      <td>0.948427</td>\n",
       "      <td>0.995015</td>\n",
       "      <td>0.995542</td>\n",
       "      <td>0.954770</td>\n",
       "      <td>0.993790</td>\n",
       "      <td>0.994463</td>\n",
       "      <td>0.960532</td>\n",
       "      <td>0.992250</td>\n",
       "      <td>0.993096</td>\n",
       "      <td>0.964795</td>\n",
       "      <td>0.989670</td>\n",
       "      <td>0.990792</td>\n",
       "      <td>0.967690</td>\n",
       "      <td>0.987200</td>\n",
       "      <td>0.988552</td>\n",
       "      <td>0.969828</td>\n",
       "      <td>0.985310</td>\n",
       "      <td>0.986852</td>\n",
       "      <td>0.972035</td>\n",
       "      <td>0.982695</td>\n",
       "      <td>0.984497</td>\n",
       "      <td>0.973205</td>\n",
       "      <td>0.979080</td>\n",
       "      <td>0.981195</td>\n",
       "      <td>0.973742</td>\n",
       "      <td>0.975230</td>\n",
       "      <td>0.977661</td>\n",
       "      <td>0.974165</td>\n",
       "      <td>0.971590</td>\n",
       "      <td>0.974387</td>\n",
       "      <td>0.973840</td>\n",
       "      <td>0.967135</td>\n",
       "      <td>0.970427</td>\n",
       "      <td>0.973037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995885</td>\n",
       "      <td>0.997725</td>\n",
       "      <td>0.997925</td>\n",
       "      <td>0.910073</td>\n",
       "      <td>0.997405</td>\n",
       "      <td>0.997633</td>\n",
       "      <td>0.922028</td>\n",
       "      <td>0.996840</td>\n",
       "      <td>0.997134</td>\n",
       "      <td>0.933410</td>\n",
       "      <td>0.996325</td>\n",
       "      <td>0.996684</td>\n",
       "      <td>0.941673</td>\n",
       "      <td>0.995645</td>\n",
       "      <td>0.996071</td>\n",
       "      <td>0.949403</td>\n",
       "      <td>0.994800</td>\n",
       "      <td>0.995324</td>\n",
       "      <td>0.956003</td>\n",
       "      <td>0.993755</td>\n",
       "      <td>0.994404</td>\n",
       "      <td>0.960700</td>\n",
       "      <td>0.991945</td>\n",
       "      <td>0.992804</td>\n",
       "      <td>0.964935</td>\n",
       "      <td>0.989630</td>\n",
       "      <td>0.990683</td>\n",
       "      <td>0.967690</td>\n",
       "      <td>0.987215</td>\n",
       "      <td>0.988494</td>\n",
       "      <td>0.969910</td>\n",
       "      <td>0.985095</td>\n",
       "      <td>0.986567</td>\n",
       "      <td>0.971873</td>\n",
       "      <td>0.982420</td>\n",
       "      <td>0.984164</td>\n",
       "      <td>0.973045</td>\n",
       "      <td>0.979255</td>\n",
       "      <td>0.981302</td>\n",
       "      <td>0.973843</td>\n",
       "      <td>0.975545</td>\n",
       "      <td>0.977910</td>\n",
       "      <td>0.974212</td>\n",
       "      <td>0.972060</td>\n",
       "      <td>0.974753</td>\n",
       "      <td>0.974160</td>\n",
       "      <td>0.967700</td>\n",
       "      <td>0.970844</td>\n",
       "      <td>0.973100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995386</td>\n",
       "      <td>0.997535</td>\n",
       "      <td>0.997769</td>\n",
       "      <td>0.909898</td>\n",
       "      <td>0.996900</td>\n",
       "      <td>0.997209</td>\n",
       "      <td>0.922935</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>0.996507</td>\n",
       "      <td>0.933323</td>\n",
       "      <td>0.995255</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.941495</td>\n",
       "      <td>0.993970</td>\n",
       "      <td>0.994646</td>\n",
       "      <td>0.948345</td>\n",
       "      <td>0.992045</td>\n",
       "      <td>0.992919</td>\n",
       "      <td>0.953798</td>\n",
       "      <td>0.990115</td>\n",
       "      <td>0.991168</td>\n",
       "      <td>0.958363</td>\n",
       "      <td>0.988380</td>\n",
       "      <td>0.989596</td>\n",
       "      <td>0.963130</td>\n",
       "      <td>0.986300</td>\n",
       "      <td>0.987742</td>\n",
       "      <td>0.966020</td>\n",
       "      <td>0.983415</td>\n",
       "      <td>0.985138</td>\n",
       "      <td>0.968357</td>\n",
       "      <td>0.979330</td>\n",
       "      <td>0.981430</td>\n",
       "      <td>0.969053</td>\n",
       "      <td>0.975820</td>\n",
       "      <td>0.978177</td>\n",
       "      <td>0.970065</td>\n",
       "      <td>0.973515</td>\n",
       "      <td>0.976098</td>\n",
       "      <td>0.971235</td>\n",
       "      <td>0.969655</td>\n",
       "      <td>0.972640</td>\n",
       "      <td>0.971152</td>\n",
       "      <td>0.965365</td>\n",
       "      <td>0.968803</td>\n",
       "      <td>0.970938</td>\n",
       "      <td>0.960320</td>\n",
       "      <td>0.964179</td>\n",
       "      <td>0.969767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995700</td>\n",
       "      <td>0.997910</td>\n",
       "      <td>0.998124</td>\n",
       "      <td>0.900215</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.997754</td>\n",
       "      <td>0.914698</td>\n",
       "      <td>0.996975</td>\n",
       "      <td>0.997281</td>\n",
       "      <td>0.927397</td>\n",
       "      <td>0.996335</td>\n",
       "      <td>0.996715</td>\n",
       "      <td>0.937137</td>\n",
       "      <td>0.995565</td>\n",
       "      <td>0.996038</td>\n",
       "      <td>0.945725</td>\n",
       "      <td>0.994535</td>\n",
       "      <td>0.995142</td>\n",
       "      <td>0.952385</td>\n",
       "      <td>0.992530</td>\n",
       "      <td>0.993373</td>\n",
       "      <td>0.958020</td>\n",
       "      <td>0.990670</td>\n",
       "      <td>0.991684</td>\n",
       "      <td>0.961910</td>\n",
       "      <td>0.988915</td>\n",
       "      <td>0.990100</td>\n",
       "      <td>0.966060</td>\n",
       "      <td>0.987195</td>\n",
       "      <td>0.988549</td>\n",
       "      <td>0.968908</td>\n",
       "      <td>0.985075</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>0.970955</td>\n",
       "      <td>0.982355</td>\n",
       "      <td>0.984199</td>\n",
       "      <td>0.972200</td>\n",
       "      <td>0.978640</td>\n",
       "      <td>0.980850</td>\n",
       "      <td>0.972903</td>\n",
       "      <td>0.975100</td>\n",
       "      <td>0.977611</td>\n",
       "      <td>0.973515</td>\n",
       "      <td>0.971740</td>\n",
       "      <td>0.974555</td>\n",
       "      <td>0.973640</td>\n",
       "      <td>0.966310</td>\n",
       "      <td>0.969696</td>\n",
       "      <td>0.972247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995784</td>\n",
       "      <td>0.997970</td>\n",
       "      <td>0.998161</td>\n",
       "      <td>0.901223</td>\n",
       "      <td>0.997575</td>\n",
       "      <td>0.997796</td>\n",
       "      <td>0.915702</td>\n",
       "      <td>0.997145</td>\n",
       "      <td>0.997403</td>\n",
       "      <td>0.927282</td>\n",
       "      <td>0.996585</td>\n",
       "      <td>0.996908</td>\n",
       "      <td>0.937257</td>\n",
       "      <td>0.995955</td>\n",
       "      <td>0.996338</td>\n",
       "      <td>0.945505</td>\n",
       "      <td>0.995035</td>\n",
       "      <td>0.995523</td>\n",
       "      <td>0.952417</td>\n",
       "      <td>0.993810</td>\n",
       "      <td>0.994453</td>\n",
       "      <td>0.958115</td>\n",
       "      <td>0.991820</td>\n",
       "      <td>0.992673</td>\n",
       "      <td>0.962153</td>\n",
       "      <td>0.989630</td>\n",
       "      <td>0.990697</td>\n",
       "      <td>0.965395</td>\n",
       "      <td>0.987385</td>\n",
       "      <td>0.988676</td>\n",
       "      <td>0.968453</td>\n",
       "      <td>0.984940</td>\n",
       "      <td>0.986454</td>\n",
       "      <td>0.970815</td>\n",
       "      <td>0.982070</td>\n",
       "      <td>0.983832</td>\n",
       "      <td>0.972120</td>\n",
       "      <td>0.978915</td>\n",
       "      <td>0.980963</td>\n",
       "      <td>0.973137</td>\n",
       "      <td>0.975735</td>\n",
       "      <td>0.978077</td>\n",
       "      <td>0.973692</td>\n",
       "      <td>0.971675</td>\n",
       "      <td>0.974440</td>\n",
       "      <td>0.973610</td>\n",
       "      <td>0.967510</td>\n",
       "      <td>0.970709</td>\n",
       "      <td>0.973287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.997885</td>\n",
       "      <td>0.998085</td>\n",
       "      <td>0.903340</td>\n",
       "      <td>0.997470</td>\n",
       "      <td>0.997709</td>\n",
       "      <td>0.916985</td>\n",
       "      <td>0.996985</td>\n",
       "      <td>0.997256</td>\n",
       "      <td>0.929215</td>\n",
       "      <td>0.996505</td>\n",
       "      <td>0.996828</td>\n",
       "      <td>0.938455</td>\n",
       "      <td>0.995860</td>\n",
       "      <td>0.996260</td>\n",
       "      <td>0.946518</td>\n",
       "      <td>0.994955</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.953213</td>\n",
       "      <td>0.993880</td>\n",
       "      <td>0.994519</td>\n",
       "      <td>0.958887</td>\n",
       "      <td>0.991810</td>\n",
       "      <td>0.992692</td>\n",
       "      <td>0.962773</td>\n",
       "      <td>0.989795</td>\n",
       "      <td>0.990880</td>\n",
       "      <td>0.965965</td>\n",
       "      <td>0.987435</td>\n",
       "      <td>0.988774</td>\n",
       "      <td>0.968828</td>\n",
       "      <td>0.985230</td>\n",
       "      <td>0.986807</td>\n",
       "      <td>0.970625</td>\n",
       "      <td>0.982075</td>\n",
       "      <td>0.983947</td>\n",
       "      <td>0.971670</td>\n",
       "      <td>0.978880</td>\n",
       "      <td>0.981040</td>\n",
       "      <td>0.972530</td>\n",
       "      <td>0.975920</td>\n",
       "      <td>0.978354</td>\n",
       "      <td>0.973577</td>\n",
       "      <td>0.971910</td>\n",
       "      <td>0.974703</td>\n",
       "      <td>0.973455</td>\n",
       "      <td>0.967575</td>\n",
       "      <td>0.970808</td>\n",
       "      <td>0.972710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995145</td>\n",
       "      <td>0.997450</td>\n",
       "      <td>0.997717</td>\n",
       "      <td>0.907223</td>\n",
       "      <td>0.996935</td>\n",
       "      <td>0.997272</td>\n",
       "      <td>0.916393</td>\n",
       "      <td>0.995820</td>\n",
       "      <td>0.996282</td>\n",
       "      <td>0.927615</td>\n",
       "      <td>0.994510</td>\n",
       "      <td>0.995098</td>\n",
       "      <td>0.934192</td>\n",
       "      <td>0.992995</td>\n",
       "      <td>0.993727</td>\n",
       "      <td>0.941805</td>\n",
       "      <td>0.991480</td>\n",
       "      <td>0.992355</td>\n",
       "      <td>0.948358</td>\n",
       "      <td>0.989845</td>\n",
       "      <td>0.990896</td>\n",
       "      <td>0.953767</td>\n",
       "      <td>0.988580</td>\n",
       "      <td>0.989756</td>\n",
       "      <td>0.958337</td>\n",
       "      <td>0.987340</td>\n",
       "      <td>0.988622</td>\n",
       "      <td>0.962918</td>\n",
       "      <td>0.985455</td>\n",
       "      <td>0.986920</td>\n",
       "      <td>0.965650</td>\n",
       "      <td>0.982620</td>\n",
       "      <td>0.984368</td>\n",
       "      <td>0.967365</td>\n",
       "      <td>0.980270</td>\n",
       "      <td>0.982217</td>\n",
       "      <td>0.968820</td>\n",
       "      <td>0.978370</td>\n",
       "      <td>0.980544</td>\n",
       "      <td>0.970550</td>\n",
       "      <td>0.972455</td>\n",
       "      <td>0.975239</td>\n",
       "      <td>0.969720</td>\n",
       "      <td>0.968590</td>\n",
       "      <td>0.971666</td>\n",
       "      <td>0.969840</td>\n",
       "      <td>0.964675</td>\n",
       "      <td>0.968124</td>\n",
       "      <td>0.969840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995568</td>\n",
       "      <td>0.997915</td>\n",
       "      <td>0.998121</td>\n",
       "      <td>0.902262</td>\n",
       "      <td>0.997525</td>\n",
       "      <td>0.997769</td>\n",
       "      <td>0.914370</td>\n",
       "      <td>0.997135</td>\n",
       "      <td>0.997413</td>\n",
       "      <td>0.924080</td>\n",
       "      <td>0.996565</td>\n",
       "      <td>0.996897</td>\n",
       "      <td>0.933048</td>\n",
       "      <td>0.995810</td>\n",
       "      <td>0.996216</td>\n",
       "      <td>0.941915</td>\n",
       "      <td>0.994680</td>\n",
       "      <td>0.995213</td>\n",
       "      <td>0.948707</td>\n",
       "      <td>0.993040</td>\n",
       "      <td>0.993754</td>\n",
       "      <td>0.953895</td>\n",
       "      <td>0.991430</td>\n",
       "      <td>0.992327</td>\n",
       "      <td>0.958747</td>\n",
       "      <td>0.989625</td>\n",
       "      <td>0.990706</td>\n",
       "      <td>0.962445</td>\n",
       "      <td>0.988185</td>\n",
       "      <td>0.989425</td>\n",
       "      <td>0.966100</td>\n",
       "      <td>0.986545</td>\n",
       "      <td>0.987929</td>\n",
       "      <td>0.968907</td>\n",
       "      <td>0.984365</td>\n",
       "      <td>0.985986</td>\n",
       "      <td>0.970750</td>\n",
       "      <td>0.980795</td>\n",
       "      <td>0.982729</td>\n",
       "      <td>0.971392</td>\n",
       "      <td>0.977780</td>\n",
       "      <td>0.980002</td>\n",
       "      <td>0.971960</td>\n",
       "      <td>0.974150</td>\n",
       "      <td>0.976675</td>\n",
       "      <td>0.972315</td>\n",
       "      <td>0.969385</td>\n",
       "      <td>0.972371</td>\n",
       "      <td>0.971662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995547</td>\n",
       "      <td>0.998045</td>\n",
       "      <td>0.998218</td>\n",
       "      <td>0.902307</td>\n",
       "      <td>0.997770</td>\n",
       "      <td>0.997970</td>\n",
       "      <td>0.915680</td>\n",
       "      <td>0.997415</td>\n",
       "      <td>0.997651</td>\n",
       "      <td>0.926905</td>\n",
       "      <td>0.996980</td>\n",
       "      <td>0.997267</td>\n",
       "      <td>0.935638</td>\n",
       "      <td>0.996265</td>\n",
       "      <td>0.996628</td>\n",
       "      <td>0.943450</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.995900</td>\n",
       "      <td>0.950335</td>\n",
       "      <td>0.993940</td>\n",
       "      <td>0.994566</td>\n",
       "      <td>0.955732</td>\n",
       "      <td>0.991685</td>\n",
       "      <td>0.992527</td>\n",
       "      <td>0.959975</td>\n",
       "      <td>0.989340</td>\n",
       "      <td>0.990409</td>\n",
       "      <td>0.962757</td>\n",
       "      <td>0.987220</td>\n",
       "      <td>0.988504</td>\n",
       "      <td>0.965500</td>\n",
       "      <td>0.985220</td>\n",
       "      <td>0.986692</td>\n",
       "      <td>0.967992</td>\n",
       "      <td>0.982220</td>\n",
       "      <td>0.983979</td>\n",
       "      <td>0.969340</td>\n",
       "      <td>0.979170</td>\n",
       "      <td>0.981159</td>\n",
       "      <td>0.970222</td>\n",
       "      <td>0.975870</td>\n",
       "      <td>0.978185</td>\n",
       "      <td>0.971070</td>\n",
       "      <td>0.972430</td>\n",
       "      <td>0.975064</td>\n",
       "      <td>0.971473</td>\n",
       "      <td>0.968780</td>\n",
       "      <td>0.971725</td>\n",
       "      <td>0.971435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': False, 'features_included': ['la...</td>\n",
       "      <td>0.995589</td>\n",
       "      <td>0.997995</td>\n",
       "      <td>0.998205</td>\n",
       "      <td>0.902345</td>\n",
       "      <td>0.997675</td>\n",
       "      <td>0.997917</td>\n",
       "      <td>0.915400</td>\n",
       "      <td>0.997355</td>\n",
       "      <td>0.997625</td>\n",
       "      <td>0.926220</td>\n",
       "      <td>0.996960</td>\n",
       "      <td>0.997267</td>\n",
       "      <td>0.934898</td>\n",
       "      <td>0.996315</td>\n",
       "      <td>0.996696</td>\n",
       "      <td>0.942873</td>\n",
       "      <td>0.995535</td>\n",
       "      <td>0.996012</td>\n",
       "      <td>0.950107</td>\n",
       "      <td>0.994195</td>\n",
       "      <td>0.994840</td>\n",
       "      <td>0.955773</td>\n",
       "      <td>0.991835</td>\n",
       "      <td>0.992735</td>\n",
       "      <td>0.959635</td>\n",
       "      <td>0.989535</td>\n",
       "      <td>0.990652</td>\n",
       "      <td>0.963060</td>\n",
       "      <td>0.987600</td>\n",
       "      <td>0.988883</td>\n",
       "      <td>0.965705</td>\n",
       "      <td>0.985505</td>\n",
       "      <td>0.986948</td>\n",
       "      <td>0.968255</td>\n",
       "      <td>0.982845</td>\n",
       "      <td>0.984543</td>\n",
       "      <td>0.969752</td>\n",
       "      <td>0.980335</td>\n",
       "      <td>0.982224</td>\n",
       "      <td>0.970840</td>\n",
       "      <td>0.977655</td>\n",
       "      <td>0.979804</td>\n",
       "      <td>0.971645</td>\n",
       "      <td>0.974395</td>\n",
       "      <td>0.976856</td>\n",
       "      <td>0.972202</td>\n",
       "      <td>0.970805</td>\n",
       "      <td>0.973616</td>\n",
       "      <td>0.972257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.994937</td>\n",
       "      <td>0.997290</td>\n",
       "      <td>0.997579</td>\n",
       "      <td>0.913030</td>\n",
       "      <td>0.996530</td>\n",
       "      <td>0.996907</td>\n",
       "      <td>0.924470</td>\n",
       "      <td>0.995410</td>\n",
       "      <td>0.995892</td>\n",
       "      <td>0.935343</td>\n",
       "      <td>0.993815</td>\n",
       "      <td>0.994482</td>\n",
       "      <td>0.943543</td>\n",
       "      <td>0.991650</td>\n",
       "      <td>0.992550</td>\n",
       "      <td>0.948958</td>\n",
       "      <td>0.989785</td>\n",
       "      <td>0.990866</td>\n",
       "      <td>0.953440</td>\n",
       "      <td>0.988265</td>\n",
       "      <td>0.989514</td>\n",
       "      <td>0.958242</td>\n",
       "      <td>0.986205</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.962647</td>\n",
       "      <td>0.984310</td>\n",
       "      <td>0.985946</td>\n",
       "      <td>0.965525</td>\n",
       "      <td>0.982185</td>\n",
       "      <td>0.984013</td>\n",
       "      <td>0.967927</td>\n",
       "      <td>0.979600</td>\n",
       "      <td>0.981670</td>\n",
       "      <td>0.970032</td>\n",
       "      <td>0.976175</td>\n",
       "      <td>0.978530</td>\n",
       "      <td>0.971205</td>\n",
       "      <td>0.973440</td>\n",
       "      <td>0.976079</td>\n",
       "      <td>0.972202</td>\n",
       "      <td>0.969155</td>\n",
       "      <td>0.972218</td>\n",
       "      <td>0.971928</td>\n",
       "      <td>0.963940</td>\n",
       "      <td>0.967494</td>\n",
       "      <td>0.970700</td>\n",
       "      <td>0.957290</td>\n",
       "      <td>0.961446</td>\n",
       "      <td>0.968923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995612</td>\n",
       "      <td>0.997750</td>\n",
       "      <td>0.997989</td>\n",
       "      <td>0.907212</td>\n",
       "      <td>0.997275</td>\n",
       "      <td>0.997561</td>\n",
       "      <td>0.920763</td>\n",
       "      <td>0.996700</td>\n",
       "      <td>0.997038</td>\n",
       "      <td>0.931768</td>\n",
       "      <td>0.996170</td>\n",
       "      <td>0.996571</td>\n",
       "      <td>0.940408</td>\n",
       "      <td>0.995345</td>\n",
       "      <td>0.995853</td>\n",
       "      <td>0.949912</td>\n",
       "      <td>0.994435</td>\n",
       "      <td>0.995046</td>\n",
       "      <td>0.955852</td>\n",
       "      <td>0.992755</td>\n",
       "      <td>0.993554</td>\n",
       "      <td>0.960940</td>\n",
       "      <td>0.990475</td>\n",
       "      <td>0.991489</td>\n",
       "      <td>0.964902</td>\n",
       "      <td>0.988290</td>\n",
       "      <td>0.989507</td>\n",
       "      <td>0.967797</td>\n",
       "      <td>0.986485</td>\n",
       "      <td>0.987882</td>\n",
       "      <td>0.970683</td>\n",
       "      <td>0.984440</td>\n",
       "      <td>0.986033</td>\n",
       "      <td>0.972825</td>\n",
       "      <td>0.981810</td>\n",
       "      <td>0.983683</td>\n",
       "      <td>0.974250</td>\n",
       "      <td>0.978340</td>\n",
       "      <td>0.980529</td>\n",
       "      <td>0.974662</td>\n",
       "      <td>0.974185</td>\n",
       "      <td>0.976796</td>\n",
       "      <td>0.974480</td>\n",
       "      <td>0.969100</td>\n",
       "      <td>0.972244</td>\n",
       "      <td>0.973398</td>\n",
       "      <td>0.963160</td>\n",
       "      <td>0.966878</td>\n",
       "      <td>0.971880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995855</td>\n",
       "      <td>0.997560</td>\n",
       "      <td>0.997807</td>\n",
       "      <td>0.915695</td>\n",
       "      <td>0.997180</td>\n",
       "      <td>0.997462</td>\n",
       "      <td>0.926673</td>\n",
       "      <td>0.996700</td>\n",
       "      <td>0.997036</td>\n",
       "      <td>0.937360</td>\n",
       "      <td>0.996155</td>\n",
       "      <td>0.996546</td>\n",
       "      <td>0.945535</td>\n",
       "      <td>0.995470</td>\n",
       "      <td>0.995940</td>\n",
       "      <td>0.952745</td>\n",
       "      <td>0.994495</td>\n",
       "      <td>0.995071</td>\n",
       "      <td>0.958758</td>\n",
       "      <td>0.993220</td>\n",
       "      <td>0.993944</td>\n",
       "      <td>0.963013</td>\n",
       "      <td>0.991460</td>\n",
       "      <td>0.992392</td>\n",
       "      <td>0.966665</td>\n",
       "      <td>0.988910</td>\n",
       "      <td>0.990105</td>\n",
       "      <td>0.969080</td>\n",
       "      <td>0.985985</td>\n",
       "      <td>0.987449</td>\n",
       "      <td>0.970882</td>\n",
       "      <td>0.983460</td>\n",
       "      <td>0.985156</td>\n",
       "      <td>0.972685</td>\n",
       "      <td>0.980735</td>\n",
       "      <td>0.982708</td>\n",
       "      <td>0.973805</td>\n",
       "      <td>0.977285</td>\n",
       "      <td>0.979637</td>\n",
       "      <td>0.974395</td>\n",
       "      <td>0.972925</td>\n",
       "      <td>0.975652</td>\n",
       "      <td>0.974005</td>\n",
       "      <td>0.968840</td>\n",
       "      <td>0.971985</td>\n",
       "      <td>0.973330</td>\n",
       "      <td>0.962710</td>\n",
       "      <td>0.966451</td>\n",
       "      <td>0.971967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995821</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997785</td>\n",
       "      <td>0.916880</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>0.927915</td>\n",
       "      <td>0.996700</td>\n",
       "      <td>0.996993</td>\n",
       "      <td>0.938335</td>\n",
       "      <td>0.996110</td>\n",
       "      <td>0.996471</td>\n",
       "      <td>0.946250</td>\n",
       "      <td>0.995390</td>\n",
       "      <td>0.995846</td>\n",
       "      <td>0.952568</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.995115</td>\n",
       "      <td>0.958668</td>\n",
       "      <td>0.993410</td>\n",
       "      <td>0.994110</td>\n",
       "      <td>0.963080</td>\n",
       "      <td>0.991715</td>\n",
       "      <td>0.992594</td>\n",
       "      <td>0.966713</td>\n",
       "      <td>0.989035</td>\n",
       "      <td>0.990206</td>\n",
       "      <td>0.969152</td>\n",
       "      <td>0.986420</td>\n",
       "      <td>0.987836</td>\n",
       "      <td>0.970990</td>\n",
       "      <td>0.983665</td>\n",
       "      <td>0.985352</td>\n",
       "      <td>0.972695</td>\n",
       "      <td>0.980965</td>\n",
       "      <td>0.982913</td>\n",
       "      <td>0.973710</td>\n",
       "      <td>0.977665</td>\n",
       "      <td>0.979901</td>\n",
       "      <td>0.974332</td>\n",
       "      <td>0.973515</td>\n",
       "      <td>0.976136</td>\n",
       "      <td>0.973997</td>\n",
       "      <td>0.969550</td>\n",
       "      <td>0.972574</td>\n",
       "      <td>0.973380</td>\n",
       "      <td>0.964265</td>\n",
       "      <td>0.967895</td>\n",
       "      <td>0.972328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995507</td>\n",
       "      <td>0.997695</td>\n",
       "      <td>0.997943</td>\n",
       "      <td>0.904445</td>\n",
       "      <td>0.997190</td>\n",
       "      <td>0.997507</td>\n",
       "      <td>0.919498</td>\n",
       "      <td>0.996520</td>\n",
       "      <td>0.996924</td>\n",
       "      <td>0.931517</td>\n",
       "      <td>0.995625</td>\n",
       "      <td>0.996128</td>\n",
       "      <td>0.940978</td>\n",
       "      <td>0.994055</td>\n",
       "      <td>0.994754</td>\n",
       "      <td>0.948762</td>\n",
       "      <td>0.992035</td>\n",
       "      <td>0.992962</td>\n",
       "      <td>0.953597</td>\n",
       "      <td>0.990020</td>\n",
       "      <td>0.991165</td>\n",
       "      <td>0.958155</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.989404</td>\n",
       "      <td>0.962267</td>\n",
       "      <td>0.986455</td>\n",
       "      <td>0.987922</td>\n",
       "      <td>0.965667</td>\n",
       "      <td>0.984945</td>\n",
       "      <td>0.986556</td>\n",
       "      <td>0.968353</td>\n",
       "      <td>0.981400</td>\n",
       "      <td>0.983388</td>\n",
       "      <td>0.969745</td>\n",
       "      <td>0.976700</td>\n",
       "      <td>0.979114</td>\n",
       "      <td>0.969910</td>\n",
       "      <td>0.973055</td>\n",
       "      <td>0.975782</td>\n",
       "      <td>0.971307</td>\n",
       "      <td>0.969430</td>\n",
       "      <td>0.972461</td>\n",
       "      <td>0.971420</td>\n",
       "      <td>0.965625</td>\n",
       "      <td>0.969020</td>\n",
       "      <td>0.970880</td>\n",
       "      <td>0.961535</td>\n",
       "      <td>0.965359</td>\n",
       "      <td>0.969938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995776</td>\n",
       "      <td>0.998020</td>\n",
       "      <td>0.998211</td>\n",
       "      <td>0.902935</td>\n",
       "      <td>0.997560</td>\n",
       "      <td>0.997786</td>\n",
       "      <td>0.917928</td>\n",
       "      <td>0.997140</td>\n",
       "      <td>0.997414</td>\n",
       "      <td>0.929488</td>\n",
       "      <td>0.996665</td>\n",
       "      <td>0.996984</td>\n",
       "      <td>0.940200</td>\n",
       "      <td>0.995985</td>\n",
       "      <td>0.996372</td>\n",
       "      <td>0.947385</td>\n",
       "      <td>0.994935</td>\n",
       "      <td>0.995454</td>\n",
       "      <td>0.954395</td>\n",
       "      <td>0.993555</td>\n",
       "      <td>0.994239</td>\n",
       "      <td>0.959495</td>\n",
       "      <td>0.991210</td>\n",
       "      <td>0.992145</td>\n",
       "      <td>0.963460</td>\n",
       "      <td>0.988985</td>\n",
       "      <td>0.990104</td>\n",
       "      <td>0.966695</td>\n",
       "      <td>0.987010</td>\n",
       "      <td>0.988316</td>\n",
       "      <td>0.969253</td>\n",
       "      <td>0.985305</td>\n",
       "      <td>0.986782</td>\n",
       "      <td>0.971340</td>\n",
       "      <td>0.982800</td>\n",
       "      <td>0.984570</td>\n",
       "      <td>0.972923</td>\n",
       "      <td>0.978170</td>\n",
       "      <td>0.980350</td>\n",
       "      <td>0.973317</td>\n",
       "      <td>0.974175</td>\n",
       "      <td>0.976668</td>\n",
       "      <td>0.973533</td>\n",
       "      <td>0.969985</td>\n",
       "      <td>0.972940</td>\n",
       "      <td>0.973067</td>\n",
       "      <td>0.964635</td>\n",
       "      <td>0.968080</td>\n",
       "      <td>0.971782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.997900</td>\n",
       "      <td>0.998101</td>\n",
       "      <td>0.905178</td>\n",
       "      <td>0.997530</td>\n",
       "      <td>0.997769</td>\n",
       "      <td>0.918735</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>0.997377</td>\n",
       "      <td>0.930660</td>\n",
       "      <td>0.996530</td>\n",
       "      <td>0.996867</td>\n",
       "      <td>0.939777</td>\n",
       "      <td>0.995995</td>\n",
       "      <td>0.996387</td>\n",
       "      <td>0.947412</td>\n",
       "      <td>0.995195</td>\n",
       "      <td>0.995689</td>\n",
       "      <td>0.954515</td>\n",
       "      <td>0.994115</td>\n",
       "      <td>0.994729</td>\n",
       "      <td>0.960260</td>\n",
       "      <td>0.992195</td>\n",
       "      <td>0.993033</td>\n",
       "      <td>0.963978</td>\n",
       "      <td>0.989375</td>\n",
       "      <td>0.990518</td>\n",
       "      <td>0.966517</td>\n",
       "      <td>0.986840</td>\n",
       "      <td>0.988222</td>\n",
       "      <td>0.968797</td>\n",
       "      <td>0.984785</td>\n",
       "      <td>0.986361</td>\n",
       "      <td>0.971075</td>\n",
       "      <td>0.982315</td>\n",
       "      <td>0.984122</td>\n",
       "      <td>0.972437</td>\n",
       "      <td>0.978675</td>\n",
       "      <td>0.980804</td>\n",
       "      <td>0.973073</td>\n",
       "      <td>0.974670</td>\n",
       "      <td>0.977127</td>\n",
       "      <td>0.973285</td>\n",
       "      <td>0.970870</td>\n",
       "      <td>0.973691</td>\n",
       "      <td>0.972990</td>\n",
       "      <td>0.966350</td>\n",
       "      <td>0.969670</td>\n",
       "      <td>0.972283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995910</td>\n",
       "      <td>0.997645</td>\n",
       "      <td>0.997879</td>\n",
       "      <td>0.909232</td>\n",
       "      <td>0.997295</td>\n",
       "      <td>0.997562</td>\n",
       "      <td>0.922035</td>\n",
       "      <td>0.996745</td>\n",
       "      <td>0.997066</td>\n",
       "      <td>0.932780</td>\n",
       "      <td>0.996225</td>\n",
       "      <td>0.996604</td>\n",
       "      <td>0.941365</td>\n",
       "      <td>0.995610</td>\n",
       "      <td>0.996058</td>\n",
       "      <td>0.948875</td>\n",
       "      <td>0.994785</td>\n",
       "      <td>0.995333</td>\n",
       "      <td>0.955518</td>\n",
       "      <td>0.993615</td>\n",
       "      <td>0.994307</td>\n",
       "      <td>0.960300</td>\n",
       "      <td>0.991905</td>\n",
       "      <td>0.992818</td>\n",
       "      <td>0.964798</td>\n",
       "      <td>0.989700</td>\n",
       "      <td>0.990832</td>\n",
       "      <td>0.967677</td>\n",
       "      <td>0.987345</td>\n",
       "      <td>0.988694</td>\n",
       "      <td>0.969915</td>\n",
       "      <td>0.985105</td>\n",
       "      <td>0.986664</td>\n",
       "      <td>0.971782</td>\n",
       "      <td>0.982295</td>\n",
       "      <td>0.984171</td>\n",
       "      <td>0.972813</td>\n",
       "      <td>0.979045</td>\n",
       "      <td>0.981213</td>\n",
       "      <td>0.973560</td>\n",
       "      <td>0.974960</td>\n",
       "      <td>0.977464</td>\n",
       "      <td>0.973613</td>\n",
       "      <td>0.971440</td>\n",
       "      <td>0.974319</td>\n",
       "      <td>0.973680</td>\n",
       "      <td>0.967070</td>\n",
       "      <td>0.970382</td>\n",
       "      <td>0.972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995611</td>\n",
       "      <td>0.997635</td>\n",
       "      <td>0.997897</td>\n",
       "      <td>0.911828</td>\n",
       "      <td>0.996940</td>\n",
       "      <td>0.997283</td>\n",
       "      <td>0.924910</td>\n",
       "      <td>0.996180</td>\n",
       "      <td>0.996629</td>\n",
       "      <td>0.935137</td>\n",
       "      <td>0.995320</td>\n",
       "      <td>0.995875</td>\n",
       "      <td>0.943025</td>\n",
       "      <td>0.994085</td>\n",
       "      <td>0.994787</td>\n",
       "      <td>0.949883</td>\n",
       "      <td>0.992055</td>\n",
       "      <td>0.992969</td>\n",
       "      <td>0.955182</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.991102</td>\n",
       "      <td>0.959658</td>\n",
       "      <td>0.988435</td>\n",
       "      <td>0.989700</td>\n",
       "      <td>0.963873</td>\n",
       "      <td>0.986435</td>\n",
       "      <td>0.987916</td>\n",
       "      <td>0.966762</td>\n",
       "      <td>0.983785</td>\n",
       "      <td>0.985540</td>\n",
       "      <td>0.969065</td>\n",
       "      <td>0.979800</td>\n",
       "      <td>0.981948</td>\n",
       "      <td>0.969685</td>\n",
       "      <td>0.976310</td>\n",
       "      <td>0.978730</td>\n",
       "      <td>0.970422</td>\n",
       "      <td>0.973525</td>\n",
       "      <td>0.976175</td>\n",
       "      <td>0.971592</td>\n",
       "      <td>0.969970</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.971492</td>\n",
       "      <td>0.965850</td>\n",
       "      <td>0.969238</td>\n",
       "      <td>0.971188</td>\n",
       "      <td>0.960525</td>\n",
       "      <td>0.964391</td>\n",
       "      <td>0.969817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995544</td>\n",
       "      <td>0.997965</td>\n",
       "      <td>0.998169</td>\n",
       "      <td>0.899355</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.997743</td>\n",
       "      <td>0.913203</td>\n",
       "      <td>0.996970</td>\n",
       "      <td>0.997262</td>\n",
       "      <td>0.926215</td>\n",
       "      <td>0.996215</td>\n",
       "      <td>0.996581</td>\n",
       "      <td>0.935710</td>\n",
       "      <td>0.995310</td>\n",
       "      <td>0.995781</td>\n",
       "      <td>0.944540</td>\n",
       "      <td>0.994210</td>\n",
       "      <td>0.994822</td>\n",
       "      <td>0.951543</td>\n",
       "      <td>0.992275</td>\n",
       "      <td>0.993136</td>\n",
       "      <td>0.956570</td>\n",
       "      <td>0.990235</td>\n",
       "      <td>0.991291</td>\n",
       "      <td>0.960805</td>\n",
       "      <td>0.988550</td>\n",
       "      <td>0.989773</td>\n",
       "      <td>0.964940</td>\n",
       "      <td>0.986775</td>\n",
       "      <td>0.988181</td>\n",
       "      <td>0.968107</td>\n",
       "      <td>0.984760</td>\n",
       "      <td>0.986361</td>\n",
       "      <td>0.970200</td>\n",
       "      <td>0.981730</td>\n",
       "      <td>0.983628</td>\n",
       "      <td>0.971463</td>\n",
       "      <td>0.977950</td>\n",
       "      <td>0.980223</td>\n",
       "      <td>0.972350</td>\n",
       "      <td>0.974620</td>\n",
       "      <td>0.977211</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.971030</td>\n",
       "      <td>0.973965</td>\n",
       "      <td>0.973242</td>\n",
       "      <td>0.965210</td>\n",
       "      <td>0.968739</td>\n",
       "      <td>0.971675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995695</td>\n",
       "      <td>0.998035</td>\n",
       "      <td>0.998223</td>\n",
       "      <td>0.900305</td>\n",
       "      <td>0.997685</td>\n",
       "      <td>0.997901</td>\n",
       "      <td>0.914078</td>\n",
       "      <td>0.997220</td>\n",
       "      <td>0.997481</td>\n",
       "      <td>0.926503</td>\n",
       "      <td>0.996695</td>\n",
       "      <td>0.997014</td>\n",
       "      <td>0.936535</td>\n",
       "      <td>0.995945</td>\n",
       "      <td>0.996336</td>\n",
       "      <td>0.945027</td>\n",
       "      <td>0.994945</td>\n",
       "      <td>0.995447</td>\n",
       "      <td>0.951682</td>\n",
       "      <td>0.993660</td>\n",
       "      <td>0.994319</td>\n",
       "      <td>0.957873</td>\n",
       "      <td>0.991425</td>\n",
       "      <td>0.992304</td>\n",
       "      <td>0.962020</td>\n",
       "      <td>0.989420</td>\n",
       "      <td>0.990506</td>\n",
       "      <td>0.965670</td>\n",
       "      <td>0.987340</td>\n",
       "      <td>0.988627</td>\n",
       "      <td>0.968448</td>\n",
       "      <td>0.984755</td>\n",
       "      <td>0.986267</td>\n",
       "      <td>0.970457</td>\n",
       "      <td>0.981945</td>\n",
       "      <td>0.983732</td>\n",
       "      <td>0.971580</td>\n",
       "      <td>0.978650</td>\n",
       "      <td>0.980738</td>\n",
       "      <td>0.972643</td>\n",
       "      <td>0.975345</td>\n",
       "      <td>0.977748</td>\n",
       "      <td>0.973065</td>\n",
       "      <td>0.971610</td>\n",
       "      <td>0.974344</td>\n",
       "      <td>0.973155</td>\n",
       "      <td>0.967255</td>\n",
       "      <td>0.970421</td>\n",
       "      <td>0.972747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>0.997915</td>\n",
       "      <td>0.998114</td>\n",
       "      <td>0.903845</td>\n",
       "      <td>0.997570</td>\n",
       "      <td>0.997805</td>\n",
       "      <td>0.917318</td>\n",
       "      <td>0.997130</td>\n",
       "      <td>0.997404</td>\n",
       "      <td>0.929497</td>\n",
       "      <td>0.996575</td>\n",
       "      <td>0.996914</td>\n",
       "      <td>0.938835</td>\n",
       "      <td>0.995970</td>\n",
       "      <td>0.996374</td>\n",
       "      <td>0.947068</td>\n",
       "      <td>0.995050</td>\n",
       "      <td>0.995565</td>\n",
       "      <td>0.953668</td>\n",
       "      <td>0.993905</td>\n",
       "      <td>0.994566</td>\n",
       "      <td>0.959085</td>\n",
       "      <td>0.991850</td>\n",
       "      <td>0.992739</td>\n",
       "      <td>0.963320</td>\n",
       "      <td>0.989730</td>\n",
       "      <td>0.990818</td>\n",
       "      <td>0.966247</td>\n",
       "      <td>0.987400</td>\n",
       "      <td>0.988728</td>\n",
       "      <td>0.968867</td>\n",
       "      <td>0.985100</td>\n",
       "      <td>0.986661</td>\n",
       "      <td>0.970615</td>\n",
       "      <td>0.982315</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.971850</td>\n",
       "      <td>0.979060</td>\n",
       "      <td>0.981165</td>\n",
       "      <td>0.972760</td>\n",
       "      <td>0.976110</td>\n",
       "      <td>0.978477</td>\n",
       "      <td>0.973525</td>\n",
       "      <td>0.972325</td>\n",
       "      <td>0.975039</td>\n",
       "      <td>0.973747</td>\n",
       "      <td>0.968065</td>\n",
       "      <td>0.971218</td>\n",
       "      <td>0.973038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.994905</td>\n",
       "      <td>0.997285</td>\n",
       "      <td>0.997585</td>\n",
       "      <td>0.905565</td>\n",
       "      <td>0.996725</td>\n",
       "      <td>0.997096</td>\n",
       "      <td>0.914063</td>\n",
       "      <td>0.995620</td>\n",
       "      <td>0.996104</td>\n",
       "      <td>0.925740</td>\n",
       "      <td>0.994230</td>\n",
       "      <td>0.994841</td>\n",
       "      <td>0.932505</td>\n",
       "      <td>0.992745</td>\n",
       "      <td>0.993505</td>\n",
       "      <td>0.940245</td>\n",
       "      <td>0.991275</td>\n",
       "      <td>0.992189</td>\n",
       "      <td>0.946917</td>\n",
       "      <td>0.989370</td>\n",
       "      <td>0.990455</td>\n",
       "      <td>0.952720</td>\n",
       "      <td>0.988110</td>\n",
       "      <td>0.989313</td>\n",
       "      <td>0.957573</td>\n",
       "      <td>0.986810</td>\n",
       "      <td>0.988133</td>\n",
       "      <td>0.962043</td>\n",
       "      <td>0.984955</td>\n",
       "      <td>0.986470</td>\n",
       "      <td>0.965045</td>\n",
       "      <td>0.982330</td>\n",
       "      <td>0.984111</td>\n",
       "      <td>0.967218</td>\n",
       "      <td>0.979925</td>\n",
       "      <td>0.981952</td>\n",
       "      <td>0.968870</td>\n",
       "      <td>0.977930</td>\n",
       "      <td>0.980184</td>\n",
       "      <td>0.970440</td>\n",
       "      <td>0.971915</td>\n",
       "      <td>0.974797</td>\n",
       "      <td>0.969653</td>\n",
       "      <td>0.968180</td>\n",
       "      <td>0.971311</td>\n",
       "      <td>0.969728</td>\n",
       "      <td>0.964400</td>\n",
       "      <td>0.967957</td>\n",
       "      <td>0.969735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995613</td>\n",
       "      <td>0.998005</td>\n",
       "      <td>0.998204</td>\n",
       "      <td>0.902348</td>\n",
       "      <td>0.997610</td>\n",
       "      <td>0.997844</td>\n",
       "      <td>0.914797</td>\n",
       "      <td>0.997270</td>\n",
       "      <td>0.997538</td>\n",
       "      <td>0.924657</td>\n",
       "      <td>0.996810</td>\n",
       "      <td>0.997121</td>\n",
       "      <td>0.933835</td>\n",
       "      <td>0.996065</td>\n",
       "      <td>0.996461</td>\n",
       "      <td>0.942532</td>\n",
       "      <td>0.994835</td>\n",
       "      <td>0.995368</td>\n",
       "      <td>0.949178</td>\n",
       "      <td>0.993200</td>\n",
       "      <td>0.993914</td>\n",
       "      <td>0.954395</td>\n",
       "      <td>0.991360</td>\n",
       "      <td>0.992269</td>\n",
       "      <td>0.958808</td>\n",
       "      <td>0.989475</td>\n",
       "      <td>0.990537</td>\n",
       "      <td>0.962492</td>\n",
       "      <td>0.988065</td>\n",
       "      <td>0.989262</td>\n",
       "      <td>0.966092</td>\n",
       "      <td>0.986530</td>\n",
       "      <td>0.987880</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.984240</td>\n",
       "      <td>0.985813</td>\n",
       "      <td>0.970643</td>\n",
       "      <td>0.980695</td>\n",
       "      <td>0.982596</td>\n",
       "      <td>0.971305</td>\n",
       "      <td>0.977915</td>\n",
       "      <td>0.980090</td>\n",
       "      <td>0.971847</td>\n",
       "      <td>0.974200</td>\n",
       "      <td>0.976688</td>\n",
       "      <td>0.972082</td>\n",
       "      <td>0.969460</td>\n",
       "      <td>0.972412</td>\n",
       "      <td>0.971558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995496</td>\n",
       "      <td>0.997885</td>\n",
       "      <td>0.998088</td>\n",
       "      <td>0.902513</td>\n",
       "      <td>0.997550</td>\n",
       "      <td>0.997789</td>\n",
       "      <td>0.916345</td>\n",
       "      <td>0.997045</td>\n",
       "      <td>0.997343</td>\n",
       "      <td>0.927455</td>\n",
       "      <td>0.996625</td>\n",
       "      <td>0.996959</td>\n",
       "      <td>0.935855</td>\n",
       "      <td>0.996035</td>\n",
       "      <td>0.996433</td>\n",
       "      <td>0.944210</td>\n",
       "      <td>0.995250</td>\n",
       "      <td>0.995736</td>\n",
       "      <td>0.950887</td>\n",
       "      <td>0.993935</td>\n",
       "      <td>0.994578</td>\n",
       "      <td>0.956420</td>\n",
       "      <td>0.991830</td>\n",
       "      <td>0.992697</td>\n",
       "      <td>0.960665</td>\n",
       "      <td>0.989680</td>\n",
       "      <td>0.990750</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.987455</td>\n",
       "      <td>0.988721</td>\n",
       "      <td>0.966262</td>\n",
       "      <td>0.985465</td>\n",
       "      <td>0.986915</td>\n",
       "      <td>0.968740</td>\n",
       "      <td>0.982385</td>\n",
       "      <td>0.984122</td>\n",
       "      <td>0.970125</td>\n",
       "      <td>0.979440</td>\n",
       "      <td>0.981424</td>\n",
       "      <td>0.970902</td>\n",
       "      <td>0.976205</td>\n",
       "      <td>0.978490</td>\n",
       "      <td>0.971815</td>\n",
       "      <td>0.973035</td>\n",
       "      <td>0.975605</td>\n",
       "      <td>0.972325</td>\n",
       "      <td>0.969560</td>\n",
       "      <td>0.972473</td>\n",
       "      <td>0.972252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>['lag_diff', 'prov_mean_diff']</td>\n",
       "      <td>{'bootstrap': True, 'features_included': ['lag...</td>\n",
       "      <td>0.995621</td>\n",
       "      <td>0.997940</td>\n",
       "      <td>0.998150</td>\n",
       "      <td>0.902768</td>\n",
       "      <td>0.997560</td>\n",
       "      <td>0.997807</td>\n",
       "      <td>0.915523</td>\n",
       "      <td>0.997125</td>\n",
       "      <td>0.997421</td>\n",
       "      <td>0.926278</td>\n",
       "      <td>0.996765</td>\n",
       "      <td>0.997098</td>\n",
       "      <td>0.935037</td>\n",
       "      <td>0.996150</td>\n",
       "      <td>0.996550</td>\n",
       "      <td>0.942840</td>\n",
       "      <td>0.995260</td>\n",
       "      <td>0.995772</td>\n",
       "      <td>0.950148</td>\n",
       "      <td>0.993820</td>\n",
       "      <td>0.994505</td>\n",
       "      <td>0.955605</td>\n",
       "      <td>0.991350</td>\n",
       "      <td>0.992315</td>\n",
       "      <td>0.959092</td>\n",
       "      <td>0.988820</td>\n",
       "      <td>0.990051</td>\n",
       "      <td>0.962255</td>\n",
       "      <td>0.986905</td>\n",
       "      <td>0.988326</td>\n",
       "      <td>0.965275</td>\n",
       "      <td>0.984785</td>\n",
       "      <td>0.986395</td>\n",
       "      <td>0.967665</td>\n",
       "      <td>0.982095</td>\n",
       "      <td>0.983969</td>\n",
       "      <td>0.969353</td>\n",
       "      <td>0.979415</td>\n",
       "      <td>0.981530</td>\n",
       "      <td>0.970385</td>\n",
       "      <td>0.976460</td>\n",
       "      <td>0.978845</td>\n",
       "      <td>0.971232</td>\n",
       "      <td>0.973095</td>\n",
       "      <td>0.975829</td>\n",
       "      <td>0.971713</td>\n",
       "      <td>0.969385</td>\n",
       "      <td>0.972458</td>\n",
       "      <td>0.971705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_id                        features  \\\n",
       "0          1  ['lag_diff', 'prov_mean_diff']   \n",
       "1          2  ['lag_diff', 'prov_mean_diff']   \n",
       "2          3  ['lag_diff', 'prov_mean_diff']   \n",
       "3          4  ['lag_diff', 'prov_mean_diff']   \n",
       "4          5  ['lag_diff', 'prov_mean_diff']   \n",
       "5          6  ['lag_diff', 'prov_mean_diff']   \n",
       "6          7  ['lag_diff', 'prov_mean_diff']   \n",
       "7          8  ['lag_diff', 'prov_mean_diff']   \n",
       "8          9  ['lag_diff', 'prov_mean_diff']   \n",
       "9         10  ['lag_diff', 'prov_mean_diff']   \n",
       "10        11  ['lag_diff', 'prov_mean_diff']   \n",
       "11        12  ['lag_diff', 'prov_mean_diff']   \n",
       "12        13  ['lag_diff', 'prov_mean_diff']   \n",
       "13        14  ['lag_diff', 'prov_mean_diff']   \n",
       "14        15  ['lag_diff', 'prov_mean_diff']   \n",
       "15        16  ['lag_diff', 'prov_mean_diff']   \n",
       "16        17  ['lag_diff', 'prov_mean_diff']   \n",
       "17        18  ['lag_diff', 'prov_mean_diff']   \n",
       "18        19  ['lag_diff', 'prov_mean_diff']   \n",
       "19        20  ['lag_diff', 'prov_mean_diff']   \n",
       "20        21  ['lag_diff', 'prov_mean_diff']   \n",
       "21        22  ['lag_diff', 'prov_mean_diff']   \n",
       "22        23  ['lag_diff', 'prov_mean_diff']   \n",
       "23        24  ['lag_diff', 'prov_mean_diff']   \n",
       "24        25  ['lag_diff', 'prov_mean_diff']   \n",
       "25        26  ['lag_diff', 'prov_mean_diff']   \n",
       "26        27  ['lag_diff', 'prov_mean_diff']   \n",
       "27        28  ['lag_diff', 'prov_mean_diff']   \n",
       "28        29  ['lag_diff', 'prov_mean_diff']   \n",
       "29        30  ['lag_diff', 'prov_mean_diff']   \n",
       "30        31  ['lag_diff', 'prov_mean_diff']   \n",
       "31        32  ['lag_diff', 'prov_mean_diff']   \n",
       "\n",
       "                                         model_params  auroc_total  \\\n",
       "0   {'bootstrap': False, 'features_included': ['la...     0.995030   \n",
       "1   {'bootstrap': False, 'features_included': ['la...     0.995494   \n",
       "2   {'bootstrap': False, 'features_included': ['la...     0.995886   \n",
       "3   {'bootstrap': False, 'features_included': ['la...     0.996053   \n",
       "4   {'bootstrap': False, 'features_included': ['la...     0.995433   \n",
       "5   {'bootstrap': False, 'features_included': ['la...     0.995725   \n",
       "6   {'bootstrap': False, 'features_included': ['la...     0.995990   \n",
       "7   {'bootstrap': False, 'features_included': ['la...     0.995885   \n",
       "8   {'bootstrap': False, 'features_included': ['la...     0.995386   \n",
       "9   {'bootstrap': False, 'features_included': ['la...     0.995700   \n",
       "10  {'bootstrap': False, 'features_included': ['la...     0.995784   \n",
       "11  {'bootstrap': False, 'features_included': ['la...     0.995768   \n",
       "12  {'bootstrap': False, 'features_included': ['la...     0.995145   \n",
       "13  {'bootstrap': False, 'features_included': ['la...     0.995568   \n",
       "14  {'bootstrap': False, 'features_included': ['la...     0.995547   \n",
       "15  {'bootstrap': False, 'features_included': ['la...     0.995589   \n",
       "16  {'bootstrap': True, 'features_included': ['lag...     0.994937   \n",
       "17  {'bootstrap': True, 'features_included': ['lag...     0.995612   \n",
       "18  {'bootstrap': True, 'features_included': ['lag...     0.995855   \n",
       "19  {'bootstrap': True, 'features_included': ['lag...     0.995821   \n",
       "20  {'bootstrap': True, 'features_included': ['lag...     0.995507   \n",
       "21  {'bootstrap': True, 'features_included': ['lag...     0.995776   \n",
       "22  {'bootstrap': True, 'features_included': ['lag...     0.995833   \n",
       "23  {'bootstrap': True, 'features_included': ['lag...     0.995910   \n",
       "24  {'bootstrap': True, 'features_included': ['lag...     0.995611   \n",
       "25  {'bootstrap': True, 'features_included': ['lag...     0.995544   \n",
       "26  {'bootstrap': True, 'features_included': ['lag...     0.995695   \n",
       "27  {'bootstrap': True, 'features_included': ['lag...     0.995851   \n",
       "28  {'bootstrap': True, 'features_included': ['lag...     0.994905   \n",
       "29  {'bootstrap': True, 'features_included': ['lag...     0.995613   \n",
       "30  {'bootstrap': True, 'features_included': ['lag...     0.995496   \n",
       "31  {'bootstrap': True, 'features_included': ['lag...     0.995621   \n",
       "\n",
       "    unweighted_aat_score_0.5  weighted_aat_score_0.5  auroc_threshold_0.5  \\\n",
       "0                   0.997270                0.997565             0.913175   \n",
       "1                   0.997595                0.997830             0.907912   \n",
       "2                   0.997615                0.997852             0.915858   \n",
       "3                   0.997825                0.998018             0.917050   \n",
       "4                   0.997540                0.997809             0.908532   \n",
       "5                   0.997940                0.998152             0.904305   \n",
       "6                   0.997720                0.997950             0.907470   \n",
       "7                   0.997725                0.997925             0.910073   \n",
       "8                   0.997535                0.997769             0.909898   \n",
       "9                   0.997910                0.998124             0.900215   \n",
       "10                  0.997970                0.998161             0.901223   \n",
       "11                  0.997885                0.998085             0.903340   \n",
       "12                  0.997450                0.997717             0.907223   \n",
       "13                  0.997915                0.998121             0.902262   \n",
       "14                  0.998045                0.998218             0.902307   \n",
       "15                  0.997995                0.998205             0.902345   \n",
       "16                  0.997290                0.997579             0.913030   \n",
       "17                  0.997750                0.997989             0.907212   \n",
       "18                  0.997560                0.997807             0.915695   \n",
       "19                  0.997570                0.997785             0.916880   \n",
       "20                  0.997695                0.997943             0.904445   \n",
       "21                  0.998020                0.998211             0.902935   \n",
       "22                  0.997900                0.998101             0.905178   \n",
       "23                  0.997645                0.997879             0.909232   \n",
       "24                  0.997635                0.997897             0.911828   \n",
       "25                  0.997965                0.998169             0.899355   \n",
       "26                  0.998035                0.998223             0.900305   \n",
       "27                  0.997915                0.998114             0.903845   \n",
       "28                  0.997285                0.997585             0.905565   \n",
       "29                  0.998005                0.998204             0.902348   \n",
       "30                  0.997885                0.998088             0.902513   \n",
       "31                  0.997940                0.998150             0.902768   \n",
       "\n",
       "    unweighted_aat_score_0.51  weighted_aat_score_0.51  auroc_threshold_0.51  \\\n",
       "0                    0.996385                 0.996785              0.924610   \n",
       "1                    0.997225                 0.997503              0.921185   \n",
       "2                    0.997190                 0.997465              0.926875   \n",
       "3                    0.997385                 0.997627              0.928710   \n",
       "4                    0.997040                 0.997370              0.921120   \n",
       "5                    0.997385                 0.997653              0.919230   \n",
       "6                    0.997425                 0.997674              0.920960   \n",
       "7                    0.997405                 0.997633              0.922028   \n",
       "8                    0.996900                 0.997209              0.922935   \n",
       "9                    0.997500                 0.997754              0.914698   \n",
       "10                   0.997575                 0.997796              0.915702   \n",
       "11                   0.997470                 0.997709              0.916985   \n",
       "12                   0.996935                 0.997272              0.916393   \n",
       "13                   0.997525                 0.997769              0.914370   \n",
       "14                   0.997770                 0.997970              0.915680   \n",
       "15                   0.997675                 0.997917              0.915400   \n",
       "16                   0.996530                 0.996907              0.924470   \n",
       "17                   0.997275                 0.997561              0.920763   \n",
       "18                   0.997180                 0.997462              0.926673   \n",
       "19                   0.997100                 0.997354              0.927915   \n",
       "20                   0.997190                 0.997507              0.919498   \n",
       "21                   0.997560                 0.997786              0.917928   \n",
       "22                   0.997530                 0.997769              0.918735   \n",
       "23                   0.997295                 0.997562              0.922035   \n",
       "24                   0.996940                 0.997283              0.924910   \n",
       "25                   0.997500                 0.997743              0.913203   \n",
       "26                   0.997685                 0.997901              0.914078   \n",
       "27                   0.997570                 0.997805              0.917318   \n",
       "28                   0.996725                 0.997096              0.914063   \n",
       "29                   0.997610                 0.997844              0.914797   \n",
       "30                   0.997550                 0.997789              0.916345   \n",
       "31                   0.997560                 0.997807              0.915523   \n",
       "\n",
       "    unweighted_aat_score_0.52  weighted_aat_score_0.52  auroc_threshold_0.52  \\\n",
       "0                    0.995250                 0.995777              0.935937   \n",
       "1                    0.996685                 0.997014              0.932292   \n",
       "2                    0.996750                 0.997078              0.937597   \n",
       "3                    0.996845                 0.997148              0.938825   \n",
       "4                    0.996360                 0.996762              0.931750   \n",
       "5                    0.996940                 0.997255              0.929652   \n",
       "6                    0.997035                 0.997322              0.932345   \n",
       "7                    0.996840                 0.997134              0.933410   \n",
       "8                    0.996100                 0.996507              0.933323   \n",
       "9                    0.996975                 0.997281              0.927397   \n",
       "10                   0.997145                 0.997403              0.927282   \n",
       "11                   0.996985                 0.997256              0.929215   \n",
       "12                   0.995820                 0.996282              0.927615   \n",
       "13                   0.997135                 0.997413              0.924080   \n",
       "14                   0.997415                 0.997651              0.926905   \n",
       "15                   0.997355                 0.997625              0.926220   \n",
       "16                   0.995410                 0.995892              0.935343   \n",
       "17                   0.996700                 0.997038              0.931768   \n",
       "18                   0.996700                 0.997036              0.937360   \n",
       "19                   0.996700                 0.996993              0.938335   \n",
       "20                   0.996520                 0.996924              0.931517   \n",
       "21                   0.997140                 0.997414              0.929488   \n",
       "22                   0.997100                 0.997377              0.930660   \n",
       "23                   0.996745                 0.997066              0.932780   \n",
       "24                   0.996180                 0.996629              0.935137   \n",
       "25                   0.996970                 0.997262              0.926215   \n",
       "26                   0.997220                 0.997481              0.926503   \n",
       "27                   0.997130                 0.997404              0.929497   \n",
       "28                   0.995620                 0.996104              0.925740   \n",
       "29                   0.997270                 0.997538              0.924657   \n",
       "30                   0.997045                 0.997343              0.927455   \n",
       "31                   0.997125                 0.997421              0.926278   \n",
       "\n",
       "    unweighted_aat_score_0.53  weighted_aat_score_0.53  auroc_threshold_0.53  \\\n",
       "0                    0.993545                 0.994252              0.943545   \n",
       "1                    0.996040                 0.996436              0.940845   \n",
       "2                    0.996045                 0.996450              0.945610   \n",
       "3                    0.996140                 0.996519              0.946175   \n",
       "4                    0.995380                 0.995891              0.941220   \n",
       "5                    0.996285                 0.996666              0.939865   \n",
       "6                    0.996620                 0.996956              0.940683   \n",
       "7                    0.996325                 0.996684              0.941673   \n",
       "8                    0.995255                 0.995768              0.941495   \n",
       "9                    0.996335                 0.996715              0.937137   \n",
       "10                   0.996585                 0.996908              0.937257   \n",
       "11                   0.996505                 0.996828              0.938455   \n",
       "12                   0.994510                 0.995098              0.934192   \n",
       "13                   0.996565                 0.996897              0.933048   \n",
       "14                   0.996980                 0.997267              0.935638   \n",
       "15                   0.996960                 0.997267              0.934898   \n",
       "16                   0.993815                 0.994482              0.943543   \n",
       "17                   0.996170                 0.996571              0.940408   \n",
       "18                   0.996155                 0.996546              0.945535   \n",
       "19                   0.996110                 0.996471              0.946250   \n",
       "20                   0.995625                 0.996128              0.940978   \n",
       "21                   0.996665                 0.996984              0.940200   \n",
       "22                   0.996530                 0.996867              0.939777   \n",
       "23                   0.996225                 0.996604              0.941365   \n",
       "24                   0.995320                 0.995875              0.943025   \n",
       "25                   0.996215                 0.996581              0.935710   \n",
       "26                   0.996695                 0.997014              0.936535   \n",
       "27                   0.996575                 0.996914              0.938835   \n",
       "28                   0.994230                 0.994841              0.932505   \n",
       "29                   0.996810                 0.997121              0.933835   \n",
       "30                   0.996625                 0.996959              0.935855   \n",
       "31                   0.996765                 0.997098              0.935037   \n",
       "\n",
       "    unweighted_aat_score_0.54  weighted_aat_score_0.54  auroc_threshold_0.54  \\\n",
       "0                    0.991590                 0.992463              0.949130   \n",
       "1                    0.995075                 0.995594              0.949612   \n",
       "2                    0.995205                 0.995715              0.952557   \n",
       "3                    0.995420                 0.995877              0.953085   \n",
       "4                    0.994035                 0.994706              0.948615   \n",
       "5                    0.995660                 0.996114              0.947115   \n",
       "6                    0.995960                 0.996374              0.948427   \n",
       "7                    0.995645                 0.996071              0.949403   \n",
       "8                    0.993970                 0.994646              0.948345   \n",
       "9                    0.995565                 0.996038              0.945725   \n",
       "10                   0.995955                 0.996338              0.945505   \n",
       "11                   0.995860                 0.996260              0.946518   \n",
       "12                   0.992995                 0.993727              0.941805   \n",
       "13                   0.995810                 0.996216              0.941915   \n",
       "14                   0.996265                 0.996628              0.943450   \n",
       "15                   0.996315                 0.996696              0.942873   \n",
       "16                   0.991650                 0.992550              0.948958   \n",
       "17                   0.995345                 0.995853              0.949912   \n",
       "18                   0.995470                 0.995940              0.952745   \n",
       "19                   0.995390                 0.995846              0.952568   \n",
       "20                   0.994055                 0.994754              0.948762   \n",
       "21                   0.995985                 0.996372              0.947385   \n",
       "22                   0.995995                 0.996387              0.947412   \n",
       "23                   0.995610                 0.996058              0.948875   \n",
       "24                   0.994085                 0.994787              0.949883   \n",
       "25                   0.995310                 0.995781              0.944540   \n",
       "26                   0.995945                 0.996336              0.945027   \n",
       "27                   0.995970                 0.996374              0.947068   \n",
       "28                   0.992745                 0.993505              0.940245   \n",
       "29                   0.996065                 0.996461              0.942532   \n",
       "30                   0.996035                 0.996433              0.944210   \n",
       "31                   0.996150                 0.996550              0.942840   \n",
       "\n",
       "    unweighted_aat_score_0.55  weighted_aat_score_0.55  auroc_threshold_0.55  \\\n",
       "0                    0.989645                 0.990712              0.953932   \n",
       "1                    0.994085                 0.994729              0.955640   \n",
       "2                    0.994390                 0.994989              0.958333   \n",
       "3                    0.994505                 0.995067              0.958488   \n",
       "4                    0.992305                 0.993148              0.954095   \n",
       "5                    0.994700                 0.995262              0.953635   \n",
       "6                    0.995015                 0.995542              0.954770   \n",
       "7                    0.994800                 0.995324              0.956003   \n",
       "8                    0.992045                 0.992919              0.953798   \n",
       "9                    0.994535                 0.995142              0.952385   \n",
       "10                   0.995035                 0.995523              0.952417   \n",
       "11                   0.994955                 0.995455              0.953213   \n",
       "12                   0.991480                 0.992355              0.948358   \n",
       "13                   0.994680                 0.995213              0.948707   \n",
       "14                   0.995455                 0.995900              0.950335   \n",
       "15                   0.995535                 0.996012              0.950107   \n",
       "16                   0.989785                 0.990866              0.953440   \n",
       "17                   0.994435                 0.995046              0.955852   \n",
       "18                   0.994495                 0.995071              0.958758   \n",
       "19                   0.994565                 0.995115              0.958668   \n",
       "20                   0.992035                 0.992962              0.953597   \n",
       "21                   0.994935                 0.995454              0.954395   \n",
       "22                   0.995195                 0.995689              0.954515   \n",
       "23                   0.994785                 0.995333              0.955518   \n",
       "24                   0.992055                 0.992969              0.955182   \n",
       "25                   0.994210                 0.994822              0.951543   \n",
       "26                   0.994945                 0.995447              0.951682   \n",
       "27                   0.995050                 0.995565              0.953668   \n",
       "28                   0.991275                 0.992189              0.946917   \n",
       "29                   0.994835                 0.995368              0.949178   \n",
       "30                   0.995250                 0.995736              0.950887   \n",
       "31                   0.995260                 0.995772              0.950148   \n",
       "\n",
       "    unweighted_aat_score_0.56  weighted_aat_score_0.56  auroc_threshold_0.56  \\\n",
       "0                    0.987900                 0.989122              0.958213   \n",
       "1                    0.992365                 0.993209              0.960625   \n",
       "2                    0.993020                 0.993785              0.962795   \n",
       "3                    0.993325                 0.994031              0.962875   \n",
       "4                    0.990075                 0.991128              0.958565   \n",
       "5                    0.993325                 0.994050              0.959278   \n",
       "6                    0.993790                 0.994463              0.960532   \n",
       "7                    0.993755                 0.994404              0.960700   \n",
       "8                    0.990115                 0.991168              0.958363   \n",
       "9                    0.992530                 0.993373              0.958020   \n",
       "10                   0.993810                 0.994453              0.958115   \n",
       "11                   0.993880                 0.994519              0.958887   \n",
       "12                   0.989845                 0.990896              0.953767   \n",
       "13                   0.993040                 0.993754              0.953895   \n",
       "14                   0.993940                 0.994566              0.955732   \n",
       "15                   0.994195                 0.994840              0.955773   \n",
       "16                   0.988265                 0.989514              0.958242   \n",
       "17                   0.992755                 0.993554              0.960940   \n",
       "18                   0.993220                 0.993944              0.963013   \n",
       "19                   0.993410                 0.994110              0.963080   \n",
       "20                   0.990020                 0.991165              0.958155   \n",
       "21                   0.993555                 0.994239              0.959495   \n",
       "22                   0.994115                 0.994729              0.960260   \n",
       "23                   0.993615                 0.994307              0.960300   \n",
       "24                   0.990000                 0.991102              0.959658   \n",
       "25                   0.992275                 0.993136              0.956570   \n",
       "26                   0.993660                 0.994319              0.957873   \n",
       "27                   0.993905                 0.994566              0.959085   \n",
       "28                   0.989370                 0.990455              0.952720   \n",
       "29                   0.993200                 0.993914              0.954395   \n",
       "30                   0.993935                 0.994578              0.956420   \n",
       "31                   0.993820                 0.994505              0.955605   \n",
       "\n",
       "    unweighted_aat_score_0.57  weighted_aat_score_0.57  auroc_threshold_0.57  \\\n",
       "0                    0.986095                 0.987489              0.962575   \n",
       "1                    0.989830                 0.990923              0.964593   \n",
       "2                    0.991035                 0.992037              0.966680   \n",
       "3                    0.991515                 0.992437              0.966827   \n",
       "4                    0.988450                 0.989629              0.962530   \n",
       "5                    0.990980                 0.991985              0.963685   \n",
       "6                    0.992250                 0.993096              0.964795   \n",
       "7                    0.991945                 0.992804              0.964935   \n",
       "8                    0.988380                 0.989596              0.963130   \n",
       "9                    0.990670                 0.991684              0.961910   \n",
       "10                   0.991820                 0.992673              0.962153   \n",
       "11                   0.991810                 0.992692              0.962773   \n",
       "12                   0.988580                 0.989756              0.958337   \n",
       "13                   0.991430                 0.992327              0.958747   \n",
       "14                   0.991685                 0.992527              0.959975   \n",
       "15                   0.991835                 0.992735              0.959635   \n",
       "16                   0.986205                 0.987640              0.962647   \n",
       "17                   0.990475                 0.991489              0.964902   \n",
       "18                   0.991460                 0.992392              0.966665   \n",
       "19                   0.991715                 0.992594              0.966713   \n",
       "20                   0.988095                 0.989404              0.962267   \n",
       "21                   0.991210                 0.992145              0.963460   \n",
       "22                   0.992195                 0.993033              0.963978   \n",
       "23                   0.991905                 0.992818              0.964798   \n",
       "24                   0.988435                 0.989700              0.963873   \n",
       "25                   0.990235                 0.991291              0.960805   \n",
       "26                   0.991425                 0.992304              0.962020   \n",
       "27                   0.991850                 0.992739              0.963320   \n",
       "28                   0.988110                 0.989313              0.957573   \n",
       "29                   0.991360                 0.992269              0.958808   \n",
       "30                   0.991830                 0.992697              0.960665   \n",
       "31                   0.991350                 0.992315              0.959092   \n",
       "\n",
       "    unweighted_aat_score_0.58  weighted_aat_score_0.58  auroc_threshold_0.58  \\\n",
       "0                    0.984360                 0.985895              0.965803   \n",
       "1                    0.987705                 0.988989              0.967385   \n",
       "2                    0.988365                 0.989643              0.968577   \n",
       "3                    0.989200                 0.990372              0.969085   \n",
       "4                    0.986885                 0.988230              0.966185   \n",
       "5                    0.988890                 0.990075              0.966755   \n",
       "6                    0.989670                 0.990792              0.967690   \n",
       "7                    0.989630                 0.990683              0.967690   \n",
       "8                    0.986300                 0.987742              0.966020   \n",
       "9                    0.988915                 0.990100              0.966060   \n",
       "10                   0.989630                 0.990697              0.965395   \n",
       "11                   0.989795                 0.990880              0.965965   \n",
       "12                   0.987340                 0.988622              0.962918   \n",
       "13                   0.989625                 0.990706              0.962445   \n",
       "14                   0.989340                 0.990409              0.962757   \n",
       "15                   0.989535                 0.990652              0.963060   \n",
       "16                   0.984310                 0.985946              0.965525   \n",
       "17                   0.988290                 0.989507              0.967797   \n",
       "18                   0.988910                 0.990105              0.969080   \n",
       "19                   0.989035                 0.990206              0.969152   \n",
       "20                   0.986455                 0.987922              0.965667   \n",
       "21                   0.988985                 0.990104              0.966695   \n",
       "22                   0.989375                 0.990518              0.966517   \n",
       "23                   0.989700                 0.990832              0.967677   \n",
       "24                   0.986435                 0.987916              0.966762   \n",
       "25                   0.988550                 0.989773              0.964940   \n",
       "26                   0.989420                 0.990506              0.965670   \n",
       "27                   0.989730                 0.990818              0.966247   \n",
       "28                   0.986810                 0.988133              0.962043   \n",
       "29                   0.989475                 0.990537              0.962492   \n",
       "30                   0.989680                 0.990750              0.963415   \n",
       "31                   0.988820                 0.990051              0.962255   \n",
       "\n",
       "    unweighted_aat_score_0.59  weighted_aat_score_0.59  auroc_threshold_0.59  \\\n",
       "0                    0.982255                 0.983981              0.968137   \n",
       "1                    0.985930                 0.987372              0.970220   \n",
       "2                    0.985405                 0.986975              0.970608   \n",
       "3                    0.986760                 0.988168              0.971233   \n",
       "4                    0.985120                 0.986642              0.968708   \n",
       "5                    0.987005                 0.988355              0.969560   \n",
       "6                    0.987200                 0.988552              0.969828   \n",
       "7                    0.987215                 0.988494              0.969910   \n",
       "8                    0.983415                 0.985138              0.968357   \n",
       "9                    0.987195                 0.988549              0.968908   \n",
       "10                   0.987385                 0.988676              0.968453   \n",
       "11                   0.987435                 0.988774              0.968828   \n",
       "12                   0.985455                 0.986920              0.965650   \n",
       "13                   0.988185                 0.989425              0.966100   \n",
       "14                   0.987220                 0.988504              0.965500   \n",
       "15                   0.987600                 0.988883              0.965705   \n",
       "16                   0.982185                 0.984013              0.967927   \n",
       "17                   0.986485                 0.987882              0.970683   \n",
       "18                   0.985985                 0.987449              0.970882   \n",
       "19                   0.986420                 0.987836              0.970990   \n",
       "20                   0.984945                 0.986556              0.968353   \n",
       "21                   0.987010                 0.988316              0.969253   \n",
       "22                   0.986840                 0.988222              0.968797   \n",
       "23                   0.987345                 0.988694              0.969915   \n",
       "24                   0.983785                 0.985540              0.969065   \n",
       "25                   0.986775                 0.988181              0.968107   \n",
       "26                   0.987340                 0.988627              0.968448   \n",
       "27                   0.987400                 0.988728              0.968867   \n",
       "28                   0.984955                 0.986470              0.965045   \n",
       "29                   0.988065                 0.989262              0.966092   \n",
       "30                   0.987455                 0.988721              0.966262   \n",
       "31                   0.986905                 0.988326              0.965275   \n",
       "\n",
       "    unweighted_aat_score_0.6  weighted_aat_score_0.6  auroc_threshold_0.6  \\\n",
       "0                   0.979865                0.981821             0.970407   \n",
       "1                   0.983535                0.985212             0.972093   \n",
       "2                   0.982820                0.984628             0.972300   \n",
       "3                   0.984265                0.985901             0.972842   \n",
       "4                   0.981700                0.983586             0.970315   \n",
       "5                   0.985600                0.987087             0.971730   \n",
       "6                   0.985310                0.986852             0.972035   \n",
       "7                   0.985095                0.986567             0.971873   \n",
       "8                   0.979330                0.981430             0.969053   \n",
       "9                   0.985075                0.986667             0.970955   \n",
       "10                  0.984940                0.986454             0.970815   \n",
       "11                  0.985230                0.986807             0.970625   \n",
       "12                  0.982620                0.984368             0.967365   \n",
       "13                  0.986545                0.987929             0.968907   \n",
       "14                  0.985220                0.986692             0.967992   \n",
       "15                  0.985505                0.986948             0.968255   \n",
       "16                  0.979600                0.981670             0.970032   \n",
       "17                  0.984440                0.986033             0.972825   \n",
       "18                  0.983460                0.985156             0.972685   \n",
       "19                  0.983665                0.985352             0.972695   \n",
       "20                  0.981400                0.983388             0.969745   \n",
       "21                  0.985305                0.986782             0.971340   \n",
       "22                  0.984785                0.986361             0.971075   \n",
       "23                  0.985105                0.986664             0.971782   \n",
       "24                  0.979800                0.981948             0.969685   \n",
       "25                  0.984760                0.986361             0.970200   \n",
       "26                  0.984755                0.986267             0.970457   \n",
       "27                  0.985100                0.986661             0.970615   \n",
       "28                  0.982330                0.984111             0.967218   \n",
       "29                  0.986530                0.987880             0.968750   \n",
       "30                  0.985465                0.986915             0.968740   \n",
       "31                  0.984785                0.986395             0.967665   \n",
       "\n",
       "    unweighted_aat_score_0.61  weighted_aat_score_0.61  auroc_threshold_0.61  \\\n",
       "0                    0.976760                 0.979006              0.971695   \n",
       "1                    0.980805                 0.982771              0.973455   \n",
       "2                    0.980080                 0.982134              0.973180   \n",
       "3                    0.981630                 0.983489              0.973945   \n",
       "4                    0.977970                 0.980225              0.970880   \n",
       "5                    0.983155                 0.984935              0.973290   \n",
       "6                    0.982695                 0.984497              0.973205   \n",
       "7                    0.982420                 0.984164              0.973045   \n",
       "8                    0.975820                 0.978177              0.970065   \n",
       "9                    0.982355                 0.984199              0.972200   \n",
       "10                   0.982070                 0.983832              0.972120   \n",
       "11                   0.982075                 0.983947              0.971670   \n",
       "12                   0.980270                 0.982217              0.968820   \n",
       "13                   0.984365                 0.985986              0.970750   \n",
       "14                   0.982220                 0.983979              0.969340   \n",
       "15                   0.982845                 0.984543              0.969752   \n",
       "16                   0.976175                 0.978530              0.971205   \n",
       "17                   0.981810                 0.983683              0.974250   \n",
       "18                   0.980735                 0.982708              0.973805   \n",
       "19                   0.980965                 0.982913              0.973710   \n",
       "20                   0.976700                 0.979114              0.969910   \n",
       "21                   0.982800                 0.984570              0.972923   \n",
       "22                   0.982315                 0.984122              0.972437   \n",
       "23                   0.982295                 0.984171              0.972813   \n",
       "24                   0.976310                 0.978730              0.970422   \n",
       "25                   0.981730                 0.983628              0.971463   \n",
       "26                   0.981945                 0.983732              0.971580   \n",
       "27                   0.982315                 0.984127              0.971850   \n",
       "28                   0.979925                 0.981952              0.968870   \n",
       "29                   0.984240                 0.985813              0.970643   \n",
       "30                   0.982385                 0.984122              0.970125   \n",
       "31                   0.982095                 0.983969              0.969353   \n",
       "\n",
       "    unweighted_aat_score_0.62  weighted_aat_score_0.62  auroc_threshold_0.62  \\\n",
       "0                    0.973760                 0.976327              0.972572   \n",
       "1                    0.977650                 0.979894              0.974145   \n",
       "2                    0.976720                 0.979106              0.973935   \n",
       "3                    0.978590                 0.980770              0.974853   \n",
       "4                    0.974250                 0.976779              0.971653   \n",
       "5                    0.978810                 0.980957              0.973725   \n",
       "6                    0.979080                 0.981195              0.973742   \n",
       "7                    0.979255                 0.981302              0.973843   \n",
       "8                    0.973515                 0.976098              0.971235   \n",
       "9                    0.978640                 0.980850              0.972903   \n",
       "10                   0.978915                 0.980963              0.973137   \n",
       "11                   0.978880                 0.981040              0.972530   \n",
       "12                   0.978370                 0.980544              0.970550   \n",
       "13                   0.980795                 0.982729              0.971392   \n",
       "14                   0.979170                 0.981159              0.970222   \n",
       "15                   0.980335                 0.982224              0.970840   \n",
       "16                   0.973440                 0.976079              0.972202   \n",
       "17                   0.978340                 0.980529              0.974662   \n",
       "18                   0.977285                 0.979637              0.974395   \n",
       "19                   0.977665                 0.979901              0.974332   \n",
       "20                   0.973055                 0.975782              0.971307   \n",
       "21                   0.978170                 0.980350              0.973317   \n",
       "22                   0.978675                 0.980804              0.973073   \n",
       "23                   0.979045                 0.981213              0.973560   \n",
       "24                   0.973525                 0.976175              0.971592   \n",
       "25                   0.977950                 0.980223              0.972350   \n",
       "26                   0.978650                 0.980738              0.972643   \n",
       "27                   0.979060                 0.981165              0.972760   \n",
       "28                   0.977930                 0.980184              0.970440   \n",
       "29                   0.980695                 0.982596              0.971305   \n",
       "30                   0.979440                 0.981424              0.970902   \n",
       "31                   0.979415                 0.981530              0.970385   \n",
       "\n",
       "    unweighted_aat_score_0.63  weighted_aat_score_0.63  auroc_threshold_0.63  \\\n",
       "0                    0.969485                 0.972494              0.972225   \n",
       "1                    0.973310                 0.975961              0.973923   \n",
       "2                    0.972655                 0.975412              0.973888   \n",
       "3                    0.974800                 0.977315              0.974712   \n",
       "4                    0.970490                 0.973408              0.971645   \n",
       "5                    0.974635                 0.977113              0.973933   \n",
       "6                    0.975230                 0.977661              0.974165   \n",
       "7                    0.975545                 0.977910              0.974212   \n",
       "8                    0.969655                 0.972640              0.971152   \n",
       "9                    0.975100                 0.977611              0.973515   \n",
       "10                   0.975735                 0.978077              0.973692   \n",
       "11                   0.975920                 0.978354              0.973577   \n",
       "12                   0.972455                 0.975239              0.969720   \n",
       "13                   0.977780                 0.980002              0.971960   \n",
       "14                   0.975870                 0.978185              0.971070   \n",
       "15                   0.977655                 0.979804              0.971645   \n",
       "16                   0.969155                 0.972218              0.971928   \n",
       "17                   0.974185                 0.976796              0.974480   \n",
       "18                   0.972925                 0.975652              0.974005   \n",
       "19                   0.973515                 0.976136              0.973997   \n",
       "20                   0.969430                 0.972461              0.971420   \n",
       "21                   0.974175                 0.976668              0.973533   \n",
       "22                   0.974670                 0.977127              0.973285   \n",
       "23                   0.974960                 0.977464              0.973613   \n",
       "24                   0.969970                 0.972973              0.971492   \n",
       "25                   0.974620                 0.977211              0.972973   \n",
       "26                   0.975345                 0.977748              0.973065   \n",
       "27                   0.976110                 0.978477              0.973525   \n",
       "28                   0.971915                 0.974797              0.969653   \n",
       "29                   0.977915                 0.980090              0.971847   \n",
       "30                   0.976205                 0.978490              0.971815   \n",
       "31                   0.976460                 0.978845              0.971232   \n",
       "\n",
       "    unweighted_aat_score_0.64  weighted_aat_score_0.64  auroc_threshold_0.64  \\\n",
       "0                    0.963615                 0.967204              0.970755   \n",
       "1                    0.968395                 0.971567              0.973185   \n",
       "2                    0.968355                 0.971580              0.973140   \n",
       "3                    0.970895                 0.973837              0.974085   \n",
       "4                    0.966665                 0.969901              0.971302   \n",
       "5                    0.970800                 0.973674              0.973633   \n",
       "6                    0.971590                 0.974387              0.973840   \n",
       "7                    0.972060                 0.974753              0.974160   \n",
       "8                    0.965365                 0.968803              0.970938   \n",
       "9                    0.971740                 0.974555              0.973640   \n",
       "10                   0.971675                 0.974440              0.973610   \n",
       "11                   0.971910                 0.974703              0.973455   \n",
       "12                   0.968590                 0.971666              0.969840   \n",
       "13                   0.974150                 0.976675              0.972315   \n",
       "14                   0.972430                 0.975064              0.971473   \n",
       "15                   0.974395                 0.976856              0.972202   \n",
       "16                   0.963940                 0.967494              0.970700   \n",
       "17                   0.969100                 0.972244              0.973398   \n",
       "18                   0.968840                 0.971985              0.973330   \n",
       "19                   0.969550                 0.972574              0.973380   \n",
       "20                   0.965625                 0.969020              0.970880   \n",
       "21                   0.969985                 0.972940              0.973067   \n",
       "22                   0.970870                 0.973691              0.972990   \n",
       "23                   0.971440                 0.974319              0.973680   \n",
       "24                   0.965850                 0.969238              0.971188   \n",
       "25                   0.971030                 0.973965              0.973242   \n",
       "26                   0.971610                 0.974344              0.973155   \n",
       "27                   0.972325                 0.975039              0.973747   \n",
       "28                   0.968180                 0.971311              0.969728   \n",
       "29                   0.974200                 0.976688              0.972082   \n",
       "30                   0.973035                 0.975605              0.972325   \n",
       "31                   0.973095                 0.975829              0.971713   \n",
       "\n",
       "    unweighted_aat_score_0.65  weighted_aat_score_0.65  auroc_threshold_0.65  \n",
       "0                    0.957215                 0.961424              0.969248  \n",
       "1                    0.962755                 0.966526              0.971765  \n",
       "2                    0.962820                 0.966603              0.972060  \n",
       "3                    0.965475                 0.969023              0.972978  \n",
       "4                    0.962620                 0.966285              0.970373  \n",
       "5                    0.965130                 0.968530              0.972110  \n",
       "6                    0.967135                 0.970427              0.973037  \n",
       "7                    0.967700                 0.970844              0.973100  \n",
       "8                    0.960320                 0.964179              0.969767  \n",
       "9                    0.966310                 0.969696              0.972247  \n",
       "10                   0.967510                 0.970709              0.973287  \n",
       "11                   0.967575                 0.970808              0.972710  \n",
       "12                   0.964675                 0.968124              0.969840  \n",
       "13                   0.969385                 0.972371              0.971662  \n",
       "14                   0.968780                 0.971725              0.971435  \n",
       "15                   0.970805                 0.973616              0.972257  \n",
       "16                   0.957290                 0.961446              0.968923  \n",
       "17                   0.963160                 0.966878              0.971880  \n",
       "18                   0.962710                 0.966451              0.971967  \n",
       "19                   0.964265                 0.967895              0.972328  \n",
       "20                   0.961535                 0.965359              0.969938  \n",
       "21                   0.964635                 0.968080              0.971782  \n",
       "22                   0.966350                 0.969670              0.972283  \n",
       "23                   0.967070                 0.970382              0.972700  \n",
       "24                   0.960525                 0.964391              0.969817  \n",
       "25                   0.965210                 0.968739              0.971675  \n",
       "26                   0.967255                 0.970421              0.972747  \n",
       "27                   0.968065                 0.971218              0.973038  \n",
       "28                   0.964400                 0.967957              0.969735  \n",
       "29                   0.969460                 0.972412              0.971558  \n",
       "30                   0.969560                 0.972473              0.972252  \n",
       "31                   0.969385                 0.972458              0.971705  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7670b5-6861-4eb8-a980-117a9b3c9b02",
   "metadata": {},
   "source": [
    "### Ensamble Model (To Do)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaa0956-b395-438b-9d98-8830f95e611d",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486c736d-2685-4f0a-bfc5-edb7e39898f3",
   "metadata": {},
   "source": [
    "Make sure `model_run_data_path` is set in settings to the tuning result path.\n",
    "Make sure `model_type` is set in settings to `XGBRegression`, `Isolation Forest`, or `Ensemble`\n",
    "\n",
    "Call `model_selector = model_selection_main.get_model_selector(settings)` to get the appropriate selector.\n",
    "Then call `model_selector.get_top_models()` to get the top models\n",
    "\n",
    "To get the candidate model that matches one of the top_model:\n",
    "     Call `model_selector.get_candidate_model_by_index(INDEX)` to get the candidate model\n",
    "     Call `model_selector.get_candidate_model_params_by_index(INDEX)` to get the candidate model params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee74b4-5174-4101-b80a-53fa0e2f94a2",
   "metadata": {},
   "source": [
    "### XG Boost Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df972c0-4b9d-4c74-88b5-554a3a04f01a",
   "metadata": {},
   "source": [
    "For `model_run_data_path` right click the file in side nav and choose `Copy Path`. Paste that and add a `/root/` before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e0682a4-e259-46ed-8cef-f753993ccf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using result:  model_runs/xgboost_regression/tuning_results_run_2022-11-24-23h13m.csv\n"
     ]
    }
   ],
   "source": [
    "list_of_runs = glob.glob(f\"{settings.get('run_save_path')}/xgboost_regression/*.csv\")\n",
    "latest_run = max(list_of_runs, key=os.path.getctime)\n",
    "print(\"Using result: \", latest_run)\n",
    "\n",
    "xgbr_settings = {\n",
    "    \"model_run_data_path\": latest_run,    \n",
    "    \"model_type\": \"XGBRegression\"\n",
    "}\n",
    "\n",
    "settings = {**settings, **xgbr_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d315d07a-d9f9-48b6-9b4f-a373326be515",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_eta</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>-6.1666</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'eta': 0.05, 'gamma': 0, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>-6.1666</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 2, 'eta': 0.05, 'gamma': 1, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>-6.1667</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 2, 'eta': 0.05, 'gamma': 0, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>-6.1668</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 2, 'eta': 0.05, 'gamma': 0, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>-6.1668</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'eta': 0.05, 'gamma': 1, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>-6.1669</td>\n",
       "      <td>0.1108</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 2, 'eta': 0.05, 'gamma': 2, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>-6.1669</td>\n",
       "      <td>0.1107</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 2, 'eta': 0.05, 'gamma': 2, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>-6.1670</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 2, 'eta': 0.05, 'gamma': 1, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>-6.1670</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'eta': 0.05, 'gamma': 2, 'max_dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-6.1670</td>\n",
       "      <td>0.1107</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0, 'eta': 0.05, 'gamma': 1, 'max_dep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_score  std_test_score  rank_test_score  param_alpha  param_eta  \\\n",
       "422          -6.1666          0.1098                1            1       0.05   \n",
       "876          -6.1666          0.1110                2            2       0.05   \n",
       "841          -6.1667          0.1105                3            2       0.05   \n",
       "842          -6.1668          0.1095                5            2       0.05   \n",
       "457          -6.1668          0.1099                4            1       0.05   \n",
       "913          -6.1669          0.1108                6            2       0.05   \n",
       "911          -6.1669          0.1107                7            2       0.05   \n",
       "879          -6.1670          0.1098                8            2       0.05   \n",
       "492          -6.1670          0.1100                9            1       0.05   \n",
       "36           -6.1670          0.1107               10            0       0.05   \n",
       "\n",
       "     param_gamma  param_max_depth  param_min_child_weight  param_subsample  \\\n",
       "422            0                5                       5                1   \n",
       "876            1                5                       4                1   \n",
       "841            0                5                       4                1   \n",
       "842            0                5                       5                1   \n",
       "457            1                5                       5                1   \n",
       "913            2                5                       6                1   \n",
       "911            2                5                       4                1   \n",
       "879            1                5                       7                1   \n",
       "492            2                5                       5                1   \n",
       "36             1                5                       4                1   \n",
       "\n",
       "                                                params  \n",
       "422  {'alpha': 1, 'eta': 0.05, 'gamma': 0, 'max_dep...  \n",
       "876  {'alpha': 2, 'eta': 0.05, 'gamma': 1, 'max_dep...  \n",
       "841  {'alpha': 2, 'eta': 0.05, 'gamma': 0, 'max_dep...  \n",
       "842  {'alpha': 2, 'eta': 0.05, 'gamma': 0, 'max_dep...  \n",
       "457  {'alpha': 1, 'eta': 0.05, 'gamma': 1, 'max_dep...  \n",
       "913  {'alpha': 2, 'eta': 0.05, 'gamma': 2, 'max_dep...  \n",
       "911  {'alpha': 2, 'eta': 0.05, 'gamma': 2, 'max_dep...  \n",
       "879  {'alpha': 2, 'eta': 0.05, 'gamma': 1, 'max_dep...  \n",
       "492  {'alpha': 1, 'eta': 0.05, 'gamma': 2, 'max_dep...  \n",
       "36   {'alpha': 0, 'eta': 0.05, 'gamma': 1, 'max_dep...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_model_selector = model_selection_svc.get_model_selector(settings)\n",
    "xgbr_model_selector.get_top_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43b862ce-121f-4db8-827e-d324b75a83ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_fit_time         3.6701\n",
       "std_fit_time          1.0238\n",
       "mean_score_time       0.0426\n",
       "std_score_time        0.0185\n",
       "param_alpha                2\n",
       "                       ...  \n",
       "split48_test_score   -6.2507\n",
       "split49_test_score   -6.1072\n",
       "mean_test_score      -6.1684\n",
       "std_test_score        0.1103\n",
       "rank_test_score           92\n",
       "Name: 846, Length: 64, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_model_index = 846\n",
    "xgbr_model_selector.get_candidate_model_by_index(xgbr_model_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "049b75c5-3523-45ee-88e6-eec4e8f25366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 2,\n",
       " 'eta': 0.05,\n",
       " 'gamma': 0,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 9,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_model_selector.get_candidate_model_params_by_index(xgbr_model_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb4fcb5-b42b-4f0a-a17f-830eba733fc2",
   "metadata": {},
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb92f7-f579-4012-a158-dfd54685372c",
   "metadata": {},
   "source": [
    "For `model_run_data_path` right click the file in side nav and choose `Copy Path`. Paste that and add a `/root/` before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37af21d1-5cf0-46c3-8b22-5d7edd3f946c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using result:  model_runs/isolation_forest/tuning_results_run_2022-11-25-01h53m.csv\n"
     ]
    }
   ],
   "source": [
    "list_of_runs = glob.glob(f\"{settings.get('run_save_path')}/isolation_forest/*.csv\")\n",
    "latest_run = max(list_of_runs, key=os.path.getctime)\n",
    "print(\"Using result: \", latest_run)\n",
    "\n",
    "if_settings = {\n",
    "    \"model_run_data_path\": latest_run,    \n",
    "    \"model_type\": \"Isolation Forest\"\n",
    "}\n",
    "\n",
    "settings = {**settings, **if_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6629071-31f7-4e3b-b2ec-0ade296ebbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>features_included</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>model_id</th>\n",
       "      <th>auroc_total</th>\n",
       "      <th>auroc_threshold_0.5</th>\n",
       "      <th>auroc_threshold_0.51</th>\n",
       "      <th>auroc_threshold_0.52</th>\n",
       "      <th>auroc_threshold_0.53</th>\n",
       "      <th>auroc_threshold_0.54</th>\n",
       "      <th>auroc_threshold_0.55</th>\n",
       "      <th>auroc_threshold_0.56</th>\n",
       "      <th>auroc_threshold_0.57</th>\n",
       "      <th>auroc_threshold_0.58</th>\n",
       "      <th>auroc_threshold_0.59</th>\n",
       "      <th>auroc_threshold_0.6</th>\n",
       "      <th>auroc_threshold_0.61</th>\n",
       "      <th>auroc_threshold_0.62</th>\n",
       "      <th>auroc_threshold_0.63</th>\n",
       "      <th>auroc_threshold_0.64</th>\n",
       "      <th>auroc_threshold_0.65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>0.9170</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.9629</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.9747</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>0.9730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.9075</td>\n",
       "      <td>0.9210</td>\n",
       "      <td>0.9323</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>0.9484</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>0.9677</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.9720</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.9738</td>\n",
       "      <td>0.9730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9159</td>\n",
       "      <td>0.9269</td>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>0.9732</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>0.9721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.9220</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.9494</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.9607</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9677</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9738</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.9742</td>\n",
       "      <td>0.9731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>19</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9157</td>\n",
       "      <td>0.9267</td>\n",
       "      <td>0.9374</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.9527</td>\n",
       "      <td>0.9588</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.9709</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.9738</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.9720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>True</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>24</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.9220</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.9414</td>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>0.9677</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>0.9736</td>\n",
       "      <td>0.9736</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.9727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>True</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>300</td>\n",
       "      <td>28</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>0.9173</td>\n",
       "      <td>0.9295</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9591</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.9730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>False</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>300</td>\n",
       "      <td>12</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9033</td>\n",
       "      <td>0.9170</td>\n",
       "      <td>0.9292</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.9589</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.9717</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9736</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>0.9727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>True</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9169</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.9383</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>0.9587</td>\n",
       "      <td>0.9631</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>0.9740</td>\n",
       "      <td>0.9734</td>\n",
       "      <td>0.9723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>True</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>23</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9398</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.9711</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.9723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bootstrap           features_included  max_features max_samples  \\\n",
       "3       False  [lag_diff, prov_mean_diff]             1        auto   \n",
       "6       False  [lag_diff, prov_mean_diff]             1         200   \n",
       "2       False  [lag_diff, prov_mean_diff]             1        auto   \n",
       "7       False  [lag_diff, prov_mean_diff]             1         200   \n",
       "18       True  [lag_diff, prov_mean_diff]             1        auto   \n",
       "23       True  [lag_diff, prov_mean_diff]             1         200   \n",
       "27       True  [lag_diff, prov_mean_diff]             1         175   \n",
       "11      False  [lag_diff, prov_mean_diff]             1         175   \n",
       "19       True  [lag_diff, prov_mean_diff]             1        auto   \n",
       "22       True  [lag_diff, prov_mean_diff]             1         200   \n",
       "\n",
       "    n_estimators  model_id  auroc_total  auroc_threshold_0.5  \\\n",
       "3            300         4       0.9961               0.9170   \n",
       "6            200         7       0.9960               0.9075   \n",
       "2            200         3       0.9959               0.9159   \n",
       "7            300         8       0.9959               0.9101   \n",
       "18           200        19       0.9959               0.9157   \n",
       "23           300        24       0.9959               0.9092   \n",
       "27           300        28       0.9959               0.9038   \n",
       "11           300        12       0.9958               0.9033   \n",
       "19           300        20       0.9958               0.9169   \n",
       "22           200        23       0.9958               0.9052   \n",
       "\n",
       "    auroc_threshold_0.51  auroc_threshold_0.52  auroc_threshold_0.53  \\\n",
       "3                 0.9287                0.9388                0.9462   \n",
       "6                 0.9210                0.9323                0.9407   \n",
       "2                 0.9269                0.9376                0.9456   \n",
       "7                 0.9220                0.9334                0.9417   \n",
       "18                0.9267                0.9374                0.9455   \n",
       "23                0.9220                0.9328                0.9414   \n",
       "27                0.9173                0.9295                0.9388   \n",
       "11                0.9170                0.9292                0.9385   \n",
       "19                0.9279                0.9383                0.9463   \n",
       "22                0.9187                0.9307                0.9398   \n",
       "\n",
       "    auroc_threshold_0.54  auroc_threshold_0.55  auroc_threshold_0.56  \\\n",
       "3                 0.9531                0.9585                0.9629   \n",
       "6                 0.9484                0.9548                0.9605   \n",
       "2                 0.9526                0.9583                0.9628   \n",
       "7                 0.9494                0.9560                0.9607   \n",
       "18                0.9527                0.9588                0.9630   \n",
       "23                0.9489                0.9555                0.9603   \n",
       "27                0.9471                0.9537                0.9591   \n",
       "11                0.9465                0.9532                0.9589   \n",
       "19                0.9526                0.9587                0.9631   \n",
       "22                0.9474                0.9545                0.9603   \n",
       "\n",
       "    auroc_threshold_0.57  auroc_threshold_0.58  auroc_threshold_0.59  \\\n",
       "3                 0.9668                0.9691                0.9712   \n",
       "6                 0.9648                0.9677                0.9698   \n",
       "2                 0.9667                0.9686                0.9706   \n",
       "7                 0.9649                0.9677                0.9699   \n",
       "18                0.9667                0.9691                0.9709   \n",
       "23                0.9648                0.9677                0.9699   \n",
       "27                0.9633                0.9662                0.9689   \n",
       "11                0.9628                0.9660                0.9688   \n",
       "19                0.9667                0.9692                0.9710   \n",
       "22                0.9640                0.9665                0.9688   \n",
       "\n",
       "    auroc_threshold_0.6  auroc_threshold_0.61  auroc_threshold_0.62  \\\n",
       "3                0.9728                0.9739                0.9749   \n",
       "6                0.9720                0.9732                0.9737   \n",
       "2                0.9723                0.9732                0.9739   \n",
       "7                0.9719                0.9730                0.9738   \n",
       "18               0.9727                0.9738                0.9744   \n",
       "23               0.9718                0.9728                0.9736   \n",
       "27               0.9706                0.9719                0.9728   \n",
       "11               0.9706                0.9717                0.9725   \n",
       "19               0.9727                0.9737                0.9743   \n",
       "22               0.9711                0.9724                0.9731   \n",
       "\n",
       "    auroc_threshold_0.63  auroc_threshold_0.64  auroc_threshold_0.65  \n",
       "3                 0.9747                0.9741                0.9730  \n",
       "6                 0.9742                0.9738                0.9730  \n",
       "2                 0.9739                0.9731                0.9721  \n",
       "7                 0.9742                0.9742                0.9731  \n",
       "18                0.9740                0.9733                0.9720  \n",
       "23                0.9736                0.9737                0.9727  \n",
       "27                0.9735                0.9737                0.9730  \n",
       "11                0.9736                0.9735                0.9727  \n",
       "19                0.9740                0.9734                0.9723  \n",
       "22                0.9733                0.9730                0.9723  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_model_selector = model_selection_svc.get_model_selector(settings)\n",
    "if_model_selector.get_top_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4533c696-1972-45e7-bbf3-e0fecf797ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>features_included</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>model_id</th>\n",
       "      <th>auroc_total</th>\n",
       "      <th>auroc_threshold_0.5</th>\n",
       "      <th>auroc_threshold_0.51</th>\n",
       "      <th>auroc_threshold_0.52</th>\n",
       "      <th>auroc_threshold_0.53</th>\n",
       "      <th>auroc_threshold_0.54</th>\n",
       "      <th>auroc_threshold_0.55</th>\n",
       "      <th>auroc_threshold_0.56</th>\n",
       "      <th>auroc_threshold_0.57</th>\n",
       "      <th>auroc_threshold_0.58</th>\n",
       "      <th>auroc_threshold_0.59</th>\n",
       "      <th>auroc_threshold_0.6</th>\n",
       "      <th>auroc_threshold_0.61</th>\n",
       "      <th>auroc_threshold_0.62</th>\n",
       "      <th>auroc_threshold_0.63</th>\n",
       "      <th>auroc_threshold_0.64</th>\n",
       "      <th>auroc_threshold_0.65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>True</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>23</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.9052</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>0.9398</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.9711</td>\n",
       "      <td>0.9724</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.9723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bootstrap           features_included  max_features max_samples  \\\n",
       "22       True  [lag_diff, prov_mean_diff]             1         200   \n",
       "\n",
       "    n_estimators  model_id  auroc_total  auroc_threshold_0.5  \\\n",
       "22           200        23       0.9958               0.9052   \n",
       "\n",
       "    auroc_threshold_0.51  auroc_threshold_0.52  auroc_threshold_0.53  \\\n",
       "22                0.9187                0.9307                0.9398   \n",
       "\n",
       "    auroc_threshold_0.54  auroc_threshold_0.55  auroc_threshold_0.56  \\\n",
       "22                0.9474                0.9545                0.9603   \n",
       "\n",
       "    auroc_threshold_0.57  auroc_threshold_0.58  auroc_threshold_0.59  \\\n",
       "22                 0.964                0.9665                0.9688   \n",
       "\n",
       "    auroc_threshold_0.6  auroc_threshold_0.61  auroc_threshold_0.62  \\\n",
       "22               0.9711                0.9724                0.9731   \n",
       "\n",
       "    auroc_threshold_0.63  auroc_threshold_0.64  auroc_threshold_0.65  \n",
       "22                0.9733                 0.973                0.9723  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_model_id = 23\n",
    "if_model_selector.get_candidate_model_by_index(if_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e570f77c-a9a0-40d6-a927-cee014e5b5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'features_included': ['lag_diff', 'prov_mean_diff'],\n",
       " 'max_features': 1,\n",
       " 'max_samples': 200,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_model_selector.get_candidate_model_params_by_index(if_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c95ce6f-a963-4927-b664-ba050d8f3bd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ensemble (Not yet Implemented)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ffaf0e-630e-47b0-b034-a614e5e88a56",
   "metadata": {},
   "source": [
    "## Final Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f12e97-fb6f-4967-bba9-058426e1ffa8",
   "metadata": {},
   "source": [
    "### XGBoost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "665e8760-a94a-400b-aef8-6730cc3a1944",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_final_fit_settings = {\n",
    "    \"model_type\": \"XGBRegression\",\n",
    "    \"model_dataset_path\": settings.get('save_modeling_dataset_path'),\n",
    "    \"xgbr_final_params\": xgbr_model_selector.get_candidate_model_params_by_index(xgbr_model_index),\n",
    "    \"drop_cols\": xgbr_drop_cols,\n",
    "}\n",
    "\n",
    "settings = {**settings, **xgbr_final_fit_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b96b787-6727-408f-995c-9db6c94adfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = final_fitting_svc.get_final_fitter(settings)\n",
    "xgbr_model = fitter.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "529bee25-4ef7-4bbb-a9b3-ef5e343b1b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=2, base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False, eta=0.05,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.0500000007, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=9,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, objective='reg:squarederror',\n",
       "             predictor='auto', ...)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b7e2b1-b04f-4ed8-afd2-b17ed6365f09",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4daa1260-08de-4c73-a3a3-7f35b0cf0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_final_fit_settings = {\n",
    "    \"model_type\": \"Isolation Forest\",\n",
    "    \"model_dataset_path\": settings.get('save_modeling_dataset_path'),\n",
    "    \"if_final_params\": if_model_selector.get_candidate_model_params_by_index(if_model_id),\n",
    "    \"drop_cols\": if_drop_cols,\n",
    "}\n",
    "\n",
    "del if_final_fit_settings['if_final_params']['features_included']\n",
    "\n",
    "settings = {**settings, **if_final_fit_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "334d6c52-1cda-4beb-932e-69c7cf3943c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = final_fitting_svc.get_final_fitter(settings)\n",
    "if_model = fitter.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8772d7cb-f694-4e8b-8e2a-5759f3042b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(behaviour='deprecated', bootstrap=True, contamination='auto',\n",
       "                max_features=1, max_samples=200, n_estimators=200, n_jobs=-1,\n",
       "                random_state=RandomState(MT19937) at 0x7F8BC15F68D0, verbose=0,\n",
       "                warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3627d4a4-8deb-413f-9810-aeebd1f4e4ee",
   "metadata": {},
   "source": [
    "### Ensamble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4b4a61-4441-42eb-acfc-1535e6871af7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Outcome Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c9ee760-c986-4abc-911a-147b465e1fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_analysis_settings = {\n",
    "    \"if_model\": if_model,\n",
    "    \"if_outlier_prediction_threshold\": 0.59,\n",
    "\n",
    "    \"xgbr_model\": xgbr_model,\n",
    "    \"xgbr_x_cols\": ['year', 'quarter', 'lag1'],\n",
    "    \"xgbr_y_cols\": ['score'],\n",
    "    \"xgbr_outlier_prediction_threshold\": 15,\n",
    "}\n",
    "\n",
    "settings = {**settings, **outcome_analysis_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffb51a17-d7fe-4b34-841e-46f0bae416bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 2, got 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-0806f7a49337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_modeling_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_modeling_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutcome_analysis_svc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/HAIP/services/outcome_analysis/src/main.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mset_user_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mxgbr_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgboost_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mif_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misolation_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HAIP/services/outcome_analysis/src/main.py\u001b[0m in \u001b[0;36mxgboost_regression\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodeling_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxgbr_x_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodeling_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxgbr_y_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mxgb_predicted_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0moutlier_prediction_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgbr_outlier_prediction_threshold'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                     \u001b[0mbase_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                     \u001b[0mvalidate_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m                 )\n\u001b[1;32m   1057\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_is_cupy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m                 raise ValueError(\n\u001b[0;32m-> 2129\u001b[0;31m                     \u001b[0;34mf\"Feature shape mismatch, expected: {self.num_features()}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2130\u001b[0m                     \u001b[0;34mf\"got {data.shape[1]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: Feature shape mismatch, expected: 2, got 3"
     ]
    }
   ],
   "source": [
    "(comp, xgb_modeling_dataset, if_modeling_dataset) = outcome_analysis_svc.main(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d473a73c-5b47-4420-8fc4-316dce895636",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_modeling_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74efb0-6a52-44bf-97a2-3fd8780487aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_modeling_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34afc44b-6996-4ae7-9f80-999a7e42d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
