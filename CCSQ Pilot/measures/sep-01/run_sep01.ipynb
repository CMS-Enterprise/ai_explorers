{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d9608799-f60f-4bed-ba48-a2db7454c07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.6.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.21.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting the-teller\n",
      "  Downloading the_teller-0.8.0-py2.py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: pandas>=1.3.4 in /opt/conda/lib/python3.7/site-packages (from the-teller) (1.3.5)\n",
      "Collecting kiwisolver>=1.3.2\n",
      "  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=8.4.0 in /opt/conda/lib/python3.7/site-packages (from the-teller) (9.2.0)\n",
      "Collecting scikit-learn>=1.0.1\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.8/24.8 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.7.2 in /opt/conda/lib/python3.7/site-packages (from the-teller) (1.7.3)\n",
      "Requirement already satisfied: matplotlib>=3.1.3 in /opt/conda/lib/python3.7/site-packages (from the-teller) (3.1.3)\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2021.3\n",
      "  Downloading pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.11.0\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting seaborn>=0.11.2\n",
      "  Downloading seaborn-0.12.1-py3-none-any.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.4 in /opt/conda/lib/python3.7/site-packages (from the-teller) (1.21.6)\n",
      "Collecting threadpoolctl>=3.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting six>=1.16.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting joblib>=1.1.0\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.62.3\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing>=3.0.6\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.3.2->the-teller) (4.3.0)\n",
      "Installing collected packages: pytz, tqdm, threadpoolctl, six, pyparsing, kiwisolver, joblib, cycler, scikit-learn, python-dateutil, seaborn, the-teller\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2019.3\n",
      "    Uninstalling pytz-2019.3:\n",
      "      Successfully uninstalled pytz-2019.3\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.42.1\n",
      "    Uninstalling tqdm-4.42.1:\n",
      "      Successfully uninstalled tqdm-4.42.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.14.0\n",
      "    Uninstalling six-1.14.0:\n",
      "      Successfully uninstalled six-1.14.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.6\n",
      "    Uninstalling pyparsing-2.4.6:\n",
      "      Successfully uninstalled pyparsing-2.4.6\n",
      "  Attempting uninstall: kiwisolver\n",
      "    Found existing installation: kiwisolver 1.1.0\n",
      "    Uninstalling kiwisolver-1.1.0:\n",
      "      Successfully uninstalled kiwisolver-1.1.0\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 0.14.1\n",
      "    Uninstalling joblib-0.14.1:\n",
      "      Successfully uninstalled joblib-0.14.1\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.10.0\n",
      "    Uninstalling cycler-0.10.0:\n",
      "      Successfully uninstalled cycler-0.10.0\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: seaborn\n",
      "    Found existing installation: seaborn 0.10.0\n",
      "    Uninstalling seaborn-0.10.0:\n",
      "      Successfully uninstalled seaborn-0.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "docker-compose 1.29.2 requires PyYAML<6,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "awscli 1.25.63 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\n",
      "awscli 1.25.63 requires rsa<4.8,>=3.1.2, but you have rsa 4.9 which is incompatible.\n",
      "aiobotocore 2.3.4 requires botocore<1.24.22,>=1.24.21, but you have botocore 1.27.62 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cycler-0.11.0 joblib-1.2.0 kiwisolver-1.4.4 pyparsing-3.0.9 python-dateutil-2.8.2 pytz-2022.6 scikit-learn-1.0.2 seaborn-0.12.1 six-1.16.0 the-teller-0.8.0 threadpoolctl-3.1.0 tqdm-4.64.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69169f57-cb41-47ef-8b74-5a029c921042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Hardcode so we can use in any notebook\n",
    "module_path = \"/root/HAIP/notebooks/services\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9083a0a4-1f5f-4d19-9d70-7a1ed0310d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/HAIP/notebooks\n",
      "['/root/HAIP/notebooks/op-10', '/opt/conda/lib/python37.zip', '/opt/conda/lib/python3.7', '/opt/conda/lib/python3.7/lib-dynload', '', '/opt/conda/lib/python3.7/site-packages', '/opt/conda/lib/python3.7/site-packages/IPython/extensions', '/root/.ipython', '/root/HAIP/notebooks/services', '/root/HAIP/notebooks/config', '/root/HAIP/notebooks']\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from initial_tests.xgbr_test import test_xgbr\n",
    "from model_training.tune_xgboost_regression import tune_xgbr\n",
    "from model_training.tune_isolation_forest import tune_iforest\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "from xgboost import XGBRegressor\n",
    "from model_selection.src import main as model_selection_svc\n",
    "from artificial_anomaly_tests.aa_tests import artificial_anomaly_test_xgb\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import pickle\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00616a88-8398-4af3-b7e1-825eff445edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    # Measure specific options\n",
    "    \"SHAREPOINT_MEASURE_DIR\": \"OP-10 Clean\",\n",
    "    \"MEASURE_SPECIFIC_FILENAME\": \"OP-10.csv\",\n",
    "    \"FULL_MEASURE_S3_PREFIX\": \"OP-10\",\n",
    "    \"filter_measure\": \"OP_10\", # make sure this is _ not -\n",
    "    \n",
    "    # Feature Engineering options\n",
    "    \"save_modeling_dataset_path\": '/root/HAIP/notebooks/op-10/data/OP-10.csv',\n",
    "    \"backfill_prov_mean\": True, # set to false to not backfill prov mean\n",
    "    \"backfill_lag\": True, # set to false to not backfill lag\n",
    "    \"lag_to_add\": 2, # add lag1/lag2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827f42d3-bd54-4383-8e27-76c56fc59b65",
   "metadata": {},
   "source": [
    "# Need to set up Feature Engineering for TEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24fc8abe-6c9b-4c6e-afde-8e79d2b8d720",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_df = pd.read_csv(\"data/OP-10-no-backfill.csv\").drop(columns = ['provider_id','lag2']).dropna()\n",
    "xgbr_modeling_df = pd.read_csv(\"data/OP-10-no-backfill.csv\").drop(columns = ['provider_id','lag2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6b481c-91e4-47d5-ba29-fddbb86f5855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>lag1</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>lag_diff</th>\n",
       "      <th>prov_mean</th>\n",
       "      <th>prov_mean_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>3.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>-0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29089</th>\n",
       "      <td>7.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>3.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29090</th>\n",
       "      <td>1.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>-3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29092</th>\n",
       "      <td>12.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>-3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29093</th>\n",
       "      <td>8.7</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>-5.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29095</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>-4.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24799 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  lag1  year  quarter  lag_diff  prov_mean  prov_mean_diff\n",
       "1        6.5   4.6  2014        2       1.9   4.600000        1.900000\n",
       "2        6.4   6.5  2015        2      -0.1   5.550000        0.850000\n",
       "3        9.0   6.4  2016        2       2.6   5.833333        3.166667\n",
       "4        6.5   9.0  2017        2      -2.5   6.625000       -0.125000\n",
       "5        8.0   6.5  2018        2       1.5   6.600000        1.400000\n",
       "...      ...   ...   ...      ...       ...        ...             ...\n",
       "29089    7.5   6.6  2019        2       0.9   4.150000        3.350000\n",
       "29090    1.6   7.5  2019        4      -5.9   5.266667       -3.666667\n",
       "29092   12.6  16.1  2019        2      -3.5  16.100000       -3.500000\n",
       "29093    8.7  12.6  2019        4      -3.9  14.350000       -5.650000\n",
       "29095    1.0   5.5  2019        4      -4.5   5.500000       -4.500000\n",
       "\n",
       "[24799 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d1c810-cc51-4616-8b8d-a8f9a90b186b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>lag1</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>prov_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>5.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>5.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29082</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29086</th>\n",
       "      <td>63.2</td>\n",
       "      <td>69.2</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>69.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29088</th>\n",
       "      <td>6.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29089</th>\n",
       "      <td>7.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>4.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29092</th>\n",
       "      <td>12.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>16.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21694 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  lag1  year  quarter  prov_mean\n",
       "1        6.5   4.6  2014        2   4.600000\n",
       "2        6.4   6.5  2015        2   5.550000\n",
       "3        9.0   6.4  2016        2   5.833333\n",
       "4        6.5   9.0  2017        2   6.625000\n",
       "5        8.0   6.5  2018        2   6.600000\n",
       "...      ...   ...   ...      ...        ...\n",
       "29082    0.2   0.8  2018        2   1.000000\n",
       "29086   63.2  69.2  2018        2  69.200000\n",
       "29088    6.6   1.7  2018        2   1.700000\n",
       "29089    7.5   6.6  2019        2   4.150000\n",
       "29092   12.6  16.1  2019        2  16.100000\n",
       "\n",
       "[21694 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_modeling_df = xgbr_modeling_df[~((xgbr_modeling_df['year'] == 2019) & (xgbr_modeling_df['quarter'] == 4))].dropna()\n",
    "xgbr_modeling_df = xgbr_modeling_df.drop(columns = ['lag_diff', 'prov_mean_diff'])\n",
    "xgbr_modeling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9150f6e-0e7d-4122-b844-c2b350bfe961",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>lag1</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>prov_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>5.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>5.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29082</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29086</th>\n",
       "      <td>63.2</td>\n",
       "      <td>69.2</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>69.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29088</th>\n",
       "      <td>6.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29089</th>\n",
       "      <td>7.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>4.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29092</th>\n",
       "      <td>12.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>16.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21694 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  lag1  year  quarter  prov_mean\n",
       "1        6.5   4.6  2014        2   4.600000\n",
       "2        6.4   6.5  2015        2   5.550000\n",
       "3        9.0   6.4  2016        2   5.833333\n",
       "4        6.5   9.0  2017        2   6.625000\n",
       "5        8.0   6.5  2018        2   6.600000\n",
       "...      ...   ...   ...      ...        ...\n",
       "29082    0.2   0.8  2018        2   1.000000\n",
       "29086   63.2  69.2  2018        2  69.200000\n",
       "29088    6.6   1.7  2018        2   1.700000\n",
       "29089    7.5   6.6  2019        2   4.150000\n",
       "29092   12.6  16.1  2019        2  16.100000\n",
       "\n",
       "[21694 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_modeling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3bdaf3f-ebf0-4eb2-b67a-abeffc9db47d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c53466698458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgbr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_xgbr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgbr_modeling_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/HAIP/notebooks/services/initial_tests/xgbr_test.py\u001b[0m in \u001b[0;36mtest_xgbr\u001b[0;34m(modeling_dataset)\u001b[0m\n\u001b[1;32m     19\u001b[0m                                                          \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                          \u001b[0merror_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \t\t\t\t\t\t\t verbose = True)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgbr_model, cv_rmse = test_xgbr(xgbr_modeling_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc9a3b3-886a-47b1-a8c1-b3cdbcb09c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.198914192739643"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4af081b7-24e2-40c5-b7d8-08e3477db5fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = XGBRegressor()\n",
    "X = xgbr_modeling_df.drop(columns = ['score'])\n",
    "y = xgbr_modeling_df[['score']]\n",
    "model.fit(X, y)\n",
    "yhat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9230341-940e-4690-8a4d-37f5e0928d39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_importance(model)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df065a04-d91b-45d7-abea-bf178589b094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgbr_selected_features = ['lag1', 'prov_mean']\n",
    "\n",
    "eta = [[0.05, 0.1, 0.2, 0.3]]\n",
    "gamma = [range(0,2)]\n",
    "max_depth = [range(5,9)]\n",
    "min_child_weight = [range(3,9)]\n",
    "subsample = [[1]]\n",
    "alpha = [[0,1,2]]\n",
    "\n",
    "parameters_dict = {'eta': eta, \n",
    "                      'gamma': gamma,\n",
    "                      'max_depth': max_depth,\n",
    "                      'min_child_weight': min_child_weight,\n",
    "                      'subsample': subsample,\n",
    "                      'alpha': alpha}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21f4af2b-0b1d-4d12-be82-cfb1245a0a02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1</th>\n",
       "      <th>prov_mean</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.6</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.4</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.5</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29082</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29086</th>\n",
       "      <td>69.2</td>\n",
       "      <td>69.200000</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29088</th>\n",
       "      <td>1.7</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29089</th>\n",
       "      <td>6.6</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29092</th>\n",
       "      <td>16.1</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21694 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lag1  prov_mean  score\n",
       "1       4.6   4.600000    6.5\n",
       "2       6.5   5.550000    6.4\n",
       "3       6.4   5.833333    9.0\n",
       "4       9.0   6.625000    6.5\n",
       "5       6.5   6.600000    8.0\n",
       "...     ...        ...    ...\n",
       "29082   0.8   1.000000    0.2\n",
       "29086  69.2  69.200000   63.2\n",
       "29088   1.7   1.700000    6.6\n",
       "29089   6.6   4.150000    7.5\n",
       "29092  16.1  16.100000   12.6\n",
       "\n",
       "[21694 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Selection\n",
    "final_xgbr_modeling_df = xgbr_modeling_df[xgbr_selected_features +['score']]\n",
    "final_xgbr_modeling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37f64f95-0775-4244-a709-63601bd9f7ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 576 candidates, totalling 28800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 36 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 440 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 728 tasks      | elapsed:   32.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1080 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1496 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1976 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2520 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3128 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3800 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4536 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5336 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6200 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7128 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8120 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9176 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 10296 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 11480 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 12728 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 14040 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 15416 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 16856 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 18360 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 19928 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 21560 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 23256 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 25016 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 26840 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done 28728 tasks      | elapsed: 12.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:11.05560\n",
      "[1]\tvalidation_0-rmse:10.11218\n",
      "[2]\tvalidation_0-rmse:9.27601\n",
      "[3]\tvalidation_0-rmse:8.53637\n",
      "[4]\tvalidation_0-rmse:7.88519\n",
      "[5]\tvalidation_0-rmse:7.31179\n",
      "[6]\tvalidation_0-rmse:6.81172\n",
      "[7]\tvalidation_0-rmse:6.36932\n",
      "[8]\tvalidation_0-rmse:5.98278\n",
      "[9]\tvalidation_0-rmse:5.65062\n",
      "[10]\tvalidation_0-rmse:5.36665\n",
      "[11]\tvalidation_0-rmse:5.12408\n",
      "[12]\tvalidation_0-rmse:4.92003\n",
      "[13]\tvalidation_0-rmse:4.74586\n",
      "[14]\tvalidation_0-rmse:4.59534\n",
      "[15]\tvalidation_0-rmse:4.47202\n",
      "[16]\tvalidation_0-rmse:4.36771\n",
      "[17]\tvalidation_0-rmse:4.27868\n",
      "[18]\tvalidation_0-rmse:4.20894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 28800 out of 28800 | elapsed: 12.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\tvalidation_0-rmse:4.14990\n",
      "[20]\tvalidation_0-rmse:4.10063\n",
      "[21]\tvalidation_0-rmse:4.06165\n",
      "[22]\tvalidation_0-rmse:4.02619\n",
      "[23]\tvalidation_0-rmse:3.99943\n",
      "[24]\tvalidation_0-rmse:3.97829\n",
      "[25]\tvalidation_0-rmse:3.95445\n",
      "[26]\tvalidation_0-rmse:3.93756\n",
      "[27]\tvalidation_0-rmse:3.92328\n",
      "[28]\tvalidation_0-rmse:3.91267\n",
      "[29]\tvalidation_0-rmse:3.90194\n",
      "[30]\tvalidation_0-rmse:3.89430\n",
      "[31]\tvalidation_0-rmse:3.88911\n",
      "[32]\tvalidation_0-rmse:3.88286\n",
      "[33]\tvalidation_0-rmse:3.87830\n",
      "[34]\tvalidation_0-rmse:3.87664\n",
      "[35]\tvalidation_0-rmse:3.87222\n",
      "[36]\tvalidation_0-rmse:3.87291\n",
      "[37]\tvalidation_0-rmse:3.86685\n",
      "[38]\tvalidation_0-rmse:3.86457\n",
      "[39]\tvalidation_0-rmse:3.86567\n",
      "[40]\tvalidation_0-rmse:3.86471\n",
      "[41]\tvalidation_0-rmse:3.87177\n",
      "[42]\tvalidation_0-rmse:3.87357\n",
      "[43]\tvalidation_0-rmse:3.87941\n",
      "[44]\tvalidation_0-rmse:3.87983\n",
      "[45]\tvalidation_0-rmse:3.87870\n",
      "[46]\tvalidation_0-rmse:3.87987\n",
      "[47]\tvalidation_0-rmse:3.88100\n",
      "[48]\tvalidation_0-rmse:3.88194\n",
      "[49]\tvalidation_0-rmse:3.88310\n",
      "[50]\tvalidation_0-rmse:3.88156\n",
      "[51]\tvalidation_0-rmse:3.88229\n",
      "[52]\tvalidation_0-rmse:3.88218\n",
      "[53]\tvalidation_0-rmse:3.88071\n",
      "[54]\tvalidation_0-rmse:3.87914\n",
      "[55]\tvalidation_0-rmse:3.87997\n",
      "[56]\tvalidation_0-rmse:3.88127\n",
      "[57]\tvalidation_0-rmse:3.88310\n",
      "[58]\tvalidation_0-rmse:3.88471\n"
     ]
    }
   ],
   "source": [
    "xgbr_save_path = './model_runs/xgboost_regression'\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d-%Hh%Mm\")\n",
    "\n",
    "xgbr_candidates = tune_xgbr(xgbr_modeling_df,\n",
    "                            'score',\n",
    "                            parameters_dict,\n",
    "                            xgbr_save_path,\n",
    "                            current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9c27d37-74cf-46a8-9d59-b7a332082993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>lag1</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>lag_diff</th>\n",
       "      <th>prov_mean</th>\n",
       "      <th>prov_mean_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24799.000000</td>\n",
       "      <td>24799.000000</td>\n",
       "      <td>24799.000000</td>\n",
       "      <td>24799.000000</td>\n",
       "      <td>24799.000000</td>\n",
       "      <td>24799.000000</td>\n",
       "      <td>24799.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.413763</td>\n",
       "      <td>8.661273</td>\n",
       "      <td>2016.850034</td>\n",
       "      <td>2.250413</td>\n",
       "      <td>-1.247510</td>\n",
       "      <td>9.732317</td>\n",
       "      <td>-2.318554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.414690</td>\n",
       "      <td>9.470437</td>\n",
       "      <td>1.798227</td>\n",
       "      <td>0.661920</td>\n",
       "      <td>4.511939</td>\n",
       "      <td>10.353490</td>\n",
       "      <td>6.122558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-75.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-75.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.700000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>3.780000</td>\n",
       "      <td>-3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.800000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>96.400000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>44.600000</td>\n",
       "      <td>96.400000</td>\n",
       "      <td>44.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              score          lag1          year       quarter      lag_diff  \\\n",
       "count  24799.000000  24799.000000  24799.000000  24799.000000  24799.000000   \n",
       "mean       7.413763      8.661273   2016.850034      2.250413     -1.247510   \n",
       "std        8.414690      9.470437      1.798227      0.661920      4.511939   \n",
       "min        0.100000      0.100000   2014.000000      2.000000    -75.400000   \n",
       "25%        2.700000      3.400000   2015.000000      2.000000     -2.500000   \n",
       "50%        5.100000      5.900000   2017.000000      2.000000     -0.500000   \n",
       "75%        8.800000     10.000000   2019.000000      2.000000      0.800000   \n",
       "max       92.000000     96.400000   2019.000000      4.000000     44.600000   \n",
       "\n",
       "          prov_mean  prov_mean_diff  \n",
       "count  24799.000000    24799.000000  \n",
       "mean       9.732317       -2.318554  \n",
       "std       10.353490        6.122558  \n",
       "min        0.100000      -75.400000  \n",
       "25%        3.780000       -3.500000  \n",
       "50%        6.300000       -1.000000  \n",
       "75%       11.250000        0.550000  \n",
       "max       96.400000       44.600000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f18249dd-c99f-4ae4-aa4d-f224d3fc9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to include\n",
    "features_included = [['lag_diff', 'prov_mean_diff']]\n",
    "\n",
    "# n_estimators: int, default=100\n",
    "#The number of base estimators in the ensemble.\n",
    "n_estimators_list = [50,100,200,300]\n",
    "\n",
    "# max_samples: “auto”, int or float, default=”auto”\n",
    "# The number of samples to draw from X to train eachz base estimator.\n",
    "max_samples_list  = ['auto', 200, 175, 128]\n",
    "\n",
    "# max_features: int or float, default=1.0\n",
    "# The number of features to draw from X to train each base estimator.\n",
    "max_features_list  = [1]\n",
    "\n",
    "# bootstrap: bool, default=False\n",
    "# If True, individual trees are fit on random subsets of the training data sampled with replacement. If False, sampling without replacement is performed.\n",
    "bootstrap_list  = [False, True]\n",
    "\n",
    "parameters_dict = {'features_included': features_included,\n",
    "                      'n_estimators': n_estimators_list, \n",
    "                      'max_samples': max_samples_list,\n",
    "                      'max_features': max_features_list,\n",
    "                      'bootstrap': bootstrap_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29583264-3ec0-4818-9a22-fb5ac003b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest_save_path = './model_runs/isolation_forest'\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d-%Hh%Mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2710642-e089-4115-9ad1-cbc956553642",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-020f1f728690>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                   \u001b[0mparameters_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                   \u001b[0miforest_save_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                   current_date)\n\u001b[0m",
      "\u001b[0;32m~/HAIP/notebooks/services/model_training/tune_isolation_forest.py\u001b[0m in \u001b[0;36mtune_iforest\u001b[0;34m(modeling_data, parameters, save_path, run_date, rng_number)\u001b[0m\n\u001b[1;32m     76\u001b[0m                                                                                                            \u001b[0mprov_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprov_means\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \t\t\t\t\t\t\t\t\t\t\t\t\t   lag1 = lag1s), \n\u001b[0;32m---> 78\u001b[0;31m \t\t\t\t\t\t\t\t  range(3,11))\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0moutput_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maat_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mcombined_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HAIP/notebooks/services/artificial_anomaly_tests/aa_tests.py\u001b[0m in \u001b[0;36martificial_anomaly_test_iforest\u001b[0;34m(model, model_data, shift_range, shift_n, scatter)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m## need to generalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mpred_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'shift'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mock_score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'prov_mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lag1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mscore_sample_control\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mpred_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'shift'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_iforest.py\u001b[0m in \u001b[0;36mscore_samples\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;31m# Take the opposite of the scores as bigger is better (here less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;31m# abnormal)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_chunked_score_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compute_chunked_score_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_iforest.py\u001b[0m in \u001b[0;36m_compute_chunked_score_samples\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# compute score on the slices of test samples:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_score_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_iforest.py\u001b[0m in \u001b[0;36m_compute_score_samples\u001b[0;34m(self, X, subsample_features)\u001b[0m\n\u001b[1;32m    458\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_indicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0m_average_path_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples_leaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m                 \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m             )\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/_iforest.py\u001b[0m in \u001b[0;36m_average_path_length\u001b[0;34m(n_samples_leaf)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0maverage_path_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     average_path_length[not_mask] = (\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples_leaf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnot_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meuler_gamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples_leaf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnot_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_samples_leaf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnot_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iforest_candidates = tune_iforest(modeling_df, \n",
    "                                  parameters_dict, \n",
    "                                  iforest_save_path,\n",
    "                                  current_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1365352b-6a8a-4582-b0df-114247f7f2dc",
   "metadata": {},
   "source": [
    "# Modeling Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6446692d-4208-4962-9941-c90bb40ae155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xg_boost_regression_settings = {\n",
    "    \"model_run_data_path\": '/root/HAIP/notebooks/op-10/xgboost-regression/xgbr_tuning_results_run_2022-11-08-20h37m.csv',    \n",
    "    \"model_type\": \"XGBRegression\"\n",
    "}\n",
    "\n",
    "\n",
    "settings = {**settings, **xg_boost_regression_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f04fce66-7993-4e49-a6bc-fb1430e007d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_eta</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.8555</td>\n",
       "      <td>0.3707</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0, 'eta': 0.3, 'gamma': 1, 'max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.8596</td>\n",
       "      <td>0.3714</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0, 'eta': 0.3, 'gamma': 0, 'max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.8647</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'eta': 0.3, 'gamma': 0, 'max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-5.8648</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'eta': 0.3, 'gamma': 1, 'max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-5.8660</td>\n",
       "      <td>0.3694</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'eta': 0.3, 'gamma': 0, 'max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.8669</td>\n",
       "      <td>0.3795</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0, 'eta': 0.3, 'gamma': 0, 'max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.8679</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0, 'eta': 0.3, 'gamma': 1, 'max_dept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-5.8683</td>\n",
       "      <td>0.3717</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'eta': 0.3, 'gamma': 1, 'max_dept...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_test_score  std_test_score  rank_test_score  param_alpha  param_eta  \\\n",
       "2          -5.8555          0.3707                1            0        0.3   \n",
       "0          -5.8596          0.3714                2            0        0.3   \n",
       "4          -5.8647          0.3726                3            1        0.3   \n",
       "6          -5.8648          0.3726                4            1        0.3   \n",
       "5          -5.8660          0.3694                5            1        0.3   \n",
       "1          -5.8669          0.3795                6            0        0.3   \n",
       "3          -5.8679          0.3791                7            0        0.3   \n",
       "7          -5.8683          0.3717                8            1        0.3   \n",
       "\n",
       "   param_gamma  param_max_depth  param_min_child_weight  param_subsample  \\\n",
       "2            1                6                       6                1   \n",
       "0            0                6                       6                1   \n",
       "4            0                6                       6                1   \n",
       "6            1                6                       6                1   \n",
       "5            0                7                       6                1   \n",
       "1            0                7                       6                1   \n",
       "3            1                7                       6                1   \n",
       "7            1                7                       6                1   \n",
       "\n",
       "                                              params  \n",
       "2  {'alpha': 0, 'eta': 0.3, 'gamma': 1, 'max_dept...  \n",
       "0  {'alpha': 0, 'eta': 0.3, 'gamma': 0, 'max_dept...  \n",
       "4  {'alpha': 1, 'eta': 0.3, 'gamma': 0, 'max_dept...  \n",
       "6  {'alpha': 1, 'eta': 0.3, 'gamma': 1, 'max_dept...  \n",
       "5  {'alpha': 1, 'eta': 0.3, 'gamma': 0, 'max_dept...  \n",
       "1  {'alpha': 0, 'eta': 0.3, 'gamma': 0, 'max_dept...  \n",
       "3  {'alpha': 0, 'eta': 0.3, 'gamma': 1, 'max_dept...  \n",
       "7  {'alpha': 1, 'eta': 0.3, 'gamma': 1, 'max_dept...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selector = model_selection_svc.get_model_selector(settings)\n",
    "model_selector.get_top_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a194bad-d8fd-4466-b8f2-a9119bcf5ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_model_index = 2\n",
    "xgbr_final_parameters = model_selector.get_candidate_model_params_by_index(selected_model_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ce5086e-c4cf-44f5-8495-bef830dc3072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0,\n",
       " 'eta': 0.3,\n",
       " 'gamma': 1,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 6,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_final_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "167f1bfe-00c6-48f8-bf36-6de3b9094fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=0, base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False, eta=0.3,\n",
       "             eval_metric=None, gamma=1, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=6,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, objective='reg:squarederror',\n",
       "             predictor='auto', ...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_final_model = XGBRegressor(**xgbr_final_parameters, random_state = 42)\n",
    "X = final_xgbr_modeling_df.drop(columns = 'score')\n",
    "y = final_xgbr_modeling_df[['score']]\n",
    "xgbr_final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dcbfb30-a721-45c6-a123-58733873fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_save_path = './xgboost-regression/xgbr_model_final.pkl'\n",
    "\n",
    "with open(xgbr_save_path, 'wb') as f:\n",
    "    pickle.dump(xgbr_final_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19f1e6d4-2f52-4734-b73b-82bd177f7096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1</th>\n",
       "      <th>prov_mean</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21694.000000</td>\n",
       "      <td>21694.000000</td>\n",
       "      <td>21694.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.927086</td>\n",
       "      <td>9.901452</td>\n",
       "      <td>8.159450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.883479</td>\n",
       "      <td>10.711228</td>\n",
       "      <td>8.708054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>3.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.900000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>5.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.300000</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>9.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.400000</td>\n",
       "      <td>96.400000</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lag1     prov_mean         score\n",
       "count  21694.000000  21694.000000  21694.000000\n",
       "mean       8.927086      9.901452      8.159450\n",
       "std        9.883479     10.711228      8.708054\n",
       "min        0.100000      0.100000      0.100000\n",
       "25%        3.400000      3.720000      3.300000\n",
       "50%        5.900000      6.300000      5.700000\n",
       "75%       10.300000     11.400000      9.500000\n",
       "max       96.400000     96.400000     92.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_xgbr_modeling_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92c9801c-273f-419e-b4a4-1cfe34b7bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_aat_results = artificial_anomaly_test_xgb(model = xgbr_final_model, \n",
    "                            model_data = final_xgbr_modeling_df,\n",
    "                            selected_features = xgbr_selected_features,\n",
    "                            shift_range = np.arange(4,11),\n",
    "                            threshold_range = range(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63b3d642-f2b0-4faf-8da3-84c98777af48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.840143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.833643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.802357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.796286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.750286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.702429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.687286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.648071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.601143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold     AUROC\n",
       "2          3  0.840143\n",
       "3          4  0.833643\n",
       "1          2  0.802357\n",
       "4          5  0.796286\n",
       "5          6  0.750286\n",
       "6          7  0.702429\n",
       "0          1  0.687286\n",
       "7          8  0.648071\n",
       "8          9  0.601143"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_aat_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92bc5d85-d504-4ed1-850e-950cc0e0cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc53092e-20d3-4679-9e04-c54c567fe444",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_full_df = modeling_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0b9835a-4fb6-4a98-9360-fc4b817a7096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>lag1</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>lag_diff</th>\n",
       "      <th>prov_mean</th>\n",
       "      <th>prov_mean_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>3.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>-0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29089</th>\n",
       "      <td>7.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>3.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29090</th>\n",
       "      <td>1.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>-3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29092</th>\n",
       "      <td>12.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>-3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29093</th>\n",
       "      <td>8.7</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>-5.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29095</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>-4.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24799 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  lag1  year  quarter  lag_diff  prov_mean  prov_mean_diff\n",
       "1        6.5   4.6  2014        2       1.9   4.600000        1.900000\n",
       "2        6.4   6.5  2015        2      -0.1   5.550000        0.850000\n",
       "3        9.0   6.4  2016        2       2.6   5.833333        3.166667\n",
       "4        6.5   9.0  2017        2      -2.5   6.625000       -0.125000\n",
       "5        8.0   6.5  2018        2       1.5   6.600000        1.400000\n",
       "...      ...   ...   ...      ...       ...        ...             ...\n",
       "29089    7.5   6.6  2019        2       0.9   4.150000        3.350000\n",
       "29090    1.6   7.5  2019        4      -5.9   5.266667       -3.666667\n",
       "29092   12.6  16.1  2019        2      -3.5  16.100000       -3.500000\n",
       "29093    8.7  12.6  2019        4      -3.9  14.350000       -5.650000\n",
       "29095    1.0   5.5  2019        4      -4.5   5.500000       -4.500000\n",
       "\n",
       "[24799 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc53651c-3eca-485e-85ec-5040372efe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_final_predictions = xgbr_final_model.predict(xgbr_full_df[xgbr_selected_features])\n",
    "xgbr_full_df['xbgr_pred_score'] = xgbr_final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49a6e655-5e13-4614-b7f6-d2e376a299d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_full_df['xgbr_score_diff'] = xgbr_full_df['score'] - xgbr_final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37d93144-f91c-4cf5-bbc4-1971295dcffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_full_df['xgbr_outlier_pred'] = abs(xgbr_full_df['xgbr_score_diff']) > 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a757e29c-4b95-479e-8601-59c8b1e604ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1674\n",
       "True     1431\n",
       "Name: xgbr_outlier_pred, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_full_df.query('(year == 2019) & (quarter == 4)')['xgbr_outlier_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5ca2b88-cdec-4eed-b021-f88d623527c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgbr_outlier_pred\n",
       "False                20538\n",
       "True                  4261\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_full_df[['xgbr_outlier_pred']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1604f95b-fe4c-434a-9210-b4f294124ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_settings = {\n",
    "    \"model_run_data_path\": './model_runs/isolation_forest/tuning_results_run_2022-11-11-14h47m.csv',    \n",
    "    \"model_type\": \"Isolation Forest\"\n",
    "}\n",
    "\n",
    "settings = {**settings, **if_settings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54e121e9-e083-4457-b45d-8aaf30ad736c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>features_included</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>model_id</th>\n",
       "      <th>auroc_total</th>\n",
       "      <th>auroc_threshold_0.5</th>\n",
       "      <th>auroc_threshold_0.51</th>\n",
       "      <th>auroc_threshold_0.52</th>\n",
       "      <th>auroc_threshold_0.53</th>\n",
       "      <th>auroc_threshold_0.54</th>\n",
       "      <th>auroc_threshold_0.55</th>\n",
       "      <th>auroc_threshold_0.56</th>\n",
       "      <th>auroc_threshold_0.57</th>\n",
       "      <th>auroc_threshold_0.58</th>\n",
       "      <th>auroc_threshold_0.59</th>\n",
       "      <th>auroc_threshold_0.6</th>\n",
       "      <th>auroc_threshold_0.61</th>\n",
       "      <th>auroc_threshold_0.62</th>\n",
       "      <th>auroc_threshold_0.63</th>\n",
       "      <th>auroc_threshold_0.64</th>\n",
       "      <th>auroc_threshold_0.65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8514</td>\n",
       "      <td>0.7732</td>\n",
       "      <td>0.7679</td>\n",
       "      <td>0.7620</td>\n",
       "      <td>0.7563</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.7387</td>\n",
       "      <td>0.7323</td>\n",
       "      <td>0.7226</td>\n",
       "      <td>0.7139</td>\n",
       "      <td>0.7050</td>\n",
       "      <td>0.6967</td>\n",
       "      <td>0.6882</td>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.6655</td>\n",
       "      <td>0.6571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8488</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.7638</td>\n",
       "      <td>0.7573</td>\n",
       "      <td>0.7497</td>\n",
       "      <td>0.7423</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>0.7246</td>\n",
       "      <td>0.7150</td>\n",
       "      <td>0.7052</td>\n",
       "      <td>0.6949</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.6735</td>\n",
       "      <td>0.6614</td>\n",
       "      <td>0.6486</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.6217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>True</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>17</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>0.7602</td>\n",
       "      <td>0.7497</td>\n",
       "      <td>0.7403</td>\n",
       "      <td>0.7313</td>\n",
       "      <td>0.7217</td>\n",
       "      <td>0.7139</td>\n",
       "      <td>0.7051</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>0.6874</td>\n",
       "      <td>0.6755</td>\n",
       "      <td>0.6675</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.6541</td>\n",
       "      <td>0.6461</td>\n",
       "      <td>0.6364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>True</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>300</td>\n",
       "      <td>24</td>\n",
       "      <td>0.8477</td>\n",
       "      <td>0.7683</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>0.7568</td>\n",
       "      <td>0.7482</td>\n",
       "      <td>0.7403</td>\n",
       "      <td>0.7319</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>0.6944</td>\n",
       "      <td>0.6839</td>\n",
       "      <td>0.6724</td>\n",
       "      <td>0.6605</td>\n",
       "      <td>0.6484</td>\n",
       "      <td>0.6362</td>\n",
       "      <td>0.6215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>0.8474</td>\n",
       "      <td>0.7759</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>0.7666</td>\n",
       "      <td>0.7611</td>\n",
       "      <td>0.7532</td>\n",
       "      <td>0.7461</td>\n",
       "      <td>0.7402</td>\n",
       "      <td>0.7298</td>\n",
       "      <td>0.7215</td>\n",
       "      <td>0.7109</td>\n",
       "      <td>0.6989</td>\n",
       "      <td>0.6849</td>\n",
       "      <td>0.6725</td>\n",
       "      <td>0.6614</td>\n",
       "      <td>0.6517</td>\n",
       "      <td>0.6417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8473</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.7601</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.7181</td>\n",
       "      <td>0.7089</td>\n",
       "      <td>0.6994</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.6822</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>0.6628</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.6257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>True</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>0.8472</td>\n",
       "      <td>0.7781</td>\n",
       "      <td>0.7757</td>\n",
       "      <td>0.7719</td>\n",
       "      <td>0.7671</td>\n",
       "      <td>0.7604</td>\n",
       "      <td>0.7532</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>0.7277</td>\n",
       "      <td>0.7176</td>\n",
       "      <td>0.7078</td>\n",
       "      <td>0.6992</td>\n",
       "      <td>0.6794</td>\n",
       "      <td>0.6717</td>\n",
       "      <td>0.6576</td>\n",
       "      <td>0.6462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>True</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>300</td>\n",
       "      <td>28</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>0.7706</td>\n",
       "      <td>0.7668</td>\n",
       "      <td>0.7606</td>\n",
       "      <td>0.7537</td>\n",
       "      <td>0.7447</td>\n",
       "      <td>0.7362</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.7206</td>\n",
       "      <td>0.7117</td>\n",
       "      <td>0.7022</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>0.6697</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.6443</td>\n",
       "      <td>0.6313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>True</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>0.7767</td>\n",
       "      <td>0.7740</td>\n",
       "      <td>0.7687</td>\n",
       "      <td>0.7613</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.7450</td>\n",
       "      <td>0.7385</td>\n",
       "      <td>0.7283</td>\n",
       "      <td>0.7192</td>\n",
       "      <td>0.7108</td>\n",
       "      <td>0.6982</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.6719</td>\n",
       "      <td>0.6600</td>\n",
       "      <td>0.6499</td>\n",
       "      <td>0.6418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>True</td>\n",
       "      <td>[lag_diff, prov_mean_diff]</td>\n",
       "      <td>1</td>\n",
       "      <td>175</td>\n",
       "      <td>100</td>\n",
       "      <td>26</td>\n",
       "      <td>0.8467</td>\n",
       "      <td>0.7738</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>0.7675</td>\n",
       "      <td>0.7603</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.7452</td>\n",
       "      <td>0.7388</td>\n",
       "      <td>0.7301</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>0.7141</td>\n",
       "      <td>0.7012</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>0.6738</td>\n",
       "      <td>0.6618</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>0.6367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bootstrap           features_included  max_features max_samples  \\\n",
       "0       False  [lag_diff, prov_mean_diff]             1        auto   \n",
       "7       False  [lag_diff, prov_mean_diff]             1         200   \n",
       "16       True  [lag_diff, prov_mean_diff]             1        auto   \n",
       "23       True  [lag_diff, prov_mean_diff]             1         200   \n",
       "8       False  [lag_diff, prov_mean_diff]             1         175   \n",
       "3       False  [lag_diff, prov_mean_diff]             1        auto   \n",
       "28       True  [lag_diff, prov_mean_diff]             1         128   \n",
       "27       True  [lag_diff, prov_mean_diff]             1         175   \n",
       "24       True  [lag_diff, prov_mean_diff]             1         175   \n",
       "25       True  [lag_diff, prov_mean_diff]             1         175   \n",
       "\n",
       "    n_estimators  model_id  auroc_total  auroc_threshold_0.5  \\\n",
       "0             50         1       0.8514               0.7732   \n",
       "7            300         8       0.8488               0.7692   \n",
       "16            50        17       0.8480               0.7655   \n",
       "23           300        24       0.8477               0.7683   \n",
       "8             50         9       0.8474               0.7759   \n",
       "3            300         4       0.8473               0.7650   \n",
       "28            50        29       0.8472               0.7781   \n",
       "27           300        28       0.8469               0.7706   \n",
       "24            50        25       0.8468               0.7767   \n",
       "25           100        26       0.8467               0.7738   \n",
       "\n",
       "    auroc_threshold_0.51  auroc_threshold_0.52  auroc_threshold_0.53  \\\n",
       "0                 0.7679                0.7620                0.7563   \n",
       "7                 0.7638                0.7573                0.7497   \n",
       "16                0.7602                0.7497                0.7403   \n",
       "23                0.7626                0.7568                0.7482   \n",
       "8                 0.7726                0.7666                0.7611   \n",
       "3                 0.7601                0.7530                0.7457   \n",
       "28                0.7757                0.7719                0.7671   \n",
       "27                0.7668                0.7606                0.7537   \n",
       "24                0.7740                0.7687                0.7613   \n",
       "25                0.7717                0.7675                0.7603   \n",
       "\n",
       "    auroc_threshold_0.54  auroc_threshold_0.55  auroc_threshold_0.56  \\\n",
       "0                 0.7464                0.7387                0.7323   \n",
       "7                 0.7423                0.7339                0.7246   \n",
       "16                0.7313                0.7217                0.7139   \n",
       "23                0.7403                0.7319                0.7236   \n",
       "8                 0.7532                0.7461                0.7402   \n",
       "3                 0.7351                0.7273                0.7181   \n",
       "28                0.7604                0.7532                0.7440   \n",
       "27                0.7447                0.7362                0.7290   \n",
       "24                0.7541                0.7450                0.7385   \n",
       "25                0.7530                0.7452                0.7388   \n",
       "\n",
       "    auroc_threshold_0.57  auroc_threshold_0.58  auroc_threshold_0.59  \\\n",
       "0                 0.7226                0.7139                0.7050   \n",
       "7                 0.7150                0.7052                0.6949   \n",
       "16                0.7051                0.6966                0.6874   \n",
       "23                0.7143                0.7043                0.6944   \n",
       "8                 0.7298                0.7215                0.7109   \n",
       "3                 0.7089                0.6994                0.6908   \n",
       "28                0.7350                0.7277                0.7176   \n",
       "27                0.7206                0.7117                0.7022   \n",
       "24                0.7283                0.7192                0.7108   \n",
       "25                0.7301                0.7223                0.7141   \n",
       "\n",
       "    auroc_threshold_0.6  auroc_threshold_0.61  auroc_threshold_0.62  \\\n",
       "0                0.6967                0.6882                0.6812   \n",
       "7                0.6846                0.6735                0.6614   \n",
       "16               0.6755                0.6675                0.6610   \n",
       "23               0.6839                0.6724                0.6605   \n",
       "8                0.6989                0.6849                0.6725   \n",
       "3                0.6822                0.6730                0.6628   \n",
       "28               0.7078                0.6992                0.6794   \n",
       "27               0.6919                0.6811                0.6697   \n",
       "24               0.6982                0.6843                0.6719   \n",
       "25               0.7012                0.6861                0.6738   \n",
       "\n",
       "    auroc_threshold_0.63  auroc_threshold_0.64  auroc_threshold_0.65  \n",
       "0                 0.6742                0.6655                0.6571  \n",
       "7                 0.6486                0.6364                0.6217  \n",
       "16                0.6541                0.6461                0.6364  \n",
       "23                0.6484                0.6362                0.6215  \n",
       "8                 0.6614                0.6517                0.6417  \n",
       "3                 0.6526                0.6403                0.6257  \n",
       "28                0.6717                0.6576                0.6462  \n",
       "27                0.6577                0.6443                0.6313  \n",
       "24                0.6600                0.6499                0.6418  \n",
       "25                0.6618                0.6490                0.6367  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selector = model_selection_svc.get_model_selector(settings)\n",
    "model_selector.get_top_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a48a77af-827f-4d6a-bf87-d431081b2b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_diff</th>\n",
       "      <th>prov_mean_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.9</td>\n",
       "      <td>1.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.6</td>\n",
       "      <td>3.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.5</td>\n",
       "      <td>-0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29089</th>\n",
       "      <td>0.9</td>\n",
       "      <td>3.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29090</th>\n",
       "      <td>-5.9</td>\n",
       "      <td>-3.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29092</th>\n",
       "      <td>-3.5</td>\n",
       "      <td>-3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29093</th>\n",
       "      <td>-3.9</td>\n",
       "      <td>-5.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29095</th>\n",
       "      <td>-4.5</td>\n",
       "      <td>-4.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24799 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lag_diff  prov_mean_diff\n",
       "1           1.9        1.900000\n",
       "2          -0.1        0.850000\n",
       "3           2.6        3.166667\n",
       "4          -2.5       -0.125000\n",
       "5           1.5        1.400000\n",
       "...         ...             ...\n",
       "29089       0.9        3.350000\n",
       "29090      -5.9       -3.666667\n",
       "29092      -3.5       -3.500000\n",
       "29093      -3.9       -5.650000\n",
       "29095      -4.5       -4.500000\n",
       "\n",
       "[24799 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iforest_final_parameters = model_selector.get_candidate_model_params_by_index(1)\n",
    "iforest_final_parameters\n",
    "#iforest_modeling_df = modeling_df[iforest_final_parameters['features_included']]\n",
    "iforest_modeling_df = modeling_df[['lag_diff','prov_mean_diff']]\n",
    "iforest_final_parameters.pop('features_included')\n",
    "iforest_modeling_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb52e309-8522-4f44-b852-51f8af667e44",
   "metadata": {},
   "source": [
    "# Final Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57601bb5-6653-48d3-82f9-fbc90fd1018c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0,\n",
       " 'eta': 0.3,\n",
       " 'gamma': 1,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 6,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_final_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "306c60eb-d1e0-4fbd-8379-b6af84351463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0,\n",
       " 'eta': 0.3,\n",
       " 'gamma': 1,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 6,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr_final_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7173d84-dc48-431b-a28a-ca89486f74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "if_model = IsolationForest(\n",
    "    random_state = rng,\n",
    "    **iforest_final_parameters,\n",
    "    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7180a1fd-4cc1-4a25-ad00-0d7f5afaa1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(behaviour='deprecated', bootstrap=False, contamination='auto',\n",
       "                max_features=1, max_samples='auto', n_estimators=100, n_jobs=-1,\n",
       "                random_state=RandomState(MT19937) at 0x7F1E124A17C0, verbose=0,\n",
       "                warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if_model.fit(iforest_modeling_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba2d9734-75e4-479a-94db-ebfcd547167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest_anomaly_scores = if_model.score_samples(iforest_modeling_df) * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47fccf61-5847-4846-a691-706431335f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44321861, 0.38736151, 0.47072023, ..., 0.43494145, 0.45878292,\n",
       "       0.46434229])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iforest_anomaly_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd067c33-2616-444f-896a-141f909fec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest_full_df = modeling_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a31f79a-21a8-4baa-8969-a2cdb6d0df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest_full_df['iforest_score'] = iforest_anomaly_scores\n",
    "iforest_full_df['iforest_pred'] = iforest_anomaly_scores > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "19b1b2f8-9c90-4884-b10e-c7068dcf7d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    21096\n",
       "True      3703\n",
       "Name: iforest_pred, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iforest_full_df['iforest_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51050599-839f-411e-85bc-e49db7b47998",
   "metadata": {},
   "outputs": [],
   "source": [
    "iforest_save_path = './isolation-forest/iforest_model_final.pkl'\n",
    "\n",
    "with open(iforest_save_path, 'wb') as f:\n",
    "    pickle.dump(if_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c3c6f-3ca6-4fda-9313-cf70550198ff",
   "metadata": {},
   "source": [
    "# Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7308aff0-5b1c-4c1a-8348-0dbf23a8d4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>lag1</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>prov_mean</th>\n",
       "      <th>iforest_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.443219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>0.387362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>0.470720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>0.401492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>0.422357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29082</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.385474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29086</th>\n",
       "      <td>63.2</td>\n",
       "      <td>69.2</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>69.200000</td>\n",
       "      <td>0.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29088</th>\n",
       "      <td>6.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.563541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29089</th>\n",
       "      <td>7.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>0.444184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29092</th>\n",
       "      <td>12.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>0.434941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21694 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  lag1  year  quarter  prov_mean  iforest_score\n",
       "1        6.5   4.6  2014        2   4.600000       0.443219\n",
       "2        6.4   6.5  2015        2   5.550000       0.387362\n",
       "3        9.0   6.4  2016        2   5.833333       0.470720\n",
       "4        6.5   9.0  2017        2   6.625000       0.401492\n",
       "5        8.0   6.5  2018        2   6.600000       0.422357\n",
       "...      ...   ...   ...      ...        ...            ...\n",
       "29082    0.2   0.8  2018        2   1.000000       0.385474\n",
       "29086   63.2  69.2  2018        2  69.200000       0.492800\n",
       "29088    6.6   1.7  2018        2   1.700000       0.563541\n",
       "29089    7.5   6.6  2019        2   4.150000       0.444184\n",
       "29092   12.6  16.1  2019        2  16.100000       0.434941\n",
       "\n",
       "[21694 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_modeling_df = modeling_df.copy()\n",
    "ensemble_modeling_df = ensemble_modeling_df.drop(columns = ['lag_diff','prov_mean_diff'])\n",
    "ensemble_modeling_df['iforest_score'] = iforest_anomaly_scores\n",
    "ensemble_modeling_df = ensemble_modeling_df[~((ensemble_modeling_df['year'] == 2019) & (ensemble_modeling_df['quarter'] == 4))].dropna()\n",
    "ensemble_modeling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "935092bb-eb9c-4f77-ad28-86f6423c964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-1a0adf11d05e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mensemble_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_xgbr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensemble_modeling_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mensemble_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble_modeling_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble_modeling_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mensemble_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/HAIP/notebooks/services/initial_tests/xgbr_test.py\u001b[0m in \u001b[0;36mtest_xgbr\u001b[0;34m(modeling_dataset)\u001b[0m\n\u001b[1;32m     19\u001b[0m                                                          \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                          \u001b[0merror_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \t\t\t\t\t\t\t verbose = True)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 236\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ensemble_model, cv_rmse = test_xgbr(ensemble_modeling_df)\n",
    "ensemble_model = XGBRegressor()\n",
    "X = ensemble_modeling_df.drop(columns = ['score'])\n",
    "y = ensemble_modeling_df[['score']]\n",
    "ensemble_model.fit(X, y)\n",
    "yhat = ensemble_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4079f5e6-16e7-4dde-b8ad-c1dd36ddc855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_importance(ensemble_model)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d88bb65f-c807-4ff1-b755-2ba2c7dd6cae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble_selected_features = ['iforest_score','lag1', 'prov_mean']\n",
    "\n",
    "eta = [[0.05, 0.1, 0.2, 0.3]]\n",
    "gamma = [range(0,2)]\n",
    "max_depth = [range(5,9)]\n",
    "min_child_weight = [range(3,9)]\n",
    "subsample = [[1]]\n",
    "alpha = [[0,1,2]]\n",
    "\n",
    "parameters_dict = {'eta': eta, \n",
    "                      'gamma': gamma,\n",
    "                      'max_depth': max_depth,\n",
    "                      'min_child_weight': min_child_weight,\n",
    "                      'subsample': subsample,\n",
    "                      'alpha': alpha}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c89c2e4c-82e3-42fe-8251-995149d0a5a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iforest_score</th>\n",
       "      <th>lag1</th>\n",
       "      <th>prov_mean</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.443219</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.387362</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.470720</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.401492</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.422357</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29082</th>\n",
       "      <td>0.385474</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29086</th>\n",
       "      <td>0.492800</td>\n",
       "      <td>69.2</td>\n",
       "      <td>69.200000</td>\n",
       "      <td>63.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29088</th>\n",
       "      <td>0.563541</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29089</th>\n",
       "      <td>0.444184</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29092</th>\n",
       "      <td>0.434941</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21694 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       iforest_score  lag1  prov_mean  score\n",
       "1           0.443219   4.6   4.600000    6.5\n",
       "2           0.387362   6.5   5.550000    6.4\n",
       "3           0.470720   6.4   5.833333    9.0\n",
       "4           0.401492   9.0   6.625000    6.5\n",
       "5           0.422357   6.5   6.600000    8.0\n",
       "...              ...   ...        ...    ...\n",
       "29082       0.385474   0.8   1.000000    0.2\n",
       "29086       0.492800  69.2  69.200000   63.2\n",
       "29088       0.563541   1.7   1.700000    6.6\n",
       "29089       0.444184   6.6   4.150000    7.5\n",
       "29092       0.434941  16.1  16.100000   12.6\n",
       "\n",
       "[21694 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Selection\n",
    "final_ensemble_modeling_df = ensemble_modeling_df[ensemble_selected_features +['score']]\n",
    "final_ensemble_modeling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0cb90b3-23a0-43c5-b33f-11fedac39f56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 576 candidates, totalling 28800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 320 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 608 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 960 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1376 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1856 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2400 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3008 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3680 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4416 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5216 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6080 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7008 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 8000 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 9056 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 10176 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 11360 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 12608 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 13920 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 15296 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 16736 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 18240 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 19808 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 21440 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 23136 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 24896 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 26720 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done 28608 tasks      | elapsed:  9.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:11.55721\n",
      "[1]\tvalidation_0-rmse:11.03187\n",
      "[2]\tvalidation_0-rmse:10.53589\n",
      "[3]\tvalidation_0-rmse:10.06388\n",
      "[4]\tvalidation_0-rmse:9.61932\n",
      "[5]\tvalidation_0-rmse:9.19460\n",
      "[6]\tvalidation_0-rmse:8.79338\n",
      "[7]\tvalidation_0-rmse:8.42064\n",
      "[8]\tvalidation_0-rmse:8.06415\n",
      "[9]\tvalidation_0-rmse:7.72552\n",
      "[10]\tvalidation_0-rmse:7.40618\n",
      "[11]\tvalidation_0-rmse:7.10120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 28800 out of 28800 | elapsed:  9.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\tvalidation_0-rmse:6.81221\n",
      "[13]\tvalidation_0-rmse:6.54423\n",
      "[14]\tvalidation_0-rmse:6.28674\n",
      "[15]\tvalidation_0-rmse:6.04970\n",
      "[16]\tvalidation_0-rmse:5.82776\n",
      "[17]\tvalidation_0-rmse:5.61728\n",
      "[18]\tvalidation_0-rmse:5.41787\n",
      "[19]\tvalidation_0-rmse:5.23025\n",
      "[20]\tvalidation_0-rmse:5.05453\n",
      "[21]\tvalidation_0-rmse:4.88930\n",
      "[22]\tvalidation_0-rmse:4.73652\n",
      "[23]\tvalidation_0-rmse:4.59307\n",
      "[24]\tvalidation_0-rmse:4.45677\n",
      "[25]\tvalidation_0-rmse:4.33153\n",
      "[26]\tvalidation_0-rmse:4.21468\n",
      "[27]\tvalidation_0-rmse:4.10341\n",
      "[28]\tvalidation_0-rmse:3.99936\n",
      "[29]\tvalidation_0-rmse:3.90432\n",
      "[30]\tvalidation_0-rmse:3.81273\n",
      "[31]\tvalidation_0-rmse:3.72591\n",
      "[32]\tvalidation_0-rmse:3.64781\n",
      "[33]\tvalidation_0-rmse:3.57800\n",
      "[34]\tvalidation_0-rmse:3.51215\n",
      "[35]\tvalidation_0-rmse:3.44849\n",
      "[36]\tvalidation_0-rmse:3.39260\n",
      "[37]\tvalidation_0-rmse:3.33878\n",
      "[38]\tvalidation_0-rmse:3.28730\n",
      "[39]\tvalidation_0-rmse:3.24004\n",
      "[40]\tvalidation_0-rmse:3.19774\n",
      "[41]\tvalidation_0-rmse:3.15873\n",
      "[42]\tvalidation_0-rmse:3.12305\n",
      "[43]\tvalidation_0-rmse:3.08714\n",
      "[44]\tvalidation_0-rmse:3.05765\n",
      "[45]\tvalidation_0-rmse:3.02687\n",
      "[46]\tvalidation_0-rmse:3.00181\n",
      "[47]\tvalidation_0-rmse:2.97510\n",
      "[48]\tvalidation_0-rmse:2.95340\n",
      "[49]\tvalidation_0-rmse:2.93222\n",
      "[50]\tvalidation_0-rmse:2.91411\n",
      "[51]\tvalidation_0-rmse:2.89906\n",
      "[52]\tvalidation_0-rmse:2.88247\n",
      "[53]\tvalidation_0-rmse:2.86810\n",
      "[54]\tvalidation_0-rmse:2.85599\n",
      "[55]\tvalidation_0-rmse:2.84505\n",
      "[56]\tvalidation_0-rmse:2.83225\n",
      "[57]\tvalidation_0-rmse:2.82318\n",
      "[58]\tvalidation_0-rmse:2.81166\n",
      "[59]\tvalidation_0-rmse:2.80164\n",
      "[60]\tvalidation_0-rmse:2.78810\n",
      "[61]\tvalidation_0-rmse:2.77659\n",
      "[62]\tvalidation_0-rmse:2.76926\n",
      "[63]\tvalidation_0-rmse:2.76163\n",
      "[64]\tvalidation_0-rmse:2.75327\n",
      "[65]\tvalidation_0-rmse:2.74472\n",
      "[66]\tvalidation_0-rmse:2.74013\n",
      "[67]\tvalidation_0-rmse:2.73715\n",
      "[68]\tvalidation_0-rmse:2.73311\n",
      "[69]\tvalidation_0-rmse:2.73062\n",
      "[70]\tvalidation_0-rmse:2.72734\n",
      "[71]\tvalidation_0-rmse:2.72339\n",
      "[72]\tvalidation_0-rmse:2.72087\n",
      "[73]\tvalidation_0-rmse:2.71569\n",
      "[74]\tvalidation_0-rmse:2.71230\n",
      "[75]\tvalidation_0-rmse:2.70976\n",
      "[76]\tvalidation_0-rmse:2.70753\n",
      "[77]\tvalidation_0-rmse:2.70501\n",
      "[78]\tvalidation_0-rmse:2.70108\n",
      "[79]\tvalidation_0-rmse:2.69498\n",
      "[80]\tvalidation_0-rmse:2.69460\n",
      "[81]\tvalidation_0-rmse:2.69210\n",
      "[82]\tvalidation_0-rmse:2.68654\n",
      "[83]\tvalidation_0-rmse:2.68491\n",
      "[84]\tvalidation_0-rmse:2.68369\n",
      "[85]\tvalidation_0-rmse:2.68115\n",
      "[86]\tvalidation_0-rmse:2.67914\n",
      "[87]\tvalidation_0-rmse:2.67824\n",
      "[88]\tvalidation_0-rmse:2.67646\n",
      "[89]\tvalidation_0-rmse:2.67647\n",
      "[90]\tvalidation_0-rmse:2.67626\n",
      "[91]\tvalidation_0-rmse:2.67605\n",
      "[92]\tvalidation_0-rmse:2.67476\n",
      "[93]\tvalidation_0-rmse:2.67449\n",
      "[94]\tvalidation_0-rmse:2.67429\n",
      "[95]\tvalidation_0-rmse:2.67348\n",
      "[96]\tvalidation_0-rmse:2.67271\n",
      "[97]\tvalidation_0-rmse:2.67339\n",
      "[98]\tvalidation_0-rmse:2.67278\n",
      "[99]\tvalidation_0-rmse:2.67267\n",
      "[100]\tvalidation_0-rmse:2.67240\n",
      "[101]\tvalidation_0-rmse:2.67243\n",
      "[102]\tvalidation_0-rmse:2.67267\n",
      "[103]\tvalidation_0-rmse:2.67289\n",
      "[104]\tvalidation_0-rmse:2.67426\n",
      "[105]\tvalidation_0-rmse:2.67226\n",
      "[106]\tvalidation_0-rmse:2.67227\n",
      "[107]\tvalidation_0-rmse:2.67227\n",
      "[108]\tvalidation_0-rmse:2.67018\n",
      "[109]\tvalidation_0-rmse:2.66968\n",
      "[110]\tvalidation_0-rmse:2.66967\n",
      "[111]\tvalidation_0-rmse:2.67105\n",
      "[112]\tvalidation_0-rmse:2.67267\n",
      "[113]\tvalidation_0-rmse:2.67475\n",
      "[114]\tvalidation_0-rmse:2.67157\n",
      "[115]\tvalidation_0-rmse:2.67179\n",
      "[116]\tvalidation_0-rmse:2.67318\n",
      "[117]\tvalidation_0-rmse:2.67283\n",
      "[118]\tvalidation_0-rmse:2.67448\n",
      "[119]\tvalidation_0-rmse:2.67481\n",
      "[120]\tvalidation_0-rmse:2.67478\n",
      "[121]\tvalidation_0-rmse:2.67465\n",
      "[122]\tvalidation_0-rmse:2.67499\n",
      "[123]\tvalidation_0-rmse:2.67608\n",
      "[124]\tvalidation_0-rmse:2.67460\n",
      "[125]\tvalidation_0-rmse:2.67473\n",
      "[126]\tvalidation_0-rmse:2.67562\n",
      "[127]\tvalidation_0-rmse:2.67474\n",
      "[128]\tvalidation_0-rmse:2.67468\n",
      "[129]\tvalidation_0-rmse:2.67456\n",
      "[130]\tvalidation_0-rmse:2.67418\n"
     ]
    }
   ],
   "source": [
    "ensemble_save_path = './model_runs/xgbr-ensemble'\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d-%Hh%Mm\")\n",
    "\n",
    "ensemble_candidates = tune_xgbr(final_ensemble_modeling_df,\n",
    "                                'score',\n",
    "                                parameters_dict,\n",
    "                                ensemble_save_path,\n",
    "                                current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae266436-cfdf-4d0f-aba1-bcc0b73c06a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_eta</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>split15_test_score</th>\n",
       "      <th>split16_test_score</th>\n",
       "      <th>split17_test_score</th>\n",
       "      <th>split18_test_score</th>\n",
       "      <th>split19_test_score</th>\n",
       "      <th>split20_test_score</th>\n",
       "      <th>split21_test_score</th>\n",
       "      <th>split22_test_score</th>\n",
       "      <th>split23_test_score</th>\n",
       "      <th>split24_test_score</th>\n",
       "      <th>split25_test_score</th>\n",
       "      <th>split26_test_score</th>\n",
       "      <th>split27_test_score</th>\n",
       "      <th>split28_test_score</th>\n",
       "      <th>split29_test_score</th>\n",
       "      <th>split30_test_score</th>\n",
       "      <th>split31_test_score</th>\n",
       "      <th>split32_test_score</th>\n",
       "      <th>split33_test_score</th>\n",
       "      <th>split34_test_score</th>\n",
       "      <th>split35_test_score</th>\n",
       "      <th>split36_test_score</th>\n",
       "      <th>split37_test_score</th>\n",
       "      <th>split38_test_score</th>\n",
       "      <th>split39_test_score</th>\n",
       "      <th>split40_test_score</th>\n",
       "      <th>split41_test_score</th>\n",
       "      <th>split42_test_score</th>\n",
       "      <th>split43_test_score</th>\n",
       "      <th>split44_test_score</th>\n",
       "      <th>split45_test_score</th>\n",
       "      <th>split46_test_score</th>\n",
       "      <th>split47_test_score</th>\n",
       "      <th>split48_test_score</th>\n",
       "      <th>split49_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2.8156</td>\n",
       "      <td>0.9368</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 2, 'eta': 0.05, 'gamma': 0, 'max_dep...</td>\n",
       "      <td>-2.8747</td>\n",
       "      <td>-2.8104</td>\n",
       "      <td>-2.9645</td>\n",
       "      <td>-2.6344</td>\n",
       "      <td>-2.5201</td>\n",
       "      <td>-2.7092</td>\n",
       "      <td>-2.8012</td>\n",
       "      <td>-2.8046</td>\n",
       "      <td>-2.6308</td>\n",
       "      <td>-3.0083</td>\n",
       "      <td>-2.6181</td>\n",
       "      <td>-2.6967</td>\n",
       "      <td>-3.0245</td>\n",
       "      <td>-3.2264</td>\n",
       "      <td>-2.6470</td>\n",
       "      <td>-2.7103</td>\n",
       "      <td>-2.7344</td>\n",
       "      <td>-2.6205</td>\n",
       "      <td>-2.7780</td>\n",
       "      <td>-2.8936</td>\n",
       "      <td>-2.6442</td>\n",
       "      <td>-2.7353</td>\n",
       "      <td>-2.7034</td>\n",
       "      <td>-2.8466</td>\n",
       "      <td>-2.7551</td>\n",
       "      <td>-2.6193</td>\n",
       "      <td>-2.8131</td>\n",
       "      <td>-2.9734</td>\n",
       "      <td>-2.7827</td>\n",
       "      <td>-2.8240</td>\n",
       "      <td>-2.7225</td>\n",
       "      <td>-2.9173</td>\n",
       "      <td>-3.0038</td>\n",
       "      <td>-2.6837</td>\n",
       "      <td>-2.5441</td>\n",
       "      <td>-2.5867</td>\n",
       "      <td>-2.8893</td>\n",
       "      <td>-2.8798</td>\n",
       "      <td>-2.8208</td>\n",
       "      <td>-2.6921</td>\n",
       "      <td>-2.8434</td>\n",
       "      <td>-2.5012</td>\n",
       "      <td>-2.6956</td>\n",
       "      <td>-2.8489</td>\n",
       "      <td>-2.7929</td>\n",
       "      <td>-2.8236</td>\n",
       "      <td>-2.7490</td>\n",
       "      <td>-2.5771</td>\n",
       "      <td>-2.8240</td>\n",
       "      <td>-2.7143</td>\n",
       "      <td>-2.7703</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>1.7830</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 2, 'eta': 0.1, 'gamma': 1, 'max_dept...</td>\n",
       "      <td>-2.9023</td>\n",
       "      <td>-2.8022</td>\n",
       "      <td>-2.9681</td>\n",
       "      <td>-2.6509</td>\n",
       "      <td>-2.5287</td>\n",
       "      <td>-2.7101</td>\n",
       "      <td>-2.7850</td>\n",
       "      <td>-2.7812</td>\n",
       "      <td>-2.6288</td>\n",
       "      <td>-2.9892</td>\n",
       "      <td>-2.6152</td>\n",
       "      <td>-2.7155</td>\n",
       "      <td>-3.0202</td>\n",
       "      <td>-3.2150</td>\n",
       "      <td>-2.6272</td>\n",
       "      <td>-2.6948</td>\n",
       "      <td>-2.7421</td>\n",
       "      <td>-2.6244</td>\n",
       "      <td>-2.7874</td>\n",
       "      <td>-2.9139</td>\n",
       "      <td>-2.6606</td>\n",
       "      <td>-2.7315</td>\n",
       "      <td>-2.6868</td>\n",
       "      <td>-2.8437</td>\n",
       "      <td>-2.7663</td>\n",
       "      <td>-2.6071</td>\n",
       "      <td>-2.8056</td>\n",
       "      <td>-2.9650</td>\n",
       "      <td>-2.7508</td>\n",
       "      <td>-2.8190</td>\n",
       "      <td>-2.7506</td>\n",
       "      <td>-2.9181</td>\n",
       "      <td>-3.0239</td>\n",
       "      <td>-2.7045</td>\n",
       "      <td>-2.5397</td>\n",
       "      <td>-2.5918</td>\n",
       "      <td>-2.9096</td>\n",
       "      <td>-2.8703</td>\n",
       "      <td>-2.8578</td>\n",
       "      <td>-2.6894</td>\n",
       "      <td>-2.8560</td>\n",
       "      <td>-2.5045</td>\n",
       "      <td>-2.7170</td>\n",
       "      <td>-2.8374</td>\n",
       "      <td>-2.8284</td>\n",
       "      <td>-2.7953</td>\n",
       "      <td>-2.7703</td>\n",
       "      <td>-2.5722</td>\n",
       "      <td>-2.8162</td>\n",
       "      <td>-2.6937</td>\n",
       "      <td>-2.7717</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2.7765</td>\n",
       "      <td>0.8016</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 2, 'eta': 0.05, 'gamma': 1, 'max_dep...</td>\n",
       "      <td>-2.8807</td>\n",
       "      <td>-2.8145</td>\n",
       "      <td>-2.9764</td>\n",
       "      <td>-2.6396</td>\n",
       "      <td>-2.5103</td>\n",
       "      <td>-2.7178</td>\n",
       "      <td>-2.7791</td>\n",
       "      <td>-2.8010</td>\n",
       "      <td>-2.6258</td>\n",
       "      <td>-3.0108</td>\n",
       "      <td>-2.6192</td>\n",
       "      <td>-2.6832</td>\n",
       "      <td>-3.0101</td>\n",
       "      <td>-3.2254</td>\n",
       "      <td>-2.6369</td>\n",
       "      <td>-2.7062</td>\n",
       "      <td>-2.7410</td>\n",
       "      <td>-2.6084</td>\n",
       "      <td>-2.8112</td>\n",
       "      <td>-2.8883</td>\n",
       "      <td>-2.6726</td>\n",
       "      <td>-2.7218</td>\n",
       "      <td>-2.7166</td>\n",
       "      <td>-2.8378</td>\n",
       "      <td>-2.7687</td>\n",
       "      <td>-2.6326</td>\n",
       "      <td>-2.8203</td>\n",
       "      <td>-3.0013</td>\n",
       "      <td>-2.7689</td>\n",
       "      <td>-2.8339</td>\n",
       "      <td>-2.7156</td>\n",
       "      <td>-2.9019</td>\n",
       "      <td>-3.0050</td>\n",
       "      <td>-2.6975</td>\n",
       "      <td>-2.5427</td>\n",
       "      <td>-2.5882</td>\n",
       "      <td>-2.9009</td>\n",
       "      <td>-2.8754</td>\n",
       "      <td>-2.8374</td>\n",
       "      <td>-2.7017</td>\n",
       "      <td>-2.8305</td>\n",
       "      <td>-2.4915</td>\n",
       "      <td>-2.6834</td>\n",
       "      <td>-2.8405</td>\n",
       "      <td>-2.8423</td>\n",
       "      <td>-2.8293</td>\n",
       "      <td>-2.7591</td>\n",
       "      <td>-2.5858</td>\n",
       "      <td>-2.8183</td>\n",
       "      <td>-2.7055</td>\n",
       "      <td>-2.7723</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2.6462</td>\n",
       "      <td>0.6415</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'eta': 0.05, 'gamma': 0, 'max_dep...</td>\n",
       "      <td>-2.8759</td>\n",
       "      <td>-2.7915</td>\n",
       "      <td>-2.9402</td>\n",
       "      <td>-2.6532</td>\n",
       "      <td>-2.5438</td>\n",
       "      <td>-2.7037</td>\n",
       "      <td>-2.8034</td>\n",
       "      <td>-2.8307</td>\n",
       "      <td>-2.6563</td>\n",
       "      <td>-2.9891</td>\n",
       "      <td>-2.6050</td>\n",
       "      <td>-2.7038</td>\n",
       "      <td>-3.0215</td>\n",
       "      <td>-3.2330</td>\n",
       "      <td>-2.6298</td>\n",
       "      <td>-2.7104</td>\n",
       "      <td>-2.7233</td>\n",
       "      <td>-2.5977</td>\n",
       "      <td>-2.7841</td>\n",
       "      <td>-2.8752</td>\n",
       "      <td>-2.6319</td>\n",
       "      <td>-2.7258</td>\n",
       "      <td>-2.7075</td>\n",
       "      <td>-2.8394</td>\n",
       "      <td>-2.7640</td>\n",
       "      <td>-2.6466</td>\n",
       "      <td>-2.8012</td>\n",
       "      <td>-2.9711</td>\n",
       "      <td>-2.7788</td>\n",
       "      <td>-2.8368</td>\n",
       "      <td>-2.7591</td>\n",
       "      <td>-2.9184</td>\n",
       "      <td>-3.0061</td>\n",
       "      <td>-2.6794</td>\n",
       "      <td>-2.5546</td>\n",
       "      <td>-2.6020</td>\n",
       "      <td>-2.9062</td>\n",
       "      <td>-2.8407</td>\n",
       "      <td>-2.8263</td>\n",
       "      <td>-2.7027</td>\n",
       "      <td>-2.8459</td>\n",
       "      <td>-2.5179</td>\n",
       "      <td>-2.6988</td>\n",
       "      <td>-2.8664</td>\n",
       "      <td>-2.8277</td>\n",
       "      <td>-2.8138</td>\n",
       "      <td>-2.7679</td>\n",
       "      <td>-2.5650</td>\n",
       "      <td>-2.8280</td>\n",
       "      <td>-2.7154</td>\n",
       "      <td>-2.7723</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1.7147</td>\n",
       "      <td>0.4713</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'eta': 0.1, 'gamma': 1, 'max_dept...</td>\n",
       "      <td>-2.8839</td>\n",
       "      <td>-2.8079</td>\n",
       "      <td>-2.9565</td>\n",
       "      <td>-2.6324</td>\n",
       "      <td>-2.5528</td>\n",
       "      <td>-2.7190</td>\n",
       "      <td>-2.7745</td>\n",
       "      <td>-2.8018</td>\n",
       "      <td>-2.6255</td>\n",
       "      <td>-2.9989</td>\n",
       "      <td>-2.6025</td>\n",
       "      <td>-2.6621</td>\n",
       "      <td>-3.0495</td>\n",
       "      <td>-3.2010</td>\n",
       "      <td>-2.6367</td>\n",
       "      <td>-2.7040</td>\n",
       "      <td>-2.7280</td>\n",
       "      <td>-2.5982</td>\n",
       "      <td>-2.8082</td>\n",
       "      <td>-2.9167</td>\n",
       "      <td>-2.6476</td>\n",
       "      <td>-2.7615</td>\n",
       "      <td>-2.6901</td>\n",
       "      <td>-2.8535</td>\n",
       "      <td>-2.7412</td>\n",
       "      <td>-2.6351</td>\n",
       "      <td>-2.8211</td>\n",
       "      <td>-2.9831</td>\n",
       "      <td>-2.7708</td>\n",
       "      <td>-2.8524</td>\n",
       "      <td>-2.7369</td>\n",
       "      <td>-2.9144</td>\n",
       "      <td>-3.0561</td>\n",
       "      <td>-2.6952</td>\n",
       "      <td>-2.5617</td>\n",
       "      <td>-2.6004</td>\n",
       "      <td>-2.9191</td>\n",
       "      <td>-2.8565</td>\n",
       "      <td>-2.8462</td>\n",
       "      <td>-2.6961</td>\n",
       "      <td>-2.8195</td>\n",
       "      <td>-2.4952</td>\n",
       "      <td>-2.7358</td>\n",
       "      <td>-2.8500</td>\n",
       "      <td>-2.8101</td>\n",
       "      <td>-2.8188</td>\n",
       "      <td>-2.7548</td>\n",
       "      <td>-2.5851</td>\n",
       "      <td>-2.7926</td>\n",
       "      <td>-2.7014</td>\n",
       "      <td>-2.7732</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.4038</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'eta': 0.3, 'gamma': 1, 'max_dept...</td>\n",
       "      <td>-2.9787</td>\n",
       "      <td>-2.9631</td>\n",
       "      <td>-3.0607</td>\n",
       "      <td>-2.7497</td>\n",
       "      <td>-2.6576</td>\n",
       "      <td>-2.7932</td>\n",
       "      <td>-2.8584</td>\n",
       "      <td>-2.8372</td>\n",
       "      <td>-2.7069</td>\n",
       "      <td>-3.0427</td>\n",
       "      <td>-2.6605</td>\n",
       "      <td>-2.7402</td>\n",
       "      <td>-3.1469</td>\n",
       "      <td>-3.2226</td>\n",
       "      <td>-2.6784</td>\n",
       "      <td>-2.7294</td>\n",
       "      <td>-2.7499</td>\n",
       "      <td>-2.6944</td>\n",
       "      <td>-2.8380</td>\n",
       "      <td>-3.0152</td>\n",
       "      <td>-2.6983</td>\n",
       "      <td>-2.8180</td>\n",
       "      <td>-2.8081</td>\n",
       "      <td>-2.9739</td>\n",
       "      <td>-2.8715</td>\n",
       "      <td>-2.6545</td>\n",
       "      <td>-2.9507</td>\n",
       "      <td>-3.0982</td>\n",
       "      <td>-2.8194</td>\n",
       "      <td>-2.9976</td>\n",
       "      <td>-2.7538</td>\n",
       "      <td>-3.1083</td>\n",
       "      <td>-3.0475</td>\n",
       "      <td>-2.7878</td>\n",
       "      <td>-2.6664</td>\n",
       "      <td>-2.6156</td>\n",
       "      <td>-2.9209</td>\n",
       "      <td>-2.9832</td>\n",
       "      <td>-2.9931</td>\n",
       "      <td>-2.7777</td>\n",
       "      <td>-3.0549</td>\n",
       "      <td>-2.5736</td>\n",
       "      <td>-2.7926</td>\n",
       "      <td>-2.9255</td>\n",
       "      <td>-2.9684</td>\n",
       "      <td>-2.8599</td>\n",
       "      <td>-2.7811</td>\n",
       "      <td>-2.7503</td>\n",
       "      <td>-2.8870</td>\n",
       "      <td>-2.7926</td>\n",
       "      <td>-2.8571</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.9556</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0, 'eta': 0.3, 'gamma': 1, 'max_dept...</td>\n",
       "      <td>-3.0187</td>\n",
       "      <td>-2.9434</td>\n",
       "      <td>-3.0260</td>\n",
       "      <td>-2.7715</td>\n",
       "      <td>-2.6489</td>\n",
       "      <td>-2.8057</td>\n",
       "      <td>-2.8667</td>\n",
       "      <td>-2.7912</td>\n",
       "      <td>-2.7890</td>\n",
       "      <td>-3.0826</td>\n",
       "      <td>-2.6835</td>\n",
       "      <td>-2.8529</td>\n",
       "      <td>-3.0662</td>\n",
       "      <td>-3.2961</td>\n",
       "      <td>-2.6683</td>\n",
       "      <td>-2.7317</td>\n",
       "      <td>-2.7997</td>\n",
       "      <td>-2.6590</td>\n",
       "      <td>-2.8656</td>\n",
       "      <td>-2.9345</td>\n",
       "      <td>-2.7185</td>\n",
       "      <td>-2.8502</td>\n",
       "      <td>-2.8279</td>\n",
       "      <td>-2.9075</td>\n",
       "      <td>-2.9010</td>\n",
       "      <td>-2.6471</td>\n",
       "      <td>-2.9459</td>\n",
       "      <td>-3.0934</td>\n",
       "      <td>-2.8018</td>\n",
       "      <td>-2.9690</td>\n",
       "      <td>-2.8188</td>\n",
       "      <td>-3.0947</td>\n",
       "      <td>-3.0968</td>\n",
       "      <td>-2.7708</td>\n",
       "      <td>-2.6464</td>\n",
       "      <td>-2.7520</td>\n",
       "      <td>-2.9168</td>\n",
       "      <td>-2.9592</td>\n",
       "      <td>-2.9520</td>\n",
       "      <td>-2.7584</td>\n",
       "      <td>-2.8985</td>\n",
       "      <td>-2.5779</td>\n",
       "      <td>-2.7556</td>\n",
       "      <td>-2.8602</td>\n",
       "      <td>-3.0265</td>\n",
       "      <td>-2.8744</td>\n",
       "      <td>-2.8632</td>\n",
       "      <td>-2.6819</td>\n",
       "      <td>-2.9413</td>\n",
       "      <td>-2.8325</td>\n",
       "      <td>-2.8608</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1.0736</td>\n",
       "      <td>0.4396</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1, 'eta': 0.3, 'gamma': 0, 'max_dept...</td>\n",
       "      <td>-2.8839</td>\n",
       "      <td>-2.8894</td>\n",
       "      <td>-3.1328</td>\n",
       "      <td>-2.7543</td>\n",
       "      <td>-2.6493</td>\n",
       "      <td>-2.8070</td>\n",
       "      <td>-2.8460</td>\n",
       "      <td>-2.8248</td>\n",
       "      <td>-2.7760</td>\n",
       "      <td>-3.0042</td>\n",
       "      <td>-2.6372</td>\n",
       "      <td>-2.7456</td>\n",
       "      <td>-3.1383</td>\n",
       "      <td>-3.3558</td>\n",
       "      <td>-2.7130</td>\n",
       "      <td>-2.8541</td>\n",
       "      <td>-2.7947</td>\n",
       "      <td>-2.7365</td>\n",
       "      <td>-2.8344</td>\n",
       "      <td>-3.0236</td>\n",
       "      <td>-2.8369</td>\n",
       "      <td>-2.8916</td>\n",
       "      <td>-2.8471</td>\n",
       "      <td>-2.9708</td>\n",
       "      <td>-2.8850</td>\n",
       "      <td>-2.6810</td>\n",
       "      <td>-2.8437</td>\n",
       "      <td>-3.1870</td>\n",
       "      <td>-2.9206</td>\n",
       "      <td>-2.8940</td>\n",
       "      <td>-2.8773</td>\n",
       "      <td>-3.1094</td>\n",
       "      <td>-3.0551</td>\n",
       "      <td>-2.7922</td>\n",
       "      <td>-2.6658</td>\n",
       "      <td>-2.6335</td>\n",
       "      <td>-2.9488</td>\n",
       "      <td>-2.8933</td>\n",
       "      <td>-2.9322</td>\n",
       "      <td>-2.7120</td>\n",
       "      <td>-2.9126</td>\n",
       "      <td>-2.6130</td>\n",
       "      <td>-2.7628</td>\n",
       "      <td>-2.9489</td>\n",
       "      <td>-3.0007</td>\n",
       "      <td>-2.8232</td>\n",
       "      <td>-2.8197</td>\n",
       "      <td>-2.6773</td>\n",
       "      <td>-2.8990</td>\n",
       "      <td>-2.7313</td>\n",
       "      <td>-2.8633</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.3159</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0, 'eta': 0.3, 'gamma': 0, 'max_dept...</td>\n",
       "      <td>-3.0536</td>\n",
       "      <td>-2.9722</td>\n",
       "      <td>-3.0618</td>\n",
       "      <td>-2.7503</td>\n",
       "      <td>-2.6166</td>\n",
       "      <td>-2.8283</td>\n",
       "      <td>-2.9097</td>\n",
       "      <td>-2.9377</td>\n",
       "      <td>-2.7394</td>\n",
       "      <td>-3.0465</td>\n",
       "      <td>-2.6608</td>\n",
       "      <td>-2.7774</td>\n",
       "      <td>-3.1016</td>\n",
       "      <td>-3.2540</td>\n",
       "      <td>-2.6950</td>\n",
       "      <td>-2.8268</td>\n",
       "      <td>-2.7911</td>\n",
       "      <td>-2.7458</td>\n",
       "      <td>-2.8301</td>\n",
       "      <td>-2.9603</td>\n",
       "      <td>-2.7248</td>\n",
       "      <td>-2.8419</td>\n",
       "      <td>-2.7467</td>\n",
       "      <td>-2.9070</td>\n",
       "      <td>-2.8780</td>\n",
       "      <td>-2.7028</td>\n",
       "      <td>-2.8654</td>\n",
       "      <td>-3.0870</td>\n",
       "      <td>-2.8279</td>\n",
       "      <td>-2.9331</td>\n",
       "      <td>-2.7439</td>\n",
       "      <td>-3.0881</td>\n",
       "      <td>-3.1090</td>\n",
       "      <td>-2.7997</td>\n",
       "      <td>-2.6597</td>\n",
       "      <td>-2.6526</td>\n",
       "      <td>-2.9426</td>\n",
       "      <td>-2.8567</td>\n",
       "      <td>-2.9482</td>\n",
       "      <td>-2.8179</td>\n",
       "      <td>-3.0158</td>\n",
       "      <td>-2.5966</td>\n",
       "      <td>-2.8202</td>\n",
       "      <td>-2.8709</td>\n",
       "      <td>-3.0075</td>\n",
       "      <td>-2.8210</td>\n",
       "      <td>-2.8720</td>\n",
       "      <td>-2.7893</td>\n",
       "      <td>-2.9255</td>\n",
       "      <td>-2.7814</td>\n",
       "      <td>-2.8638</td>\n",
       "      <td>0.1427</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.9165</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 0, 'eta': 0.3, 'gamma': 1, 'max_dept...</td>\n",
       "      <td>-3.0088</td>\n",
       "      <td>-2.9449</td>\n",
       "      <td>-3.0691</td>\n",
       "      <td>-2.7521</td>\n",
       "      <td>-2.6667</td>\n",
       "      <td>-2.7914</td>\n",
       "      <td>-2.8877</td>\n",
       "      <td>-2.9326</td>\n",
       "      <td>-2.7934</td>\n",
       "      <td>-3.0408</td>\n",
       "      <td>-2.6647</td>\n",
       "      <td>-2.8439</td>\n",
       "      <td>-3.1208</td>\n",
       "      <td>-3.3552</td>\n",
       "      <td>-2.6859</td>\n",
       "      <td>-2.7689</td>\n",
       "      <td>-2.7824</td>\n",
       "      <td>-2.7215</td>\n",
       "      <td>-2.7802</td>\n",
       "      <td>-2.9247</td>\n",
       "      <td>-2.7271</td>\n",
       "      <td>-2.8464</td>\n",
       "      <td>-2.7374</td>\n",
       "      <td>-2.9666</td>\n",
       "      <td>-2.8851</td>\n",
       "      <td>-2.6685</td>\n",
       "      <td>-2.8691</td>\n",
       "      <td>-3.1034</td>\n",
       "      <td>-2.8445</td>\n",
       "      <td>-2.9970</td>\n",
       "      <td>-2.7531</td>\n",
       "      <td>-3.1165</td>\n",
       "      <td>-3.1173</td>\n",
       "      <td>-2.8167</td>\n",
       "      <td>-2.6590</td>\n",
       "      <td>-2.6416</td>\n",
       "      <td>-2.9609</td>\n",
       "      <td>-2.8584</td>\n",
       "      <td>-2.9297</td>\n",
       "      <td>-2.8022</td>\n",
       "      <td>-3.0388</td>\n",
       "      <td>-2.5789</td>\n",
       "      <td>-2.7749</td>\n",
       "      <td>-2.8834</td>\n",
       "      <td>-3.0150</td>\n",
       "      <td>-2.8479</td>\n",
       "      <td>-2.8423</td>\n",
       "      <td>-2.7594</td>\n",
       "      <td>-2.9491</td>\n",
       "      <td>-2.7799</td>\n",
       "      <td>-2.8661</td>\n",
       "      <td>0.1532</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "390         2.8156        0.9368           0.0221          0.0063   \n",
       "462         1.7830        0.5794           0.0155          0.0038   \n",
       "414         2.7765        0.8016           0.0218          0.0054   \n",
       "198         2.6462        0.6415           0.0210          0.0045   \n",
       "270         1.7147        0.4713           0.0150          0.0031   \n",
       "..             ...           ...              ...             ...   \n",
       "381         0.9769        0.4038           0.0102          0.0031   \n",
       "190         0.9556        0.2890           0.0102          0.0022   \n",
       "356         1.0736        0.4396           0.0108          0.0028   \n",
       "165         0.9870        0.3159           0.0104          0.0023   \n",
       "189         0.9165        0.3030           0.0099          0.0024   \n",
       "\n",
       "     param_alpha  param_eta  param_gamma  param_max_depth  \\\n",
       "390            2       0.05            0                6   \n",
       "462            2       0.10            1                6   \n",
       "414            2       0.05            1                6   \n",
       "198            1       0.05            0                6   \n",
       "270            1       0.10            1                6   \n",
       "..           ...        ...          ...              ...   \n",
       "381            1       0.30            1                8   \n",
       "190            0       0.30            1                8   \n",
       "356            1       0.30            0                8   \n",
       "165            0       0.30            0                8   \n",
       "189            0       0.30            1                8   \n",
       "\n",
       "     param_min_child_weight  param_subsample  \\\n",
       "390                       3                1   \n",
       "462                       3                1   \n",
       "414                       3                1   \n",
       "198                       3                1   \n",
       "270                       3                1   \n",
       "..                      ...              ...   \n",
       "381                       6                1   \n",
       "190                       7                1   \n",
       "356                       5                1   \n",
       "165                       6                1   \n",
       "189                       6                1   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "390  {'alpha': 2, 'eta': 0.05, 'gamma': 0, 'max_dep...            -2.8747   \n",
       "462  {'alpha': 2, 'eta': 0.1, 'gamma': 1, 'max_dept...            -2.9023   \n",
       "414  {'alpha': 2, 'eta': 0.05, 'gamma': 1, 'max_dep...            -2.8807   \n",
       "198  {'alpha': 1, 'eta': 0.05, 'gamma': 0, 'max_dep...            -2.8759   \n",
       "270  {'alpha': 1, 'eta': 0.1, 'gamma': 1, 'max_dept...            -2.8839   \n",
       "..                                                 ...                ...   \n",
       "381  {'alpha': 1, 'eta': 0.3, 'gamma': 1, 'max_dept...            -2.9787   \n",
       "190  {'alpha': 0, 'eta': 0.3, 'gamma': 1, 'max_dept...            -3.0187   \n",
       "356  {'alpha': 1, 'eta': 0.3, 'gamma': 0, 'max_dept...            -2.8839   \n",
       "165  {'alpha': 0, 'eta': 0.3, 'gamma': 0, 'max_dept...            -3.0536   \n",
       "189  {'alpha': 0, 'eta': 0.3, 'gamma': 1, 'max_dept...            -3.0088   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "390            -2.8104            -2.9645            -2.6344   \n",
       "462            -2.8022            -2.9681            -2.6509   \n",
       "414            -2.8145            -2.9764            -2.6396   \n",
       "198            -2.7915            -2.9402            -2.6532   \n",
       "270            -2.8079            -2.9565            -2.6324   \n",
       "..                 ...                ...                ...   \n",
       "381            -2.9631            -3.0607            -2.7497   \n",
       "190            -2.9434            -3.0260            -2.7715   \n",
       "356            -2.8894            -3.1328            -2.7543   \n",
       "165            -2.9722            -3.0618            -2.7503   \n",
       "189            -2.9449            -3.0691            -2.7521   \n",
       "\n",
       "     split4_test_score  split5_test_score  split6_test_score  \\\n",
       "390            -2.5201            -2.7092            -2.8012   \n",
       "462            -2.5287            -2.7101            -2.7850   \n",
       "414            -2.5103            -2.7178            -2.7791   \n",
       "198            -2.5438            -2.7037            -2.8034   \n",
       "270            -2.5528            -2.7190            -2.7745   \n",
       "..                 ...                ...                ...   \n",
       "381            -2.6576            -2.7932            -2.8584   \n",
       "190            -2.6489            -2.8057            -2.8667   \n",
       "356            -2.6493            -2.8070            -2.8460   \n",
       "165            -2.6166            -2.8283            -2.9097   \n",
       "189            -2.6667            -2.7914            -2.8877   \n",
       "\n",
       "     split7_test_score  split8_test_score  split9_test_score  \\\n",
       "390            -2.8046            -2.6308            -3.0083   \n",
       "462            -2.7812            -2.6288            -2.9892   \n",
       "414            -2.8010            -2.6258            -3.0108   \n",
       "198            -2.8307            -2.6563            -2.9891   \n",
       "270            -2.8018            -2.6255            -2.9989   \n",
       "..                 ...                ...                ...   \n",
       "381            -2.8372            -2.7069            -3.0427   \n",
       "190            -2.7912            -2.7890            -3.0826   \n",
       "356            -2.8248            -2.7760            -3.0042   \n",
       "165            -2.9377            -2.7394            -3.0465   \n",
       "189            -2.9326            -2.7934            -3.0408   \n",
       "\n",
       "     split10_test_score  split11_test_score  split12_test_score  \\\n",
       "390             -2.6181             -2.6967             -3.0245   \n",
       "462             -2.6152             -2.7155             -3.0202   \n",
       "414             -2.6192             -2.6832             -3.0101   \n",
       "198             -2.6050             -2.7038             -3.0215   \n",
       "270             -2.6025             -2.6621             -3.0495   \n",
       "..                  ...                 ...                 ...   \n",
       "381             -2.6605             -2.7402             -3.1469   \n",
       "190             -2.6835             -2.8529             -3.0662   \n",
       "356             -2.6372             -2.7456             -3.1383   \n",
       "165             -2.6608             -2.7774             -3.1016   \n",
       "189             -2.6647             -2.8439             -3.1208   \n",
       "\n",
       "     split13_test_score  split14_test_score  split15_test_score  \\\n",
       "390             -3.2264             -2.6470             -2.7103   \n",
       "462             -3.2150             -2.6272             -2.6948   \n",
       "414             -3.2254             -2.6369             -2.7062   \n",
       "198             -3.2330             -2.6298             -2.7104   \n",
       "270             -3.2010             -2.6367             -2.7040   \n",
       "..                  ...                 ...                 ...   \n",
       "381             -3.2226             -2.6784             -2.7294   \n",
       "190             -3.2961             -2.6683             -2.7317   \n",
       "356             -3.3558             -2.7130             -2.8541   \n",
       "165             -3.2540             -2.6950             -2.8268   \n",
       "189             -3.3552             -2.6859             -2.7689   \n",
       "\n",
       "     split16_test_score  split17_test_score  split18_test_score  \\\n",
       "390             -2.7344             -2.6205             -2.7780   \n",
       "462             -2.7421             -2.6244             -2.7874   \n",
       "414             -2.7410             -2.6084             -2.8112   \n",
       "198             -2.7233             -2.5977             -2.7841   \n",
       "270             -2.7280             -2.5982             -2.8082   \n",
       "..                  ...                 ...                 ...   \n",
       "381             -2.7499             -2.6944             -2.8380   \n",
       "190             -2.7997             -2.6590             -2.8656   \n",
       "356             -2.7947             -2.7365             -2.8344   \n",
       "165             -2.7911             -2.7458             -2.8301   \n",
       "189             -2.7824             -2.7215             -2.7802   \n",
       "\n",
       "     split19_test_score  split20_test_score  split21_test_score  \\\n",
       "390             -2.8936             -2.6442             -2.7353   \n",
       "462             -2.9139             -2.6606             -2.7315   \n",
       "414             -2.8883             -2.6726             -2.7218   \n",
       "198             -2.8752             -2.6319             -2.7258   \n",
       "270             -2.9167             -2.6476             -2.7615   \n",
       "..                  ...                 ...                 ...   \n",
       "381             -3.0152             -2.6983             -2.8180   \n",
       "190             -2.9345             -2.7185             -2.8502   \n",
       "356             -3.0236             -2.8369             -2.8916   \n",
       "165             -2.9603             -2.7248             -2.8419   \n",
       "189             -2.9247             -2.7271             -2.8464   \n",
       "\n",
       "     split22_test_score  split23_test_score  split24_test_score  \\\n",
       "390             -2.7034             -2.8466             -2.7551   \n",
       "462             -2.6868             -2.8437             -2.7663   \n",
       "414             -2.7166             -2.8378             -2.7687   \n",
       "198             -2.7075             -2.8394             -2.7640   \n",
       "270             -2.6901             -2.8535             -2.7412   \n",
       "..                  ...                 ...                 ...   \n",
       "381             -2.8081             -2.9739             -2.8715   \n",
       "190             -2.8279             -2.9075             -2.9010   \n",
       "356             -2.8471             -2.9708             -2.8850   \n",
       "165             -2.7467             -2.9070             -2.8780   \n",
       "189             -2.7374             -2.9666             -2.8851   \n",
       "\n",
       "     split25_test_score  split26_test_score  split27_test_score  \\\n",
       "390             -2.6193             -2.8131             -2.9734   \n",
       "462             -2.6071             -2.8056             -2.9650   \n",
       "414             -2.6326             -2.8203             -3.0013   \n",
       "198             -2.6466             -2.8012             -2.9711   \n",
       "270             -2.6351             -2.8211             -2.9831   \n",
       "..                  ...                 ...                 ...   \n",
       "381             -2.6545             -2.9507             -3.0982   \n",
       "190             -2.6471             -2.9459             -3.0934   \n",
       "356             -2.6810             -2.8437             -3.1870   \n",
       "165             -2.7028             -2.8654             -3.0870   \n",
       "189             -2.6685             -2.8691             -3.1034   \n",
       "\n",
       "     split28_test_score  split29_test_score  split30_test_score  \\\n",
       "390             -2.7827             -2.8240             -2.7225   \n",
       "462             -2.7508             -2.8190             -2.7506   \n",
       "414             -2.7689             -2.8339             -2.7156   \n",
       "198             -2.7788             -2.8368             -2.7591   \n",
       "270             -2.7708             -2.8524             -2.7369   \n",
       "..                  ...                 ...                 ...   \n",
       "381             -2.8194             -2.9976             -2.7538   \n",
       "190             -2.8018             -2.9690             -2.8188   \n",
       "356             -2.9206             -2.8940             -2.8773   \n",
       "165             -2.8279             -2.9331             -2.7439   \n",
       "189             -2.8445             -2.9970             -2.7531   \n",
       "\n",
       "     split31_test_score  split32_test_score  split33_test_score  \\\n",
       "390             -2.9173             -3.0038             -2.6837   \n",
       "462             -2.9181             -3.0239             -2.7045   \n",
       "414             -2.9019             -3.0050             -2.6975   \n",
       "198             -2.9184             -3.0061             -2.6794   \n",
       "270             -2.9144             -3.0561             -2.6952   \n",
       "..                  ...                 ...                 ...   \n",
       "381             -3.1083             -3.0475             -2.7878   \n",
       "190             -3.0947             -3.0968             -2.7708   \n",
       "356             -3.1094             -3.0551             -2.7922   \n",
       "165             -3.0881             -3.1090             -2.7997   \n",
       "189             -3.1165             -3.1173             -2.8167   \n",
       "\n",
       "     split34_test_score  split35_test_score  split36_test_score  \\\n",
       "390             -2.5441             -2.5867             -2.8893   \n",
       "462             -2.5397             -2.5918             -2.9096   \n",
       "414             -2.5427             -2.5882             -2.9009   \n",
       "198             -2.5546             -2.6020             -2.9062   \n",
       "270             -2.5617             -2.6004             -2.9191   \n",
       "..                  ...                 ...                 ...   \n",
       "381             -2.6664             -2.6156             -2.9209   \n",
       "190             -2.6464             -2.7520             -2.9168   \n",
       "356             -2.6658             -2.6335             -2.9488   \n",
       "165             -2.6597             -2.6526             -2.9426   \n",
       "189             -2.6590             -2.6416             -2.9609   \n",
       "\n",
       "     split37_test_score  split38_test_score  split39_test_score  \\\n",
       "390             -2.8798             -2.8208             -2.6921   \n",
       "462             -2.8703             -2.8578             -2.6894   \n",
       "414             -2.8754             -2.8374             -2.7017   \n",
       "198             -2.8407             -2.8263             -2.7027   \n",
       "270             -2.8565             -2.8462             -2.6961   \n",
       "..                  ...                 ...                 ...   \n",
       "381             -2.9832             -2.9931             -2.7777   \n",
       "190             -2.9592             -2.9520             -2.7584   \n",
       "356             -2.8933             -2.9322             -2.7120   \n",
       "165             -2.8567             -2.9482             -2.8179   \n",
       "189             -2.8584             -2.9297             -2.8022   \n",
       "\n",
       "     split40_test_score  split41_test_score  split42_test_score  \\\n",
       "390             -2.8434             -2.5012             -2.6956   \n",
       "462             -2.8560             -2.5045             -2.7170   \n",
       "414             -2.8305             -2.4915             -2.6834   \n",
       "198             -2.8459             -2.5179             -2.6988   \n",
       "270             -2.8195             -2.4952             -2.7358   \n",
       "..                  ...                 ...                 ...   \n",
       "381             -3.0549             -2.5736             -2.7926   \n",
       "190             -2.8985             -2.5779             -2.7556   \n",
       "356             -2.9126             -2.6130             -2.7628   \n",
       "165             -3.0158             -2.5966             -2.8202   \n",
       "189             -3.0388             -2.5789             -2.7749   \n",
       "\n",
       "     split43_test_score  split44_test_score  split45_test_score  \\\n",
       "390             -2.8489             -2.7929             -2.8236   \n",
       "462             -2.8374             -2.8284             -2.7953   \n",
       "414             -2.8405             -2.8423             -2.8293   \n",
       "198             -2.8664             -2.8277             -2.8138   \n",
       "270             -2.8500             -2.8101             -2.8188   \n",
       "..                  ...                 ...                 ...   \n",
       "381             -2.9255             -2.9684             -2.8599   \n",
       "190             -2.8602             -3.0265             -2.8744   \n",
       "356             -2.9489             -3.0007             -2.8232   \n",
       "165             -2.8709             -3.0075             -2.8210   \n",
       "189             -2.8834             -3.0150             -2.8479   \n",
       "\n",
       "     split46_test_score  split47_test_score  split48_test_score  \\\n",
       "390             -2.7490             -2.5771             -2.8240   \n",
       "462             -2.7703             -2.5722             -2.8162   \n",
       "414             -2.7591             -2.5858             -2.8183   \n",
       "198             -2.7679             -2.5650             -2.8280   \n",
       "270             -2.7548             -2.5851             -2.7926   \n",
       "..                  ...                 ...                 ...   \n",
       "381             -2.7811             -2.7503             -2.8870   \n",
       "190             -2.8632             -2.6819             -2.9413   \n",
       "356             -2.8197             -2.6773             -2.8990   \n",
       "165             -2.8720             -2.7893             -2.9255   \n",
       "189             -2.8423             -2.7594             -2.9491   \n",
       "\n",
       "     split49_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "390             -2.7143          -2.7703          0.1422                1  \n",
       "462             -2.6937          -2.7717          0.1420                2  \n",
       "414             -2.7055          -2.7723          0.1434                3  \n",
       "198             -2.7154          -2.7723          0.1394                4  \n",
       "270             -2.7014          -2.7732          0.1432                5  \n",
       "..                  ...              ...             ...              ...  \n",
       "381             -2.7926          -2.8571          0.1517              572  \n",
       "190             -2.8325          -2.8608          0.1454              573  \n",
       "356             -2.7313          -2.8633          0.1524              574  \n",
       "165             -2.7814          -2.8638          0.1427              575  \n",
       "189             -2.7799          -2.8661          0.1532              576  \n",
       "\n",
       "[576 rows x 64 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_tuning_results = pd.read_csv(\"./model_runs/xgbr-ensemble/tuning_results_run_2022-11-14-18h36m.csv\")\n",
    "ensemble_tuning_results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2c6b2704-12b1-4c03-a237-3f4f9871e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ensemble_params = ast.literal_eval(ensemble_tuning_results.iloc[462]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "faffa7de-757c-4664-b3ac-3a33c727c2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 2,\n",
       " 'eta': 0.1,\n",
       " 'gamma': 1,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 3,\n",
       " 'subsample': 1}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ensemble_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "712e23f1-dbca-4dc4-a64c-51d1b00a5c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(alpha=2, base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False, eta=0.1,\n",
       "             eval_metric=None, gamma=1, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.100000001, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=3,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, objective='reg:squarederror',\n",
       "             predictor='auto', ...)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_final_model = XGBRegressor(**final_ensemble_params, random_state = 42)\n",
    "X = final_ensemble_modeling_df.drop(columns = 'score')\n",
    "y = final_ensemble_modeling_df[['score']]\n",
    "ensemble_final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea2c9b49-94f9-4449-a43e-a50099f25903",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_save_path = './xgbr-ensemble/ensemble_model_final.pkl'\n",
    "\n",
    "with open(ensemble_save_path, 'wb') as f:\n",
    "    pickle.dump(ensemble_final_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7072d7ef-77e0-4115-99c9-2cc149d69f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble_aat_results = artificial_anomaly_test_xgb(\n",
    "    model = ensemble_final_model,\n",
    "    model_data = final_ensemble_modeling_df,\n",
    "    selected_features = ['iforest_score','lag1','prov_mean'],\n",
    "    shift_range = np.arange(4,11),\n",
    "    threshold_range = range(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2308dbda-edc9-4c3f-919c-2065a12180c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>AUROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.914357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.897286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.881929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.849000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.730571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.607214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold     AUROC\n",
       "2          3  0.914357\n",
       "3          4  0.897286\n",
       "1          2  0.881929\n",
       "4          5  0.849000\n",
       "5          6  0.790000\n",
       "0          1  0.770000\n",
       "6          7  0.730571\n",
       "7          8  0.667500\n",
       "8          9  0.607214"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_aat_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4d3fb0a-398e-4a07-9221-08c956d6169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "07a5ce09-38d3-4b9d-8ac5-a547f6ffb5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_full_df = modeling_df.copy()\n",
    "ensemble_full_df['iforest_score'] = iforest_anomaly_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eab5c74a-df38-438c-ab19-148105d7a1de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iforest_score</th>\n",
       "      <th>lag1</th>\n",
       "      <th>prov_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.443219</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.387362</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.470720</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.401492</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.422357</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29089</th>\n",
       "      <td>0.444184</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29090</th>\n",
       "      <td>0.469713</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29092</th>\n",
       "      <td>0.434941</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29093</th>\n",
       "      <td>0.458783</td>\n",
       "      <td>12.6</td>\n",
       "      <td>14.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29095</th>\n",
       "      <td>0.464342</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24799 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       iforest_score  lag1  prov_mean\n",
       "1           0.443219   4.6   4.600000\n",
       "2           0.387362   6.5   5.550000\n",
       "3           0.470720   6.4   5.833333\n",
       "4           0.401492   9.0   6.625000\n",
       "5           0.422357   6.5   6.600000\n",
       "...              ...   ...        ...\n",
       "29089       0.444184   6.6   4.150000\n",
       "29090       0.469713   7.5   5.266667\n",
       "29092       0.434941  16.1  16.100000\n",
       "29093       0.458783  12.6  14.350000\n",
       "29095       0.464342   5.5   5.500000\n",
       "\n",
       "[24799 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_full_df[ensemble_selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "45580a09-6880-44fb-8166-e3bbee911606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble_final_predictions = ensemble_final_model.predict(ensemble_full_df[ensemble_selected_features])\n",
    "ensemble_full_df['ensemble_pred_score'] = ensemble_final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cf22a659-1584-4b9d-aacd-628756191689",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_full_df['ensemble_score_diff'] = ensemble_full_df['score'] - ensemble_final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4da10346-e992-4c4c-8906-c4c901ae877c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>lag1</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>lag_diff</th>\n",
       "      <th>prov_mean</th>\n",
       "      <th>prov_mean_diff</th>\n",
       "      <th>iforest_score</th>\n",
       "      <th>ensemble_pred_score</th>\n",
       "      <th>ensemble_score_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.443219</td>\n",
       "      <td>5.738575</td>\n",
       "      <td>0.761425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.387362</td>\n",
       "      <td>5.301938</td>\n",
       "      <td>1.098062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0.470720</td>\n",
       "      <td>6.597307</td>\n",
       "      <td>2.402693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.401492</td>\n",
       "      <td>7.151802</td>\n",
       "      <td>-0.651802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.422357</td>\n",
       "      <td>5.742346</td>\n",
       "      <td>2.257654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29089</th>\n",
       "      <td>7.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>0.444184</td>\n",
       "      <td>5.756759</td>\n",
       "      <td>1.743241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29090</th>\n",
       "      <td>1.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>-3.666667</td>\n",
       "      <td>0.469713</td>\n",
       "      <td>6.280502</td>\n",
       "      <td>-4.680502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29092</th>\n",
       "      <td>12.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>0.434941</td>\n",
       "      <td>14.185899</td>\n",
       "      <td>-1.585899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29093</th>\n",
       "      <td>8.7</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>-5.650000</td>\n",
       "      <td>0.458783</td>\n",
       "      <td>11.234047</td>\n",
       "      <td>-2.534047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29095</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>0.464342</td>\n",
       "      <td>5.964983</td>\n",
       "      <td>-4.964983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24799 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  lag1  year  quarter  lag_diff  prov_mean  prov_mean_diff  \\\n",
       "1        6.5   4.6  2014        2       1.9   4.600000        1.900000   \n",
       "2        6.4   6.5  2015        2      -0.1   5.550000        0.850000   \n",
       "3        9.0   6.4  2016        2       2.6   5.833333        3.166667   \n",
       "4        6.5   9.0  2017        2      -2.5   6.625000       -0.125000   \n",
       "5        8.0   6.5  2018        2       1.5   6.600000        1.400000   \n",
       "...      ...   ...   ...      ...       ...        ...             ...   \n",
       "29089    7.5   6.6  2019        2       0.9   4.150000        3.350000   \n",
       "29090    1.6   7.5  2019        4      -5.9   5.266667       -3.666667   \n",
       "29092   12.6  16.1  2019        2      -3.5  16.100000       -3.500000   \n",
       "29093    8.7  12.6  2019        4      -3.9  14.350000       -5.650000   \n",
       "29095    1.0   5.5  2019        4      -4.5   5.500000       -4.500000   \n",
       "\n",
       "       iforest_score  ensemble_pred_score  ensemble_score_diff  \n",
       "1           0.443219             5.738575             0.761425  \n",
       "2           0.387362             5.301938             1.098062  \n",
       "3           0.470720             6.597307             2.402693  \n",
       "4           0.401492             7.151802            -0.651802  \n",
       "5           0.422357             5.742346             2.257654  \n",
       "...              ...                  ...                  ...  \n",
       "29089       0.444184             5.756759             1.743241  \n",
       "29090       0.469713             6.280502            -4.680502  \n",
       "29092       0.434941            14.185899            -1.585899  \n",
       "29093       0.458783            11.234047            -2.534047  \n",
       "29095       0.464342             5.964983            -4.964983  \n",
       "\n",
       "[24799 rows x 10 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3ca4f0f-6246-459c-b807-801e6c05c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_full_df['ensemble_outlier_pred'] = abs(ensemble_full_df['ensemble_score_diff']) > 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8ace426-f498-42b5-ace5-cd26a4e97ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1752\n",
       "True     1353\n",
       "Name: ensemble_outlier_pred, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_full_df.query('(year == 2019) & (quarter == 4)')['ensemble_outlier_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af004412-4e6f-4e67-bdb4-ac8175914c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ensemble_outlier_pred\n",
       "False                    22329\n",
       "True                      2470\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_full_df[['ensemble_outlier_pred']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "549e1991-07cb-48c6-ad0f-611a65ec5c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>lag1</th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>lag_diff</th>\n",
       "      <th>prov_mean</th>\n",
       "      <th>prov_mean_diff</th>\n",
       "      <th>iforest_score</th>\n",
       "      <th>ensemble_pred_score</th>\n",
       "      <th>ensemble_score_diff</th>\n",
       "      <th>ensemble_outlier_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.443219</td>\n",
       "      <td>5.738575</td>\n",
       "      <td>0.761425</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.387362</td>\n",
       "      <td>5.301938</td>\n",
       "      <td>1.098062</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0.470720</td>\n",
       "      <td>6.597307</td>\n",
       "      <td>2.402693</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.401492</td>\n",
       "      <td>7.151802</td>\n",
       "      <td>-0.651802</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.422357</td>\n",
       "      <td>5.742346</td>\n",
       "      <td>2.257654</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29089</th>\n",
       "      <td>7.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>3.350000</td>\n",
       "      <td>0.444184</td>\n",
       "      <td>5.756759</td>\n",
       "      <td>1.743241</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29090</th>\n",
       "      <td>1.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>5.266667</td>\n",
       "      <td>-3.666667</td>\n",
       "      <td>0.469713</td>\n",
       "      <td>6.280502</td>\n",
       "      <td>-4.680502</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29092</th>\n",
       "      <td>12.6</td>\n",
       "      <td>16.1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>0.434941</td>\n",
       "      <td>14.185899</td>\n",
       "      <td>-1.585899</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29093</th>\n",
       "      <td>8.7</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>-5.650000</td>\n",
       "      <td>0.458783</td>\n",
       "      <td>11.234047</td>\n",
       "      <td>-2.534047</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29095</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>0.464342</td>\n",
       "      <td>5.964983</td>\n",
       "      <td>-4.964983</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24799 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  lag1  year  quarter  lag_diff  prov_mean  prov_mean_diff  \\\n",
       "1        6.5   4.6  2014        2       1.9   4.600000        1.900000   \n",
       "2        6.4   6.5  2015        2      -0.1   5.550000        0.850000   \n",
       "3        9.0   6.4  2016        2       2.6   5.833333        3.166667   \n",
       "4        6.5   9.0  2017        2      -2.5   6.625000       -0.125000   \n",
       "5        8.0   6.5  2018        2       1.5   6.600000        1.400000   \n",
       "...      ...   ...   ...      ...       ...        ...             ...   \n",
       "29089    7.5   6.6  2019        2       0.9   4.150000        3.350000   \n",
       "29090    1.6   7.5  2019        4      -5.9   5.266667       -3.666667   \n",
       "29092   12.6  16.1  2019        2      -3.5  16.100000       -3.500000   \n",
       "29093    8.7  12.6  2019        4      -3.9  14.350000       -5.650000   \n",
       "29095    1.0   5.5  2019        4      -4.5   5.500000       -4.500000   \n",
       "\n",
       "       iforest_score  ensemble_pred_score  ensemble_score_diff  \\\n",
       "1           0.443219             5.738575             0.761425   \n",
       "2           0.387362             5.301938             1.098062   \n",
       "3           0.470720             6.597307             2.402693   \n",
       "4           0.401492             7.151802            -0.651802   \n",
       "5           0.422357             5.742346             2.257654   \n",
       "...              ...                  ...                  ...   \n",
       "29089       0.444184             5.756759             1.743241   \n",
       "29090       0.469713             6.280502            -4.680502   \n",
       "29092       0.434941            14.185899            -1.585899   \n",
       "29093       0.458783            11.234047            -2.534047   \n",
       "29095       0.464342             5.964983            -4.964983   \n",
       "\n",
       "       ensemble_outlier_pred  \n",
       "1                      False  \n",
       "2                      False  \n",
       "3                      False  \n",
       "4                      False  \n",
       "5                      False  \n",
       "...                      ...  \n",
       "29089                  False  \n",
       "29090                   True  \n",
       "29092                  False  \n",
       "29093                  False  \n",
       "29095                   True  \n",
       "\n",
       "[24799 rows x 11 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d72684b6-f6ce-4c33-af83-937bc9449acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(alpha=2, base_score=0.5, booster='gbtree', callbacks=None,\n",
      "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "             early_stopping_rounds=None, enable_categorical=False, eta=0.1,\n",
      "             eval_metric=None, gamma=1, gpu_id=-1, grow_policy='depthwise',\n",
      "             importance_type=None, interaction_constraints='',\n",
      "             learning_rate=0.100000001, max_bin=256, max_cat_to_onehot=4,\n",
      "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=3,\n",
      "             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
      "             num_parallel_tree=1, objective='reg:squarederror',\n",
      "             predictor='auto', ...)\n"
     ]
    }
   ],
   "source": [
    "print(ensemble_final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "44a74507-5499-4a3d-900e-85ce5b9eadaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ensemble_final_modeling_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-ad85cd619008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mensemble_final_modeling_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ensemble_final_modeling_df' is not defined"
     ]
    }
   ],
   "source": [
    "ensemble_final_modeling_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722a24f-e7ff-478b-ae71-d1350a9acb5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.c5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
